{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6917ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# # Download necessary NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# # Initialize a Porter stemmer\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "from datasets import DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 54] Connection\n",
      "[nltk_data]     reset by peer>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "# nltk.load('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acac9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cae03fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: arxiv-summarization/section\n",
      "Found cached dataset arxiv-summarization (/Users/ashnadua/.cache/huggingface/datasets/ccdv___arxiv-summarization/section/1.0.0/fa2c9abf4312afb8660ef8e041d576b8e3943ea96ae771bd3cd091b5798e7cc3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b3d41b87214c6c9724b409e5155686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ccdv/arxiv-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a1a89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    document_article = example['article']\n",
    "    # print(document_article)\n",
    "\n",
    "    sentences = document_article.split(\" .\")\n",
    "\n",
    "    sent_articles = \"\"\n",
    "    for sen in sentences:\n",
    "      sen = sen.replace('\\n', ' ')\n",
    "      sen = ' '.join(word for word in sen.split() if not word.startswith('@'))\n",
    "      sen = re.sub(r'\\W+', ' ', sen)\n",
    "      sent_articles += sen\n",
    "      sent_articles += \". \"\n",
    "    document_abstract = example['abstract']\n",
    "    sentences = document_abstract.split(\" .\")\n",
    "    sent_abstract = \"\"\n",
    "    for sen in sentences:\n",
    "      sen = sen.replace('\\n', ' ')\n",
    "      sen = ' '.join(word for word in sen.split() if not word.startswith('@'))\n",
    "      sen = re.sub(r'\\W+', ' ', sen)\n",
    "      sent_abstract += sen\n",
    "      sent_abstract += \". \"\n",
    "\n",
    "    return {'article': sent_articles, 'abstract': sent_abstract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_send = DatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_send[\"train\"] = dataset[\"train\"].select(range(1000))\n",
    "dataset_send[\"validation\"] = dataset[\"validation\"].select(range(1000))\n",
    "dataset_send[\"test\"] = dataset[\"test\"].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select(range(500))\n",
    "dataset[\"validation\"] = dataset[\"validation\"].select(range(500))\n",
    "dataset[\"test\"] = dataset[\"test\"].select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3d85ccb2354e768728ae164d299381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96932de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27da5097886047f5a03f4fd2bf7ca594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"validation\"] = dataset[\"validation\"].map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3472fa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33767f3a26374fae819cef2b93e94223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"test\"] = dataset[\"test\"].map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5f7054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c4b22e2ebc4f7a9542dd4b97d607ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_send[\"test\"] = dataset_send[\"test\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa984783",
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_phrases = [\"the paper describes\", \"in conclusion\", \"in summary\", \"our investigation\", \"the best\", \"the most important\", \"in particular\", \"according to the study\", \"significantly\", \"important\", \"hardly\", \"impossible\"]\n",
    "\n",
    "def calculate_scores(articles):\n",
    "    scores = []\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Split each article into sentences and flatten the list\n",
    "    sentences = [sentence for article in articles for sentence in article.split('. ')]\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sLen = len(word_tokenize(sentence))\n",
    "        sPos = i / len(sentences)\n",
    "\n",
    "        pos_tags = nltk.pos_tag(word_tokenize(sentence))\n",
    "        nvpi = len([word for word, pos in pos_tags if pos in ['NN', 'NNS', 'VB', 'VBD', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']])\n",
    "        PNi = len([word for word, pos in pos_tags if pos in ['NNP', 'NNPS']])\n",
    "\n",
    "        current_tfidf = tfidf_matrix[i].toarray()\n",
    "        acs = cosine_similarity(current_tfidf, tfidf_matrix).mean()\n",
    "        cp_count = sum(1 for phrase in cue_phrases if phrase in sentence.lower())\n",
    "        tf_idf = current_tfidf.sum()\n",
    "\n",
    "        scores.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"F1\": sLen,\n",
    "            \"F2\": sPos,\n",
    "            \"F3\": tf_idf,\n",
    "            \"F4\": nvpi,\n",
    "            \"F5\": PNi,               \n",
    "            \"F6\": acs,\n",
    "            \"F7\": cp_count,\n",
    "        })\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_for_each_sentence(articles):\n",
    "    all_scores = []\n",
    "    \n",
    "    for article in articles:\n",
    "        # Split the article into sentences\n",
    "        sentences = article.split('. ')\n",
    "        \n",
    "        scores = calculate_scores(sentences)\n",
    "        \n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    return all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = calculate_scores_for_each_sentence(dataset_send[\"test\"][\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = calculate_scores(df_train[\"article\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def restructure_scores(articles, scores):\n",
    "#     start = 0\n",
    "#     all_scores = []\n",
    "#     for article in articles:\n",
    "#         num_sentences = len(article.split(\". \"))\n",
    "#         article_scores = scores[start:start+num_sentences]\n",
    "#         all_scores.append(article_scores)\n",
    "#         start += num_sentences\n",
    "#     return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_scores = restructure_scores(df_train[\"article\"], scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentence_length(sLen):\n",
    "    sLenmax = max(sLen)\n",
    "    if sLenmax == 0:\n",
    "        return [0.0] * len(sLen)  # Avoid division by zero\n",
    "    return [sLeni / sLenmax for sLeni in sLen]\n",
    "\n",
    "def normalize_tfidf(tfidf_scores):\n",
    "    tfidf_max = max(tfidf_scores)\n",
    "    if tfidf_max == 0:\n",
    "        return [0.0] * len(tfidf_scores)  # Avoid division by zero\n",
    "    return [(tfidf_i / tfidf_max) for tfidf_i in tfidf_scores]\n",
    "\n",
    "def normalize_noun_verb_phrase(nvpi):\n",
    "    nvpi_max = max(nvpi)\n",
    "    if nvpi_max == 0:\n",
    "        return [0.0] * len(nvpi)  # Avoid division by zero\n",
    "    return [(nvpi_i / nvpi_max) for nvpi_i in nvpi]\n",
    "\n",
    "def normalize_proper_noun(PNi):\n",
    "    PNmax = max(PNi)\n",
    "    if PNmax == 0:\n",
    "        return [0.0] * len(PNi)  # Avoid division by zero\n",
    "    return [(PNi_i / PNmax) for PNi_i in PNi]\n",
    "\n",
    "def normalize_cosine_similarity(ACS):\n",
    "    ACSmax = max(ACS)\n",
    "    if ACSmax == 0:\n",
    "        return [0.0] * len(ACS)  # Avoid division by zero\n",
    "    return [(ACS_i / ACSmax) for ACS_i in ACS]\n",
    "\n",
    "def normalize_cue_phrases(CPi, tCP):\n",
    "    if tCP == 0:\n",
    "        return [0.0] * len(CPi)  # Avoid division by zero\n",
    "    return [(CPi_i / tCP) for CPi_i in CPi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(grouped_scores):\n",
    "    normalized_scores = []\n",
    "    for scores in grouped_scores:\n",
    "        df = pd.DataFrame(scores)\n",
    "        \n",
    "        df['F1'] = normalize_sentence_length(df['F1'])\n",
    "        df['F3'] = normalize_tfidf(df['F3'])\n",
    "        df['F4'] = normalize_noun_verb_phrase(df['F4'])\n",
    "        df['F5'] = normalize_proper_noun(df['F5'])\n",
    "        df['F6'] = normalize_cosine_similarity(df['F6'])\n",
    "        df['F7'] = normalize_cue_phrases(df['F7'], df['F7'].sum())\n",
    "        \n",
    "        normalized_scores.append(df)\n",
    "    \n",
    "    return normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_scores = normalize_scores(all_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in normalized_scores:\n",
    "    df['total_score'] = df[['F1', 'F3', 'F4', 'F5', 'F6', 'F7']].sum(axis=1)\n",
    "    df.sort_values(by='total_score', ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def generate_summary(normalized_scores, num_sentences=3, similarity_threshold=0.8):\n",
    "    summaries = []\n",
    "    \n",
    "    for df in normalized_scores:\n",
    "        # Sort the DataFrame by 'total_score' in descending order and reset the index\n",
    "        df_sorted = df.sort_values(by='total_score', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        # Fit the TF-IDF vectorizer on the sentences of the current article\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_vectorizer.fit(df_sorted['sentence'])\n",
    "        \n",
    "        summary_sentences = []\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            sentence = row['sentence']\n",
    "            if not summary_sentences:\n",
    "                summary_sentences.append(sentence)\n",
    "            else:\n",
    "                # Calculate cosine similarity with existing summary\n",
    "                similarity = cosine_similarity(\n",
    "                    tfidf_vectorizer.transform([sentence]),\n",
    "                    tfidf_vectorizer.transform(summary_sentences)\n",
    "                )\n",
    "                # If the sentence is not too similar to the existing summary, add it\n",
    "                if np.max(similarity) < similarity_threshold:\n",
    "                    summary_sentences.append(sentence)\n",
    "            # Stop adding sentences if we've reached the desired length\n",
    "            if len(summary_sentences) == num_sentences:\n",
    "                break\n",
    "        \n",
    "        # Join the sentences together into a summary\n",
    "        summary = '. '.join(summary_sentences)\n",
    "        \n",
    "        summaries.append(summary)\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "# Now you can call the function like this:\n",
    "summaries = generate_summary(normalized_scores, num_sentences=10, similarity_threshold=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_send[\"test\"] = dataset_send[\"test\"].add_column(\"summary\", summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a2c8534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'abstract', 'summary'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_send[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "class Score:\n",
    "    def __init__(self, trueSummary = None, predSummary = None):\n",
    "        self.trueSummary = trueSummary if trueSummary is not None else \"\"\n",
    "        self.predSummary = predSummary if predSummary is not None else \"\"\n",
    "\n",
    "    def rougeScore(self):\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rouge3'], use_stemmer=True)\n",
    "        scores = scorer.score(self.trueSummary, self.predSummary)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the short term periodicities of the daily sunspot area fluctuations from august 1923 to october 1933 are discussed. for these data the correlative analysis indicates negative correlation for the periodicity of about days but the power spectrum analysis indicates a statistically significant peak in this time interval. a new method of the diagnosis of an echo effect in spectrum is proposed and it is stated that the 155 day periodicity is a harmonic of the periodicities from the interval of days. the autocorrelation functions for the daily sunspot area fluctuations and for the fluctuations of the one rotation time interval in the northern hemisphere separately for the whole solar cycle 16 and for the maximum activity period of this cycle do not show differences especially in the interval of days. it proves against the thesis of the existence of strong positive fluctuations of the about interval in the maximum activity period of the solar cycle 16 in the northern hemisphere. however a similar analysis for data from the southern hemisphere indicates that there is the periodicity of about days in sunspot area data in the maximum activity period of the cycle 16 only. . '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_send[\"test\"][0][\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4c96492",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = []\n",
    "\n",
    "for i in range(len(dataset_send[\"test\"])):\n",
    "    true_summary = dataset_send[\"test\"][i][\"abstract\"]\n",
    "    pred_summary = dataset_send[\"test\"][i][\"summary\"]\n",
    "\n",
    "    score_obj = Score(true_summary, pred_summary)\n",
    "    scores = score_obj.rougeScore()\n",
    "    rouge_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "77a0be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_send[\"test\"] = dataset_send[\"test\"].add_column(\"Rouge\", rouge_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_send[\"test\"] = dataset_send[\"test\"].rename_column('abstract', 'Gold Summary')\n",
    "dataset_send[\"test\"] = dataset_send[\"test\"].rename_column('summary', 'Generated Summary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'Gold Summary', 'Generated Summary', 'Rouge'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_send[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "68c8e8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138461783fd34d7c8b31423e66935dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "33101782"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_send[\"test\"].to_csv('sum_it_up_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
