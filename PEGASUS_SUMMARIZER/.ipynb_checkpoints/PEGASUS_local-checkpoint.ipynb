{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29232896",
   "metadata": {},
   "source": [
    "## PEGASUS Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be9b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from parser.parser import Parser\n",
    "from scorer import Score\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "model_name = 'tuner007/pegasus_summarizer'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401b3c4",
   "metadata": {},
   "source": [
    "### Getting the token and downloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1da5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b291f",
   "metadata": {},
   "source": [
    "### Getting response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5418ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=1024, return_tensors=\"pt\").to(torch_device)\n",
    "  gen_out = model.generate(**batch,max_length=128,num_beams=5, num_return_sequences=1, do_sample = True, temperature=1.5)\n",
    "  output_text = tokenizer.batch_decode(gen_out, skip_special_tokens=True)\n",
    "  return output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a82718",
   "metadata": {},
   "source": [
    "### Getting the Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1ec634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We propose pre-training Transformer-based encoder-decoder mod-els on massive text corpora with a new self-supervised objective for abstractive text summarization. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an abstractive summary. We evaluated PEGASUS model on 12 downstream summariza- tion tasks spanning news, science, stories, instruc- tions, emails, patents, and legislative bills.\n"
     ]
    }
   ],
   "source": [
    "paperName = \"pegasus\"\n",
    "\n",
    "content = Parser(pdfFile = \"../papers/\" + paperName +\".pdf\")\n",
    "\n",
    "pegasusSummary = get_response(content)[0]\n",
    "\n",
    "print(pegasusSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45dbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldenSummary = '''Recent work pre-training Transformers with\n",
    "self-supervised objectives on large text corpora\n",
    "has shown great success when fine-tuned on\n",
    "downstream NLP tasks including text summa-\n",
    "rization. However, pre-training objectives tai-\n",
    "lored for abstractive text summarization have\n",
    "not been explored. Furthermore there is a\n",
    "lack of systematic evaluation across diverse do-\n",
    "mains. In this work, we propose pre-training\n",
    "large Transformer-based encoder-decoder mod-\n",
    "els on massive text corpora with a new self-\n",
    "supervised objective. In PEGASUS, important\n",
    "sentences are removed/masked from an input doc-\n",
    "ument and are generated together as one output\n",
    "sequence from the remaining sentences, similar\n",
    "to an extractive summary. We evaluated our best\n",
    "PEGASUS model on 12 downstream summariza-\n",
    "tion tasks spanning news, science, stories, instruc-\n",
    "tions, emails, patents, and legislative bills. Experi-\n",
    "ments demonstrate it achieves state-of-the-art per-\n",
    "formance on all 12 downstream datasets measured\n",
    "by ROUGE scores. Our model also shows surpris-\n",
    "ing performance on low-resource summarization,\n",
    "surpassing previous state-of-the-art results on 6\n",
    "datasets with only 1000 examples. Finally we\n",
    "validated our results using human evaluation and\n",
    "show that our model summaries achieve human\n",
    "performance on multiple datasets.'''\n",
    "\n",
    "score = Score(trueSummary = goldenSummary, predSummary = pegasusSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7afc0781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge2': Score(precision=0.9027777777777778, recall=0.33505154639175255, fmeasure=0.48872180451127817), 'rouge6': Score(precision=0.5882352941176471, recall=0.21052631578947367, fmeasure=0.31007751937984496)}\n"
     ]
    }
   ],
   "source": [
    "print(score.rougeScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebac6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
