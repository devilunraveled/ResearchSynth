{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29232896",
   "metadata": {},
   "source": [
    "## PEGASUS Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be9b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from parser.parser import Parser\n",
    "\n",
    "from scorer import Score\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "model_name = 'tuner007/pegasus_summarizer'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401b3c4",
   "metadata": {},
   "source": [
    "### Getting the token and downloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1da5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b291f",
   "metadata": {},
   "source": [
    "### Getting response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5418ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=1024, return_tensors=\"pt\").to(torch_device)\n",
    "  gen_out = model.generate(**batch,max_length=128,num_beams=5, num_return_sequences=1, do_sample = True, temperature=1.5)\n",
    "  output_text = tokenizer.batch_decode(gen_out, skip_special_tokens=True)\n",
    "  return output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a82718",
   "metadata": {},
   "source": [
    "### Getting the Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1ec634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large, flexible class of long, high-redundancy error correcting codes, GRAND, can be efficiently decoded with guessing random additive noise dec oding (GRAND). Grand is a recently developed family of code-agnostic decoding algorithms that can accurately decode long, high- redundancy codes. It can be used to decode long, high-redundancy codes while LDPC codes are used to decode long, high-redundancy codes.\n"
     ]
    }
   ],
   "source": [
    "paperName = \"2310.10737\"\n",
    "\n",
    "content = Parser(pdfFile = \"../papers/\" + paperName +\".pdf\")\n",
    "\n",
    "pegasusSummary = get_response(content)[0]\n",
    "\n",
    "print(pegasusSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d45dbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldenSummary = \"\"\n",
    "\n",
    "with open ( \"../papers/\" + paperName + \"_ABSTRACT.txt\") as f :\n",
    "    goldenSummary = f.read()\n",
    "    \n",
    "score = Score(trueSummary = goldenSummary, predSummary = pegasusSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7afc0781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria:rouge1, Score:Score(precision=0.703125, recall=0.17928286852589642, fmeasure=0.2857142857142857)\n",
      "Criteria:rouge2, Score:Score(precision=0.2857142857142857, recall=0.072, fmeasure=0.11501597444089456)\n",
      "Criteria:rougeL, Score:Score(precision=0.515625, recall=0.13147410358565736, fmeasure=0.2095238095238095)\n"
     ]
    }
   ],
   "source": [
    "for key, value in score.rougeScore().items():\n",
    "    print(f\"Criteria:{key}, Score:{value}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
