{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da90a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ashnadua/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ashnadua/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ashnadua/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize a Porter stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2b4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73918720",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9081a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = test_dict = {\"article_id\": \"1405.3379\", \"article_text\": [\"additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models .\", \"it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models .\", \"many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space @xmath0 , see e.g. @xcite . in the last years\", \"many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g. @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and the references therein . of course , the least squares loss function is differentiable and has many nice mathematical properties , but it is only locally lipschitz continuous and therefore regularized kernel based methods based on this loss function typically suffer on bad statistical robustness properties , even if the kernel is bounded .\", \"this is in sharp contrast to kernel methods based on a lipschitz continuous loss function and on a bounded loss function , where results on upper bounds for the maxbias bias and on a bounded influence function are known , see e.g. @xcite for the general case and @xcite for additive models .\", \"therefore , we will here consider the case of regularized kernel based methods based on a general convex and lipschitz continuous loss function , on a general kernel , and on the classical regularizing term @xmath1 for some @xmath2 which is a smoothness penalty but not a sparsity penalty , see e.g. @xcite .\", \"such regularized kernel based methods are now often called support vector machines ( svms ) , although the notation was historically used for such methods based on the special hinge loss function and for special kernels only , we refer to @xcite .    in this paper we address the open question , whether an svm with an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , if the assumption of an additive model is satisfied .\", \"our leading example covers learning rates for quantile regression based on the lipschitz continuous but non - differentiable pinball loss function , which is also called check function in the literature , see e.g. @xcite and @xcite for parametric quantile regression and @xcite , @xcite , and @xcite for kernel based quantile regression .\", \"we will not address the question how to check whether the assumption of an additive model is satisfied because this would be a topic of a paper of its own .\", \"of course , a practical approach might be to fit both models and compare their risks evaluated for test data .\", \"for the same reason we will also not cover sparsity .\", \"consistency of support vector machines generated by additive kernels for additive models was considered in @xcite . in this paper\", \"we establish learning rates for these algorithms .\", \"let us recall the framework with a complete separable metric space @xmath3 as the input space and a closed subset @xmath4 of @xmath5 as the output space .\", \"a borel probability measure @xmath6 on @xmath7 is used to model the learning problem and an independent and identically distributed sample @xmath8 is drawn according to @xmath6 for learning .\", \"a loss function @xmath9 is used to measure the quality of a prediction function @xmath10 by the local error @xmath11 .\", \"_ throughout the paper we assume that @xmath12 is measurable , @xmath13 , convex with respect to the third variable , and uniformly lipschitz continuous satisfying @xmath14 with a finite constant @xmath15 .\", \"_    support vector machines ( svms ) considered here are kernel - based regularization schemes in a reproducing kernel hilbert space ( rkhs ) @xmath0 generated by a mercer kernel @xmath16 . with a shifted loss function @xmath17 introduced for dealing\", \"even with heavy - tailed distributions as @xmath18 , they take the form @xmath19 where for a general borel measure @xmath20 on @xmath21 , the function @xmath22 is defined by @xmath23 where @xmath24 is a regularization parameter .\", \"the idea to shift a loss function has a long history , see e.g. @xcite in the context of m - estimators .\", \"it was shown in @xcite that @xmath22 is also a minimizer of the following optimization problem involving the original loss function @xmath12 if a minimizer exists : @xmath25    the additive model we consider consists of the _ input space decomposition _\", \"@xmath26 with each @xmath27 a complete separable metric space and a _ hypothesis space _\", \"@xmath28 where @xmath29 is a set of functions @xmath30 each of which is also identified as a map @xmath31 from @xmath3 to @xmath5 .\", \"hence the functions from @xmath32 take the additive form @xmath33 .\", \"we mention , that there is strictly speaking a notational problem here , because in the previous formula each quantity @xmath34 is an element of the set @xmath35 which is a subset of the full input space @xmath36 , @xmath37 , whereas in the definition of sample @xmath8 each quantity @xmath38 is an element of the full input space @xmath36 , where @xmath39 .\", \"because these notations will only be used in different places and because we do not expect any misunderstandings , we think this notation is easier and more intuitive than specifying these quantities with different symbols .\", \"the additive kernel @xmath40 is defined in terms of mercer kernels @xmath41 on @xmath27 as @xmath42 it generates an rkhs @xmath0 which can be written in terms of the rkhs @xmath43 generated by @xmath41 on @xmath27 corresponding to the form ( [ additive ] ) as @xmath44 with norm given by @xmath45 the norm of @xmath46 satisfies @xmath47    to illustrate advantages of additive models , we provide two examples of comparing additive with product kernels .\", \"the first example deals with gaussian rbf kernels .\", \"all proofs will be given in section [ proofsection ] .\", \"[ gaussadd ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and @xmath52.\\\\ ] ] the additive kernel @xmath53 is given by @xmath54 furthermore , the product kernel @xmath55 is the standard gaussian kernel given by @xmath56 define a gaussian function @xmath57 on @xmath58 ^ 2 $ ] depending only on one variable by @xmath59 then @xmath60 but @xmath61 where @xmath62 denotes the rkhs generated by the standard gaussian rbf kernel @xmath63 .\", \"the second example is about sobolev kernels .\", \"[ sobolvadd ] let @xmath64 , @xmath65 $ ] and @xmath58^s.$ ] let @xmath66 : = \\\\bigl\\\\{u\\\\in l_2([0,1 ] ) ; d^\\\\alpha u \\\\in l_2([0,1 ] ) \\\\mbox{~for~all~}|\\\\alpha|\\\\le 1\\\\bigr\\\\}\\\\ ] ] be the sobolev space consisting of all square integrable univariate functions whose derivative is also square integrable .\", \"it is an rkhs with a mercer kernel @xmath67 defined on @xmath68 ^ 2 $ ] .\", \"if we take all the mercer kernels @xmath69 to be @xmath67 , then @xmath70 $ ] for each @xmath71 .\", \"the additive kernel @xmath72 is also a mercer kernel and defines an rkhs @xmath73\\\\right\\\\}.\\\\ ] ] however , the multivariate sobolev space @xmath74^s)$ ] , consisting of all square integrable functions whose partial derivatives are all square integrable , contains discontinuous functions and is not an rkhs .\", \"denote the marginal distribution of @xmath6 on @xmath27 as @xmath75 . under the assumption that @xmath76 for each @xmath71 and that @xmath43 is dense in @xmath29 in the @xmath77-metric , it was proved in @xcite that @xmath78 in probability as long as @xmath79 satisfies @xmath80 and @xmath81 .\", \"the rest of the paper has the following structure .\", \"section [ ratessection ] contains our main results on learning rates for svms based on additive kernels . learning rates for quantile regression\", \"are treated as important special cases .\", \"section [ comparisonsection ] contains a comparison of our results with other learning rates published recently .\", \"section [ proofsection ] contains all the proofs and some results which can be interesting in their own .\", \"in this paper we provide some learning rates for the support vector machines generated by additive kernels for additive models which helps improve the quantitative understanding presented in @xcite .\", \"the rates are about asymptotic behaviors of the excess risk @xmath82 and take the form @xmath83 with @xmath84 .\", \"they will be stated under three kinds of conditions involving the hypothesis space @xmath0 , the measure @xmath6 , the loss @xmath12 , and the choice of the regularization parameter @xmath85 .\", \"the first condition is about the approximation ability of the hypothesis space @xmath0 .\", \"since the output function @xmath19 is from the hypothesis space , the learning rates of the learning algorithm depend on the approximation ability of the hypothesis space @xmath0 with respect to the optimal risk @xmath86 measured by the following approximation error .\", \"[ defapprox ] the approximation error of the triple @xmath87 is defined as @xmath88    to estimate the approximation error , we make an assumption about the minimizer of the risk @xmath89    for each @xmath90 , define the integral operator @xmath91 associated with the kernel @xmath41 by @xmath92 we mention that @xmath93 is a compact and positive operator on @xmath94 . hence we can find its normalized eigenpairs @xmath95 such that @xmath96 is an orthonormal basis of @xmath94 and @xmath97 as @xmath98 . fix @xmath99 .\", \"then we can define the @xmath100-th power @xmath101 of @xmath93 by @xmath102 this is a positive and bounded operator and its range is well - defined .\", \"the assumption @xmath103 means @xmath104 lies in this range .\", \"[ assumption1 ] we assume @xmath105 and @xmath106 where for some @xmath107 and each @xmath108 , @xmath109 is a function of the form @xmath110 with some @xmath111 .\", \"the case @xmath112 of assumption [ assumption1 ] means each @xmath113 lies in the rkhs @xmath43 .\", \"a standard condition in the literature ( e.g. , @xcite ) for achieving decays of the form @xmath114 for the approximation error ( [ approxerrordef ] ) is @xmath115 with some @xmath116 . here\", \"the operator @xmath117 is defined by @xmath118 in general , this can not be written in an additive form .\", \"however , the hypothesis space ( [ additive ] ) takes an additive form @xmath119 .\", \"so it is natural for us to impose an additive expression @xmath120 for the target function @xmath121 with the component functions @xmath113 satisfying the power condition @xmath110 .\", \"the above natural assumption leads to a technical difficulty in estimating the approximation error : the function @xmath113 has no direct connection to the marginal distribution @xmath122 projected onto @xmath27 , hence existing methods in the literature ( e.g. , @xcite ) can not be applied directly .\", \"note that on the product space @xmath123 , there is no natural probability measure projected from @xmath6 , and the risk on @xmath124 is not defined .    our idea to overcome the difficulty is to introduce an intermediate function @xmath125 .\", \"it may not minimize a risk ( which is not even defined ) .\", \"however , it approximates the component function @xmath113 well .\", \"when we add up such functions @xmath126 , we get a good approximation of the target function @xmath121 , and thereby a good estimate of the approximation error .\", \"this is the first novelty of the paper .\", \"[ approxerrorthm ] under assumption [ assumption1 ] , we have @xmath127 where @xmath128 is the constant given by @xmath129      the second condition for our learning rates is about the capacity of the hypothesis space measured by @xmath130-empirical covering numbers .    let @xmath131 be a set of functions on @xmath21 and @xmath132 for every @xmath133 the * covering number of @xmath131 * with respect to the empirical metric @xmath134 , given by @xmath135 is defined as @xmath136 and the * @xmath130-empirical covering number * of @xmath137 is defined as @xmath138    [ assumption2 ] we assume @xmath139 and that for some @xmath140 , @xmath141 and every @xmath142 , the @xmath130-empirical covering number of the unit ball of @xmath43 satisfies @xmath143    the second novelty of this paper is to observe that the additive nature of the hypothesis space yields the following nice bound with a dimension - independent power exponent for the covering numbers of the balls of the hypothesis space @xmath0 , to be proved in section [ samplesection ] .\", \"[ capacitythm ] under assumption [ assumption2 ] , for any @xmath144 and @xmath145 , we have @xmath146    the bound for the covering numbers stated in theorem [ capacitythm ] is special : the power @xmath147 is independent of the number @xmath148 of the components in the additive model .\", \"it is well - known @xcite in the literature of function spaces that the covering numbers of balls of the sobolev space @xmath149 on the cube @xmath150^s$ ] of the euclidean space @xmath151 with regularity index @xmath152 has the following asymptotic behavior with @xmath153 : @xmath154 here the power @xmath155 depends linearly on the dimension @xmath148 .\", \"similar dimension - dependent bounds for the covering numbers of the rkhss associated with gaussian rbf - kernels can be found in @xcite .\", \"the special bound in theorem [ capacitythm ] demonstrates an advantage of the additive model in terms of capacity of the additive hypothesis space .\", \"the third condition for our learning rates is about the noise level in the measure @xmath6 with respect to the hypothesis space . before stating the general condition\", \", we consider a special case for quantile regression , to illustrate our general results .\", \"let @xmath156 be a quantile parameter .\", \"the quantile regression function @xmath157 is defined by its value @xmath158 to be a @xmath159-quantile of @xmath160 , i.e. , a value @xmath161 satisfying @xmath162 the regularization scheme for quantile regression considered here takes the form ( [ algor ] ) with the loss function @xmath12 given by the pinball loss as @xmath163    a noise condition on @xmath6 for quantile regression is defined in @xcite as follows . to this end , let @xmath164 be a probability measure on @xmath165 and @xmath166 . then a real number @xmath167 is called @xmath159-quantile of @xmath164 , if and only if @xmath167 belongs to the set @xmath168\\\\bigr ) \\\\ge\", \"\\\\tau     \\\\mbox{~~and~~ } q\\\\bigl([t , \\\\infty)\\\\bigr ) \\\\ge 1-\\\\tau\\\\bigr\\\\}\\\\,.\\\\ ] ] it is well - known that @xmath169 is a compact interval .\", \"[ noisecond ] let @xmath166 .    1 .\", \"a probability measure @xmath164 on @xmath165 is said to have a * @xmath159-quantile of type @xmath170 * , if there exist a @xmath159-quantile @xmath171 and a constant @xmath172 such that , for all @xmath173 $ ] , we have @xmath174 2 .\", \"let @xmath175 $ ] .\", \"we say that a probability measure @xmath20 on @xmath176 has a * @xmath159-quantile of @xmath177-average type @xmath170 * if the conditional probability measure @xmath178 has @xmath179-almost surely a @xmath159-quantile of type @xmath170 and the function @xmath180 where @xmath181 is the constant defined in part ( 1 ) , satisfies @xmath182 .\", \"one can show that a distribution @xmath164 having a @xmath159-quantile of type @xmath170 has a unique @xmath159-quantile @xmath183 .\", \"moreover , if @xmath164 has a lebesgue density @xmath184 then @xmath164 has a @xmath159-quantile of type @xmath170 if @xmath184 is bounded away from zero on @xmath185 $ ] since we can use @xmath186\\\\}$ ] in ( [ tauquantileoftype2formula ] ) .\", \"this assumption is general enough to cover many distributions used in parametric statistics such as gaussian , student s @xmath187 , and logistic distributions ( with @xmath188 ) , gamma and log - normal distributions ( with @xmath189 ) , and uniform and beta distributions ( with @xmath190 $ ] ) .\", \"the following theorem , to be proved in section [ proofsection ] , gives a learning rate for the regularization scheme ( [ algor ] ) in the special case of quantile regression .\", \"[ quantilethm ] suppose that @xmath191 almost surely for some constant @xmath192 , and that each kernel @xmath41 is @xmath193 with @xmath194 for some @xmath195 .\", \"if assumption [ assumption1 ] holds with @xmath112 and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath198 and @xmath199 , with confidence at least @xmath200 we have @xmath201 where @xmath202 is a constant independent of @xmath203 and @xmath204 and @xmath205    please note that the exponent @xmath206 given by ( [ quantilerates2 ] ) for the learning rate in ( [ quantilerates ] ) is independent of the quantile level @xmath159 , of the number @xmath148 of additive components in @xmath207 , and of the dimensions @xmath208 and @xmath209 further note that @xmath210 , if @xmath211 , and @xmath212 if @xmath213 . because @xmath214 can be arbitrarily close to @xmath215 , the learning rate , which is independent of the dimension @xmath216 and given by theorem [ quantilethm ] , is close to @xmath217 for large values of @xmath177 and is close to @xmath218 or better , if @xmath211 .      to state our general learning rates\", \", we need an assumption on a _ variance - expectation bound _ which is similar to definition [ noisecond ] in the special case of quantile regression .\", \"[ assumption3 ] we assume that there exist an exponent @xmath219 $ ] and a positive constant @xmath220 such that @xmath221    assumption [ assumption3 ] always holds true for @xmath222 . if the triple @xmath223 satisfies some conditions , the exponent @xmath224 can be larger .\", \"for example , when @xmath12 is the pinball loss ( [ pinloss ] ) and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath225 for some @xmath196 $ ] and @xmath226 as defined in @xcite , then @xmath227 .\", \"[ mainratesthm ] suppose that @xmath228 is bounded by a constant @xmath229 almost surely . under assumptions [ assumption1 ] to [ assumption3 ] ,\", \"if we take @xmath198 and @xmath230 for some @xmath231 , then for any @xmath232 , with confidence at least @xmath200 we have @xmath233 where @xmath234 is given by @xmath235 and @xmath202 is constant independent of @xmath203 or @xmath204 ( to be given explicitly in the proof ) .\", \"we now add some theoretical and numerical comparisons on the goodness of our learning rates with those from the literature . as already mentioned in the introduction\", \", some reasons for the popularity of additive models are flexibility , increased interpretability , and ( often ) a reduced proneness of the curse of high dimensions .\", \"hence it is important to check , whether the learning rate given in theorem [ mainratesthm ] under the assumption of an additive model favourably compares to ( essentially ) optimal learning rates without this assumption . in other words ,\", \"we need to demonstrate that the main goal of this paper is achieved by theorem [ quantilethm ] and theorem [ mainratesthm ] , i.e. that an svm based on an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , provided the assumption of an additive model is satisfied .\", \"our learning rate in theorem [ quantilethm ] is new and optimal in the literature of svm for quantile regression .\", \"most learning rates in the literature of svm for quantile regression are given for projected output functions @xmath236 , while it is well known that projections improve learning rates @xcite . here the projection operator @xmath237 is defined for any measurable function @xmath10 by @xmath238 sometimes this is called clipping .\", \"such results are given in @xcite .\", \"for example , under the assumptions that @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , the approximation error condition ( [ approxerrorb ] ) is satisfied for some @xmath239 , and that for some constants @xmath240 , the sequence of eigenvalues @xmath241 of the integral operator @xmath117 satisfies @xmath242 for every @xmath243 , it was shown in @xcite that with confidence at least @xmath200 , @xmath244 where @xmath245 here the parameter @xmath246 measures the capacity of the rkhs @xmath247 and it plays a similar role as half of the parameter @xmath147 in assumption 2 . for a @xmath193 kernel and @xmath112\", \", one can choose @xmath246 and @xmath147 to be arbitrarily small and the above power index @xmath248 can be taken as @xmath249 .\", \"the learning rate in theorem [ quantilethm ] may be improved by relaxing assumption 1 to a sobolev smoothness condition for @xmath121 and a regularity condition for the marginal distribution @xmath250 .\", \"for example , one may use a gaussian kernel @xmath251 depending on the sample size @xmath203 and @xcite achieve the approximation error condition ( [ approxerrorb ] ) for some @xmath252 .\", \"this is done for quantile regression in @xcite .\", \"since we are mainly interested in additive models , we shall not discuss such an extension .\", \"[ gaussmore ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and the additive kernel @xmath72 be given by ( [ gaussaddform ] ) with @xmath253 in example [ gaussadd ] as @xmath52.\\\\ ] ] if the function @xmath121 is given by ( [ gaussfcn ] ) , @xmath191 almost surely for some constant @xmath192 , and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath145 and @xmath199 , ( [ quantilerates ] ) holds with confidence at least @xmath200 .    it is unknown whether the above learning rate can be derived by existing approaches in the literature ( e.g. @xcite ) even after projection .\", \"note that the kernel in the above example is independent of the sample size .\", \"it would be interesting to see whether there exists some @xmath99 such that the function @xmath57 defined by ( [ gaussfcn ] ) lies in the range of the operator @xmath254 .\", \"the existence of such a positive index would lead to the approximation error condition ( [ approxerrorb ] ) , see @xcite .    let us now add some numerical comparisons on the goodness of our learning rates given by theorem [ mainratesthm ] with those given by @xcite .\", \"their corollary 4.12 gives ( essentially ) minmax optimal learning rates for ( clipped ) svms in the context of nonparametric quantile regression using one gaussian rbf kernel on the whole input space under appropriate smoothness assumptions of the target function .\", \"let us consider the case that the distribution @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , where @xmath255 , and assume that both corollary 4.12 in @xcite and our theorem [ mainratesthm ] are applicable .\", \"i.e. , we assume in particular that @xmath6 is a probability measure on @xmath256 $ ] and that the marginal distribution @xmath257 has a lebesgue density @xmath258 for some @xmath259 . furthermore , suppose that the optimal decision function @xmath260 has ( to make theorem [ mainratesthm ] applicable with @xmath261 $ ] ) the additive structure @xmath207 with each @xmath104 as stated in assumption [ assumption1 ] , where @xmath262 and @xmath263 , with minimal risk @xmath86 and additionally fulfills ( to make corollary 4.12 in @xcite applicable ) @xmath264 where @xmath265 $ ] and @xmath266 denotes a besov space with smoothness parameter @xmath267 .\", \"the intuitive meaning of @xmath248 is , that increasing values of @xmath248 correspond to increased smoothness .\", \"we refer to ( * ? ? ? * and p. 44 ) for details on besov spaces .\", \"it is well - known that the besov space @xmath268 contains the sobolev space @xmath269 for @xmath270 , @xmath271 , and @xmath272 , and that @xmath273 .\", \"we mention that if all @xmath41 are suitably chosen wendland kernels , their reproducing kernel hilbert spaces @xmath43 are sobolev spaces , see ( * ? ? ?\", \"* thm . 10.35 , p. 160 ) .\", \"furthermore , we use the same sequence of regularizing parameters as in ( * ? ? ?\", \"4.9 , cor . 4.12 ) , i.e. , @xmath274 where @xmath275 , @xmath276 , @xmath277 $ ] , and @xmath278 is some user - defined positive constant independent of @xmath279 . for\", \"reasons of simplicity , let us fix @xmath280 .\", \"then ( * ? ? ?\", \"4.12 ) gives learning rates for the risk of svms for @xmath159-quantile regression , if a single gaussian rbf - kernel on @xmath281 is used for @xmath159-quantile functions of @xmath177-average type @xmath170 with @xmath255 , which are of order @xmath282 hence the learning rate in theorem [ quantilethm ] is better than the one in ( * ? ? ?\", \"4.12 ) in this situation , if @xmath283 provided the assumption of the additive model is valid .\", \"table [ table1 ] lists the values of @xmath284 from ( [ explicitratescz2 ] ) for some finite values of the dimension @xmath216 , where @xmath285 .\", \"all of these values of @xmath284 are positive with the exceptions if @xmath286 or @xmath287 .\", \"this is in contrast to the corresponding exponent in the learning rate by ( * ? ?\", \"* cor . 4.12 ) , because @xmath288    table [ table2 ] and figures [ figure1 ] to [ figure2 ] give additional information on the limit @xmath289 .\", \"of course , higher values of the exponent indicates faster rates of convergence .\", \"it is obvious , that an svm based on an additive kernel has a significantly faster rate of convergence in higher dimensions @xmath216 compared to svm based on a single gaussian rbf kernel defined on the whole input space , of course under the assumption that the additive model is valid .\", \"the figures seem to indicate that our learning rate from theorem [ mainratesthm ] is probably not optimal for small dimensions . however , the main focus of the present paper is on high dimensions .\", \".[table1 ] the table lists the limits of the exponents @xmath290 from ( * ? ? ?\", \"* cor . 4.12 ) and @xmath291 from theorem [ mainratesthm ] , respectively , if the regularizing parameter @xmath292 is chosen in an optimal manner for the nonparametric setup , i.e. @xmath293 , with @xmath294 for @xmath295 and @xmath296 .\", \"recall that @xmath297 $ ] .\", \"[ cols= \\\" > , > , > , > \\\" , ]\"], \"abstract_text\": [\"<S> additive models play an important role in semiparametric statistics . </S>\", \"<S> this paper gives learning rates for regularized kernel based methods for additive models . </S>\", \"<S> these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . </S>\", \"<S> additionally , a concrete example is presented to show that a gaussian function depending only on one variable lies in a reproducing kernel hilbert space generated by an additive gaussian kernel , but does not belong to the reproducing kernel hilbert space generated by the multivariate gaussian kernel of the same variance .    * </S>\", \"<S> key words and phrases . * additive model , kernel , quantile regression , semiparametric , rate of convergence , support vector machine . </S>\"], \"labels\":[], \"section_names\": [\"introduction\", \"main results on learning rates\", \"comparison of learning rates\"], \"sections\": [[\"additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models .\", \"it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models .\", \"many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space @xmath0 , see e.g. @xcite . in the last years\", \"many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g. @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and the references therein . of course , the least squares loss function is differentiable and has many nice mathematical properties , but it is only locally lipschitz continuous and therefore regularized kernel based methods based on this loss function typically suffer on bad statistical robustness properties , even if the kernel is bounded .\", \"this is in sharp contrast to kernel methods based on a lipschitz continuous loss function and on a bounded loss function , where results on upper bounds for the maxbias bias and on a bounded influence function are known , see e.g. @xcite for the general case and @xcite for additive models .\", \"therefore , we will here consider the case of regularized kernel based methods based on a general convex and lipschitz continuous loss function , on a general kernel , and on the classical regularizing term @xmath1 for some @xmath2 which is a smoothness penalty but not a sparsity penalty , see e.g. @xcite .\", \"such regularized kernel based methods are now often called support vector machines ( svms ) , although the notation was historically used for such methods based on the special hinge loss function and for special kernels only , we refer to @xcite .    in this paper we address the open question , whether an svm with an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , if the assumption of an additive model is satisfied .\", \"our leading example covers learning rates for quantile regression based on the lipschitz continuous but non - differentiable pinball loss function , which is also called check function in the literature , see e.g. @xcite and @xcite for parametric quantile regression and @xcite , @xcite , and @xcite for kernel based quantile regression .\", \"we will not address the question how to check whether the assumption of an additive model is satisfied because this would be a topic of a paper of its own .\", \"of course , a practical approach might be to fit both models and compare their risks evaluated for test data .\", \"for the same reason we will also not cover sparsity .\", \"consistency of support vector machines generated by additive kernels for additive models was considered in @xcite . in this paper\", \"we establish learning rates for these algorithms .\", \"let us recall the framework with a complete separable metric space @xmath3 as the input space and a closed subset @xmath4 of @xmath5 as the output space .\", \"a borel probability measure @xmath6 on @xmath7 is used to model the learning problem and an independent and identically distributed sample @xmath8 is drawn according to @xmath6 for learning .\", \"a loss function @xmath9 is used to measure the quality of a prediction function @xmath10 by the local error @xmath11 .\", \"_ throughout the paper we assume that @xmath12 is measurable , @xmath13 , convex with respect to the third variable , and uniformly lipschitz continuous satisfying @xmath14 with a finite constant @xmath15 .\", \"_    support vector machines ( svms ) considered here are kernel - based regularization schemes in a reproducing kernel hilbert space ( rkhs ) @xmath0 generated by a mercer kernel @xmath16 . with a shifted loss function @xmath17 introduced for dealing\", \"even with heavy - tailed distributions as @xmath18 , they take the form @xmath19 where for a general borel measure @xmath20 on @xmath21 , the function @xmath22 is defined by @xmath23 where @xmath24 is a regularization parameter .\", \"the idea to shift a loss function has a long history , see e.g. @xcite in the context of m - estimators .\", \"it was shown in @xcite that @xmath22 is also a minimizer of the following optimization problem involving the original loss function @xmath12 if a minimizer exists : @xmath25    the additive model we consider consists of the _ input space decomposition _\", \"@xmath26 with each @xmath27 a complete separable metric space and a _ hypothesis space _\", \"@xmath28 where @xmath29 is a set of functions @xmath30 each of which is also identified as a map @xmath31 from @xmath3 to @xmath5 .\", \"hence the functions from @xmath32 take the additive form @xmath33 .\", \"we mention , that there is strictly speaking a notational problem here , because in the previous formula each quantity @xmath34 is an element of the set @xmath35 which is a subset of the full input space @xmath36 , @xmath37 , whereas in the definition of sample @xmath8 each quantity @xmath38 is an element of the full input space @xmath36 , where @xmath39 .\", \"because these notations will only be used in different places and because we do not expect any misunderstandings , we think this notation is easier and more intuitive than specifying these quantities with different symbols .\", \"the additive kernel @xmath40 is defined in terms of mercer kernels @xmath41 on @xmath27 as @xmath42 it generates an rkhs @xmath0 which can be written in terms of the rkhs @xmath43 generated by @xmath41 on @xmath27 corresponding to the form ( [ additive ] ) as @xmath44 with norm given by @xmath45 the norm of @xmath46 satisfies @xmath47    to illustrate advantages of additive models , we provide two examples of comparing additive with product kernels .\", \"the first example deals with gaussian rbf kernels .\", \"all proofs will be given in section [ proofsection ] .\", \"[ gaussadd ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and @xmath52.\\\\ ] ] the additive kernel @xmath53 is given by @xmath54 furthermore , the product kernel @xmath55 is the standard gaussian kernel given by @xmath56 define a gaussian function @xmath57 on @xmath58 ^ 2 $ ] depending only on one variable by @xmath59 then @xmath60 but @xmath61 where @xmath62 denotes the rkhs generated by the standard gaussian rbf kernel @xmath63 .\", \"the second example is about sobolev kernels .\", \"[ sobolvadd ] let @xmath64 , @xmath65 $ ] and @xmath58^s.$ ] let @xmath66 : = \\\\bigl\\\\{u\\\\in l_2([0,1 ] ) ; d^\\\\alpha u \\\\in l_2([0,1 ] ) \\\\mbox{~for~all~}|\\\\alpha|\\\\le 1\\\\bigr\\\\}\\\\ ] ] be the sobolev space consisting of all square integrable univariate functions whose derivative is also square integrable .\", \"it is an rkhs with a mercer kernel @xmath67 defined on @xmath68 ^ 2 $ ] .\", \"if we take all the mercer kernels @xmath69 to be @xmath67 , then @xmath70 $ ] for each @xmath71 .\", \"the additive kernel @xmath72 is also a mercer kernel and defines an rkhs @xmath73\\\\right\\\\}.\\\\ ] ] however , the multivariate sobolev space @xmath74^s)$ ] , consisting of all square integrable functions whose partial derivatives are all square integrable , contains discontinuous functions and is not an rkhs .\", \"denote the marginal distribution of @xmath6 on @xmath27 as @xmath75 . under the assumption that @xmath76 for each @xmath71 and that @xmath43 is dense in @xmath29 in the @xmath77-metric , it was proved in @xcite that @xmath78 in probability as long as @xmath79 satisfies @xmath80 and @xmath81 .\", \"the rest of the paper has the following structure .\", \"section [ ratessection ] contains our main results on learning rates for svms based on additive kernels . learning rates for quantile regression\", \"are treated as important special cases .\", \"section [ comparisonsection ] contains a comparison of our results with other learning rates published recently .\", \"section [ proofsection ] contains all the proofs and some results which can be interesting in their own .\"], [\"in this paper we provide some learning rates for the support vector machines generated by additive kernels for additive models which helps improve the quantitative understanding presented in @xcite .\", \"the rates are about asymptotic behaviors of the excess risk @xmath82 and take the form @xmath83 with @xmath84 .\", \"they will be stated under three kinds of conditions involving the hypothesis space @xmath0 , the measure @xmath6 , the loss @xmath12 , and the choice of the regularization parameter @xmath85 .\", \"the first condition is about the approximation ability of the hypothesis space @xmath0 .\", \"since the output function @xmath19 is from the hypothesis space , the learning rates of the learning algorithm depend on the approximation ability of the hypothesis space @xmath0 with respect to the optimal risk @xmath86 measured by the following approximation error .\", \"[ defapprox ] the approximation error of the triple @xmath87 is defined as @xmath88    to estimate the approximation error , we make an assumption about the minimizer of the risk @xmath89    for each @xmath90 , define the integral operator @xmath91 associated with the kernel @xmath41 by @xmath92 we mention that @xmath93 is a compact and positive operator on @xmath94 . hence we can find its normalized eigenpairs @xmath95 such that @xmath96 is an orthonormal basis of @xmath94 and @xmath97 as @xmath98 . fix @xmath99 .\", \"then we can define the @xmath100-th power @xmath101 of @xmath93 by @xmath102 this is a positive and bounded operator and its range is well - defined .\", \"the assumption @xmath103 means @xmath104 lies in this range .\", \"[ assumption1 ] we assume @xmath105 and @xmath106 where for some @xmath107 and each @xmath108 , @xmath109 is a function of the form @xmath110 with some @xmath111 .\", \"the case @xmath112 of assumption [ assumption1 ] means each @xmath113 lies in the rkhs @xmath43 .\", \"a standard condition in the literature ( e.g. , @xcite ) for achieving decays of the form @xmath114 for the approximation error ( [ approxerrordef ] ) is @xmath115 with some @xmath116 . here\", \"the operator @xmath117 is defined by @xmath118 in general , this can not be written in an additive form .\", \"however , the hypothesis space ( [ additive ] ) takes an additive form @xmath119 .\", \"so it is natural for us to impose an additive expression @xmath120 for the target function @xmath121 with the component functions @xmath113 satisfying the power condition @xmath110 .\", \"the above natural assumption leads to a technical difficulty in estimating the approximation error : the function @xmath113 has no direct connection to the marginal distribution @xmath122 projected onto @xmath27 , hence existing methods in the literature ( e.g. , @xcite ) can not be applied directly .\", \"note that on the product space @xmath123 , there is no natural probability measure projected from @xmath6 , and the risk on @xmath124 is not defined .    our idea to overcome the difficulty is to introduce an intermediate function @xmath125 .\", \"it may not minimize a risk ( which is not even defined ) .\", \"however , it approximates the component function @xmath113 well .\", \"when we add up such functions @xmath126 , we get a good approximation of the target function @xmath121 , and thereby a good estimate of the approximation error .\", \"this is the first novelty of the paper .\", \"[ approxerrorthm ] under assumption [ assumption1 ] , we have @xmath127 where @xmath128 is the constant given by @xmath129      the second condition for our learning rates is about the capacity of the hypothesis space measured by @xmath130-empirical covering numbers .    let @xmath131 be a set of functions on @xmath21 and @xmath132 for every @xmath133 the * covering number of @xmath131 * with respect to the empirical metric @xmath134 , given by @xmath135 is defined as @xmath136 and the * @xmath130-empirical covering number * of @xmath137 is defined as @xmath138    [ assumption2 ] we assume @xmath139 and that for some @xmath140 , @xmath141 and every @xmath142 , the @xmath130-empirical covering number of the unit ball of @xmath43 satisfies @xmath143    the second novelty of this paper is to observe that the additive nature of the hypothesis space yields the following nice bound with a dimension - independent power exponent for the covering numbers of the balls of the hypothesis space @xmath0 , to be proved in section [ samplesection ] .\", \"[ capacitythm ] under assumption [ assumption2 ] , for any @xmath144 and @xmath145 , we have @xmath146    the bound for the covering numbers stated in theorem [ capacitythm ] is special : the power @xmath147 is independent of the number @xmath148 of the components in the additive model .\", \"it is well - known @xcite in the literature of function spaces that the covering numbers of balls of the sobolev space @xmath149 on the cube @xmath150^s$ ] of the euclidean space @xmath151 with regularity index @xmath152 has the following asymptotic behavior with @xmath153 : @xmath154 here the power @xmath155 depends linearly on the dimension @xmath148 .\", \"similar dimension - dependent bounds for the covering numbers of the rkhss associated with gaussian rbf - kernels can be found in @xcite .\", \"the special bound in theorem [ capacitythm ] demonstrates an advantage of the additive model in terms of capacity of the additive hypothesis space .\", \"the third condition for our learning rates is about the noise level in the measure @xmath6 with respect to the hypothesis space . before stating the general condition\", \", we consider a special case for quantile regression , to illustrate our general results .\", \"let @xmath156 be a quantile parameter .\", \"the quantile regression function @xmath157 is defined by its value @xmath158 to be a @xmath159-quantile of @xmath160 , i.e. , a value @xmath161 satisfying @xmath162 the regularization scheme for quantile regression considered here takes the form ( [ algor ] ) with the loss function @xmath12 given by the pinball loss as @xmath163    a noise condition on @xmath6 for quantile regression is defined in @xcite as follows . to this end , let @xmath164 be a probability measure on @xmath165 and @xmath166 . then a real number @xmath167 is called @xmath159-quantile of @xmath164 , if and only if @xmath167 belongs to the set @xmath168\\\\bigr ) \\\\ge\", \"\\\\tau     \\\\mbox{~~and~~ } q\\\\bigl([t , \\\\infty)\\\\bigr ) \\\\ge 1-\\\\tau\\\\bigr\\\\}\\\\,.\\\\ ] ] it is well - known that @xmath169 is a compact interval .\", \"[ noisecond ] let @xmath166 .    1 .\", \"a probability measure @xmath164 on @xmath165 is said to have a * @xmath159-quantile of type @xmath170 * , if there exist a @xmath159-quantile @xmath171 and a constant @xmath172 such that , for all @xmath173 $ ] , we have @xmath174 2 .\", \"let @xmath175 $ ] .\", \"we say that a probability measure @xmath20 on @xmath176 has a * @xmath159-quantile of @xmath177-average type @xmath170 * if the conditional probability measure @xmath178 has @xmath179-almost surely a @xmath159-quantile of type @xmath170 and the function @xmath180 where @xmath181 is the constant defined in part ( 1 ) , satisfies @xmath182 .\", \"one can show that a distribution @xmath164 having a @xmath159-quantile of type @xmath170 has a unique @xmath159-quantile @xmath183 .\", \"moreover , if @xmath164 has a lebesgue density @xmath184 then @xmath164 has a @xmath159-quantile of type @xmath170 if @xmath184 is bounded away from zero on @xmath185 $ ] since we can use @xmath186\\\\}$ ] in ( [ tauquantileoftype2formula ] ) .\", \"this assumption is general enough to cover many distributions used in parametric statistics such as gaussian , student s @xmath187 , and logistic distributions ( with @xmath188 ) , gamma and log - normal distributions ( with @xmath189 ) , and uniform and beta distributions ( with @xmath190 $ ] ) .\", \"the following theorem , to be proved in section [ proofsection ] , gives a learning rate for the regularization scheme ( [ algor ] ) in the special case of quantile regression .\", \"[ quantilethm ] suppose that @xmath191 almost surely for some constant @xmath192 , and that each kernel @xmath41 is @xmath193 with @xmath194 for some @xmath195 .\", \"if assumption [ assumption1 ] holds with @xmath112 and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath198 and @xmath199 , with confidence at least @xmath200 we have @xmath201 where @xmath202 is a constant independent of @xmath203 and @xmath204 and @xmath205    please note that the exponent @xmath206 given by ( [ quantilerates2 ] ) for the learning rate in ( [ quantilerates ] ) is independent of the quantile level @xmath159 , of the number @xmath148 of additive components in @xmath207 , and of the dimensions @xmath208 and @xmath209 further note that @xmath210 , if @xmath211 , and @xmath212 if @xmath213 . because @xmath214 can be arbitrarily close to @xmath215 , the learning rate , which is independent of the dimension @xmath216 and given by theorem [ quantilethm ] , is close to @xmath217 for large values of @xmath177 and is close to @xmath218 or better , if @xmath211 .      to state our general learning rates\", \", we need an assumption on a _ variance - expectation bound _ which is similar to definition [ noisecond ] in the special case of quantile regression .\", \"[ assumption3 ] we assume that there exist an exponent @xmath219 $ ] and a positive constant @xmath220 such that @xmath221    assumption [ assumption3 ] always holds true for @xmath222 . if the triple @xmath223 satisfies some conditions , the exponent @xmath224 can be larger .\", \"for example , when @xmath12 is the pinball loss ( [ pinloss ] ) and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath225 for some @xmath196 $ ] and @xmath226 as defined in @xcite , then @xmath227 .\", \"[ mainratesthm ] suppose that @xmath228 is bounded by a constant @xmath229 almost surely . under assumptions [ assumption1 ] to [ assumption3 ] ,\", \"if we take @xmath198 and @xmath230 for some @xmath231 , then for any @xmath232 , with confidence at least @xmath200 we have @xmath233 where @xmath234 is given by @xmath235 and @xmath202 is constant independent of @xmath203 or @xmath204 ( to be given explicitly in the proof ) .\"], [\"we now add some theoretical and numerical comparisons on the goodness of our learning rates with those from the literature . as already mentioned in the introduction\", \", some reasons for the popularity of additive models are flexibility , increased interpretability , and ( often ) a reduced proneness of the curse of high dimensions .\", \"hence it is important to check , whether the learning rate given in theorem [ mainratesthm ] under the assumption of an additive model favourably compares to ( essentially ) optimal learning rates without this assumption . in other words ,\", \"we need to demonstrate that the main goal of this paper is achieved by theorem [ quantilethm ] and theorem [ mainratesthm ] , i.e. that an svm based on an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , provided the assumption of an additive model is satisfied .\", \"our learning rate in theorem [ quantilethm ] is new and optimal in the literature of svm for quantile regression .\", \"most learning rates in the literature of svm for quantile regression are given for projected output functions @xmath236 , while it is well known that projections improve learning rates @xcite . here the projection operator @xmath237 is defined for any measurable function @xmath10 by @xmath238 sometimes this is called clipping .\", \"such results are given in @xcite .\", \"for example , under the assumptions that @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , the approximation error condition ( [ approxerrorb ] ) is satisfied for some @xmath239 , and that for some constants @xmath240 , the sequence of eigenvalues @xmath241 of the integral operator @xmath117 satisfies @xmath242 for every @xmath243 , it was shown in @xcite that with confidence at least @xmath200 , @xmath244 where @xmath245 here the parameter @xmath246 measures the capacity of the rkhs @xmath247 and it plays a similar role as half of the parameter @xmath147 in assumption 2 . for a @xmath193 kernel and @xmath112\", \", one can choose @xmath246 and @xmath147 to be arbitrarily small and the above power index @xmath248 can be taken as @xmath249 .\", \"the learning rate in theorem [ quantilethm ] may be improved by relaxing assumption 1 to a sobolev smoothness condition for @xmath121 and a regularity condition for the marginal distribution @xmath250 .\", \"for example , one may use a gaussian kernel @xmath251 depending on the sample size @xmath203 and @xcite achieve the approximation error condition ( [ approxerrorb ] ) for some @xmath252 .\", \"this is done for quantile regression in @xcite .\", \"since we are mainly interested in additive models , we shall not discuss such an extension .\", \"[ gaussmore ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and the additive kernel @xmath72 be given by ( [ gaussaddform ] ) with @xmath253 in example [ gaussadd ] as @xmath52.\\\\ ] ] if the function @xmath121 is given by ( [ gaussfcn ] ) , @xmath191 almost surely for some constant @xmath192 , and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath145 and @xmath199 , ( [ quantilerates ] ) holds with confidence at least @xmath200 .    it is unknown whether the above learning rate can be derived by existing approaches in the literature ( e.g. @xcite ) even after projection .\", \"note that the kernel in the above example is independent of the sample size .\", \"it would be interesting to see whether there exists some @xmath99 such that the function @xmath57 defined by ( [ gaussfcn ] ) lies in the range of the operator @xmath254 .\", \"the existence of such a positive index would lead to the approximation error condition ( [ approxerrorb ] ) , see @xcite .    let us now add some numerical comparisons on the goodness of our learning rates given by theorem [ mainratesthm ] with those given by @xcite .\", \"their corollary 4.12 gives ( essentially ) minmax optimal learning rates for ( clipped ) svms in the context of nonparametric quantile regression using one gaussian rbf kernel on the whole input space under appropriate smoothness assumptions of the target function .\", \"let us consider the case that the distribution @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , where @xmath255 , and assume that both corollary 4.12 in @xcite and our theorem [ mainratesthm ] are applicable .\", \"i.e. , we assume in particular that @xmath6 is a probability measure on @xmath256 $ ] and that the marginal distribution @xmath257 has a lebesgue density @xmath258 for some @xmath259 . furthermore , suppose that the optimal decision function @xmath260 has ( to make theorem [ mainratesthm ] applicable with @xmath261 $ ] ) the additive structure @xmath207 with each @xmath104 as stated in assumption [ assumption1 ] , where @xmath262 and @xmath263 , with minimal risk @xmath86 and additionally fulfills ( to make corollary 4.12 in @xcite applicable ) @xmath264 where @xmath265 $ ] and @xmath266 denotes a besov space with smoothness parameter @xmath267 .\", \"the intuitive meaning of @xmath248 is , that increasing values of @xmath248 correspond to increased smoothness .\", \"we refer to ( * ? ? ? * and p. 44 ) for details on besov spaces .\", \"it is well - known that the besov space @xmath268 contains the sobolev space @xmath269 for @xmath270 , @xmath271 , and @xmath272 , and that @xmath273 .\", \"we mention that if all @xmath41 are suitably chosen wendland kernels , their reproducing kernel hilbert spaces @xmath43 are sobolev spaces , see ( * ? ? ?\", \"* thm . 10.35 , p. 160 ) .\", \"furthermore , we use the same sequence of regularizing parameters as in ( * ? ? ?\", \"4.9 , cor . 4.12 ) , i.e. , @xmath274 where @xmath275 , @xmath276 , @xmath277 $ ] , and @xmath278 is some user - defined positive constant independent of @xmath279 . for\", \"reasons of simplicity , let us fix @xmath280 .\", \"then ( * ? ? ?\", \"4.12 ) gives learning rates for the risk of svms for @xmath159-quantile regression , if a single gaussian rbf - kernel on @xmath281 is used for @xmath159-quantile functions of @xmath177-average type @xmath170 with @xmath255 , which are of order @xmath282 hence the learning rate in theorem [ quantilethm ] is better than the one in ( * ? ? ?\", \"4.12 ) in this situation , if @xmath283 provided the assumption of the additive model is valid .\", \"table [ table1 ] lists the values of @xmath284 from ( [ explicitratescz2 ] ) for some finite values of the dimension @xmath216 , where @xmath285 .\", \"all of these values of @xmath284 are positive with the exceptions if @xmath286 or @xmath287 .\", \"this is in contrast to the corresponding exponent in the learning rate by ( * ? ?\", \"* cor . 4.12 ) , because @xmath288    table [ table2 ] and figures [ figure1 ] to [ figure2 ] give additional information on the limit @xmath289 .\", \"of course , higher values of the exponent indicates faster rates of convergence .\", \"it is obvious , that an svm based on an additive kernel has a significantly faster rate of convergence in higher dimensions @xmath216 compared to svm based on a single gaussian rbf kernel defined on the whole input space , of course under the assumption that the additive model is valid .\", \"the figures seem to indicate that our learning rate from theorem [ mainratesthm ] is probably not optimal for small dimensions . however , the main focus of the present paper is on high dimensions .\", \".[table1 ] the table lists the limits of the exponents @xmath290 from ( * ? ? ?\", \"* cor . 4.12 ) and @xmath291 from theorem [ mainratesthm ] , respectively , if the regularizing parameter @xmath292 is chosen in an optimal manner for the nonparametric setup , i.e. @xmath293 , with @xmath294 for @xmath295 and @xmath296 .\", \"recall that @xmath297 $ ] .\", \"[ cols= \\\" > , > , > , > \\\" , ]\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a395e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models .',\n",
       " 'it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models .',\n",
       " 'many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space @xmath0 , see e.g. @xcite . in the last years',\n",
       " 'many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g. @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and the references therein . of course , the least squares loss function is differentiable and has many nice mathematical properties , but it is only locally lipschitz continuous and therefore regularized kernel based methods based on this loss function typically suffer on bad statistical robustness properties , even if the kernel is bounded .',\n",
       " 'this is in sharp contrast to kernel methods based on a lipschitz continuous loss function and on a bounded loss function , where results on upper bounds for the maxbias bias and on a bounded influence function are known , see e.g. @xcite for the general case and @xcite for additive models .',\n",
       " 'therefore , we will here consider the case of regularized kernel based methods based on a general convex and lipschitz continuous loss function , on a general kernel , and on the classical regularizing term @xmath1 for some @xmath2 which is a smoothness penalty but not a sparsity penalty , see e.g. @xcite .',\n",
       " 'such regularized kernel based methods are now often called support vector machines ( svms ) , although the notation was historically used for such methods based on the special hinge loss function and for special kernels only , we refer to @xcite .    in this paper we address the open question , whether an svm with an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , if the assumption of an additive model is satisfied .',\n",
       " 'our leading example covers learning rates for quantile regression based on the lipschitz continuous but non - differentiable pinball loss function , which is also called check function in the literature , see e.g. @xcite and @xcite for parametric quantile regression and @xcite , @xcite , and @xcite for kernel based quantile regression .',\n",
       " 'we will not address the question how to check whether the assumption of an additive model is satisfied because this would be a topic of a paper of its own .',\n",
       " 'of course , a practical approach might be to fit both models and compare their risks evaluated for test data .',\n",
       " 'for the same reason we will also not cover sparsity .',\n",
       " 'consistency of support vector machines generated by additive kernels for additive models was considered in @xcite . in this paper',\n",
       " 'we establish learning rates for these algorithms .',\n",
       " 'let us recall the framework with a complete separable metric space @xmath3 as the input space and a closed subset @xmath4 of @xmath5 as the output space .',\n",
       " 'a borel probability measure @xmath6 on @xmath7 is used to model the learning problem and an independent and identically distributed sample @xmath8 is drawn according to @xmath6 for learning .',\n",
       " 'a loss function @xmath9 is used to measure the quality of a prediction function @xmath10 by the local error @xmath11 .',\n",
       " '_ throughout the paper we assume that @xmath12 is measurable , @xmath13 , convex with respect to the third variable , and uniformly lipschitz continuous satisfying @xmath14 with a finite constant @xmath15 .',\n",
       " '_    support vector machines ( svms ) considered here are kernel - based regularization schemes in a reproducing kernel hilbert space ( rkhs ) @xmath0 generated by a mercer kernel @xmath16 . with a shifted loss function @xmath17 introduced for dealing',\n",
       " 'even with heavy - tailed distributions as @xmath18 , they take the form @xmath19 where for a general borel measure @xmath20 on @xmath21 , the function @xmath22 is defined by @xmath23 where @xmath24 is a regularization parameter .',\n",
       " 'the idea to shift a loss function has a long history , see e.g. @xcite in the context of m - estimators .',\n",
       " 'it was shown in @xcite that @xmath22 is also a minimizer of the following optimization problem involving the original loss function @xmath12 if a minimizer exists : @xmath25    the additive model we consider consists of the _ input space decomposition _',\n",
       " '@xmath26 with each @xmath27 a complete separable metric space and a _ hypothesis space _',\n",
       " '@xmath28 where @xmath29 is a set of functions @xmath30 each of which is also identified as a map @xmath31 from @xmath3 to @xmath5 .',\n",
       " 'hence the functions from @xmath32 take the additive form @xmath33 .',\n",
       " 'we mention , that there is strictly speaking a notational problem here , because in the previous formula each quantity @xmath34 is an element of the set @xmath35 which is a subset of the full input space @xmath36 , @xmath37 , whereas in the definition of sample @xmath8 each quantity @xmath38 is an element of the full input space @xmath36 , where @xmath39 .',\n",
       " 'because these notations will only be used in different places and because we do not expect any misunderstandings , we think this notation is easier and more intuitive than specifying these quantities with different symbols .',\n",
       " 'the additive kernel @xmath40 is defined in terms of mercer kernels @xmath41 on @xmath27 as @xmath42 it generates an rkhs @xmath0 which can be written in terms of the rkhs @xmath43 generated by @xmath41 on @xmath27 corresponding to the form ( [ additive ] ) as @xmath44 with norm given by @xmath45 the norm of @xmath46 satisfies @xmath47    to illustrate advantages of additive models , we provide two examples of comparing additive with product kernels .',\n",
       " 'the first example deals with gaussian rbf kernels .',\n",
       " 'all proofs will be given in section [ proofsection ] .',\n",
       " '[ gaussadd ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and @xmath52.\\\\ ] ] the additive kernel @xmath53 is given by @xmath54 furthermore , the product kernel @xmath55 is the standard gaussian kernel given by @xmath56 define a gaussian function @xmath57 on @xmath58 ^ 2 $ ] depending only on one variable by @xmath59 then @xmath60 but @xmath61 where @xmath62 denotes the rkhs generated by the standard gaussian rbf kernel @xmath63 .',\n",
       " 'the second example is about sobolev kernels .',\n",
       " '[ sobolvadd ] let @xmath64 , @xmath65 $ ] and @xmath58^s.$ ] let @xmath66 : = \\\\bigl\\\\{u\\\\in l_2([0,1 ] ) ; d^\\\\alpha u \\\\in l_2([0,1 ] ) \\\\mbox{~for~all~}|\\\\alpha|\\\\le 1\\\\bigr\\\\}\\\\ ] ] be the sobolev space consisting of all square integrable univariate functions whose derivative is also square integrable .',\n",
       " 'it is an rkhs with a mercer kernel @xmath67 defined on @xmath68 ^ 2 $ ] .',\n",
       " 'if we take all the mercer kernels @xmath69 to be @xmath67 , then @xmath70 $ ] for each @xmath71 .',\n",
       " 'the additive kernel @xmath72 is also a mercer kernel and defines an rkhs @xmath73\\\\right\\\\}.\\\\ ] ] however , the multivariate sobolev space @xmath74^s)$ ] , consisting of all square integrable functions whose partial derivatives are all square integrable , contains discontinuous functions and is not an rkhs .',\n",
       " 'denote the marginal distribution of @xmath6 on @xmath27 as @xmath75 . under the assumption that @xmath76 for each @xmath71 and that @xmath43 is dense in @xmath29 in the @xmath77-metric , it was proved in @xcite that @xmath78 in probability as long as @xmath79 satisfies @xmath80 and @xmath81 .',\n",
       " 'the rest of the paper has the following structure .',\n",
       " 'section [ ratessection ] contains our main results on learning rates for svms based on additive kernels . learning rates for quantile regression',\n",
       " 'are treated as important special cases .',\n",
       " 'section [ comparisonsection ] contains a comparison of our results with other learning rates published recently .',\n",
       " 'section [ proofsection ] contains all the proofs and some results which can be interesting in their own .',\n",
       " 'in this paper we provide some learning rates for the support vector machines generated by additive kernels for additive models which helps improve the quantitative understanding presented in @xcite .',\n",
       " 'the rates are about asymptotic behaviors of the excess risk @xmath82 and take the form @xmath83 with @xmath84 .',\n",
       " 'they will be stated under three kinds of conditions involving the hypothesis space @xmath0 , the measure @xmath6 , the loss @xmath12 , and the choice of the regularization parameter @xmath85 .',\n",
       " 'the first condition is about the approximation ability of the hypothesis space @xmath0 .',\n",
       " 'since the output function @xmath19 is from the hypothesis space , the learning rates of the learning algorithm depend on the approximation ability of the hypothesis space @xmath0 with respect to the optimal risk @xmath86 measured by the following approximation error .',\n",
       " '[ defapprox ] the approximation error of the triple @xmath87 is defined as @xmath88    to estimate the approximation error , we make an assumption about the minimizer of the risk @xmath89    for each @xmath90 , define the integral operator @xmath91 associated with the kernel @xmath41 by @xmath92 we mention that @xmath93 is a compact and positive operator on @xmath94 . hence we can find its normalized eigenpairs @xmath95 such that @xmath96 is an orthonormal basis of @xmath94 and @xmath97 as @xmath98 . fix @xmath99 .',\n",
       " 'then we can define the @xmath100-th power @xmath101 of @xmath93 by @xmath102 this is a positive and bounded operator and its range is well - defined .',\n",
       " 'the assumption @xmath103 means @xmath104 lies in this range .',\n",
       " '[ assumption1 ] we assume @xmath105 and @xmath106 where for some @xmath107 and each @xmath108 , @xmath109 is a function of the form @xmath110 with some @xmath111 .',\n",
       " 'the case @xmath112 of assumption [ assumption1 ] means each @xmath113 lies in the rkhs @xmath43 .',\n",
       " 'a standard condition in the literature ( e.g. , @xcite ) for achieving decays of the form @xmath114 for the approximation error ( [ approxerrordef ] ) is @xmath115 with some @xmath116 . here',\n",
       " 'the operator @xmath117 is defined by @xmath118 in general , this can not be written in an additive form .',\n",
       " 'however , the hypothesis space ( [ additive ] ) takes an additive form @xmath119 .',\n",
       " 'so it is natural for us to impose an additive expression @xmath120 for the target function @xmath121 with the component functions @xmath113 satisfying the power condition @xmath110 .',\n",
       " 'the above natural assumption leads to a technical difficulty in estimating the approximation error : the function @xmath113 has no direct connection to the marginal distribution @xmath122 projected onto @xmath27 , hence existing methods in the literature ( e.g. , @xcite ) can not be applied directly .',\n",
       " 'note that on the product space @xmath123 , there is no natural probability measure projected from @xmath6 , and the risk on @xmath124 is not defined .    our idea to overcome the difficulty is to introduce an intermediate function @xmath125 .',\n",
       " 'it may not minimize a risk ( which is not even defined ) .',\n",
       " 'however , it approximates the component function @xmath113 well .',\n",
       " 'when we add up such functions @xmath126 , we get a good approximation of the target function @xmath121 , and thereby a good estimate of the approximation error .',\n",
       " 'this is the first novelty of the paper .',\n",
       " '[ approxerrorthm ] under assumption [ assumption1 ] , we have @xmath127 where @xmath128 is the constant given by @xmath129      the second condition for our learning rates is about the capacity of the hypothesis space measured by @xmath130-empirical covering numbers .    let @xmath131 be a set of functions on @xmath21 and @xmath132 for every @xmath133 the * covering number of @xmath131 * with respect to the empirical metric @xmath134 , given by @xmath135 is defined as @xmath136 and the * @xmath130-empirical covering number * of @xmath137 is defined as @xmath138    [ assumption2 ] we assume @xmath139 and that for some @xmath140 , @xmath141 and every @xmath142 , the @xmath130-empirical covering number of the unit ball of @xmath43 satisfies @xmath143    the second novelty of this paper is to observe that the additive nature of the hypothesis space yields the following nice bound with a dimension - independent power exponent for the covering numbers of the balls of the hypothesis space @xmath0 , to be proved in section [ samplesection ] .',\n",
       " '[ capacitythm ] under assumption [ assumption2 ] , for any @xmath144 and @xmath145 , we have @xmath146    the bound for the covering numbers stated in theorem [ capacitythm ] is special : the power @xmath147 is independent of the number @xmath148 of the components in the additive model .',\n",
       " 'it is well - known @xcite in the literature of function spaces that the covering numbers of balls of the sobolev space @xmath149 on the cube @xmath150^s$ ] of the euclidean space @xmath151 with regularity index @xmath152 has the following asymptotic behavior with @xmath153 : @xmath154 here the power @xmath155 depends linearly on the dimension @xmath148 .',\n",
       " 'similar dimension - dependent bounds for the covering numbers of the rkhss associated with gaussian rbf - kernels can be found in @xcite .',\n",
       " 'the special bound in theorem [ capacitythm ] demonstrates an advantage of the additive model in terms of capacity of the additive hypothesis space .',\n",
       " 'the third condition for our learning rates is about the noise level in the measure @xmath6 with respect to the hypothesis space . before stating the general condition',\n",
       " ', we consider a special case for quantile regression , to illustrate our general results .',\n",
       " 'let @xmath156 be a quantile parameter .',\n",
       " 'the quantile regression function @xmath157 is defined by its value @xmath158 to be a @xmath159-quantile of @xmath160 , i.e. , a value @xmath161 satisfying @xmath162 the regularization scheme for quantile regression considered here takes the form ( [ algor ] ) with the loss function @xmath12 given by the pinball loss as @xmath163    a noise condition on @xmath6 for quantile regression is defined in @xcite as follows . to this end , let @xmath164 be a probability measure on @xmath165 and @xmath166 . then a real number @xmath167 is called @xmath159-quantile of @xmath164 , if and only if @xmath167 belongs to the set @xmath168\\\\bigr ) \\\\ge',\n",
       " '\\\\tau     \\\\mbox{~~and~~ } q\\\\bigl([t , \\\\infty)\\\\bigr ) \\\\ge 1-\\\\tau\\\\bigr\\\\}\\\\,.\\\\ ] ] it is well - known that @xmath169 is a compact interval .',\n",
       " '[ noisecond ] let @xmath166 .    1 .',\n",
       " 'a probability measure @xmath164 on @xmath165 is said to have a * @xmath159-quantile of type @xmath170 * , if there exist a @xmath159-quantile @xmath171 and a constant @xmath172 such that , for all @xmath173 $ ] , we have @xmath174 2 .',\n",
       " 'let @xmath175 $ ] .',\n",
       " 'we say that a probability measure @xmath20 on @xmath176 has a * @xmath159-quantile of @xmath177-average type @xmath170 * if the conditional probability measure @xmath178 has @xmath179-almost surely a @xmath159-quantile of type @xmath170 and the function @xmath180 where @xmath181 is the constant defined in part ( 1 ) , satisfies @xmath182 .',\n",
       " 'one can show that a distribution @xmath164 having a @xmath159-quantile of type @xmath170 has a unique @xmath159-quantile @xmath183 .',\n",
       " 'moreover , if @xmath164 has a lebesgue density @xmath184 then @xmath164 has a @xmath159-quantile of type @xmath170 if @xmath184 is bounded away from zero on @xmath185 $ ] since we can use @xmath186\\\\}$ ] in ( [ tauquantileoftype2formula ] ) .',\n",
       " 'this assumption is general enough to cover many distributions used in parametric statistics such as gaussian , student s @xmath187 , and logistic distributions ( with @xmath188 ) , gamma and log - normal distributions ( with @xmath189 ) , and uniform and beta distributions ( with @xmath190 $ ] ) .',\n",
       " 'the following theorem , to be proved in section [ proofsection ] , gives a learning rate for the regularization scheme ( [ algor ] ) in the special case of quantile regression .',\n",
       " '[ quantilethm ] suppose that @xmath191 almost surely for some constant @xmath192 , and that each kernel @xmath41 is @xmath193 with @xmath194 for some @xmath195 .',\n",
       " 'if assumption [ assumption1 ] holds with @xmath112 and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath198 and @xmath199 , with confidence at least @xmath200 we have @xmath201 where @xmath202 is a constant independent of @xmath203 and @xmath204 and @xmath205    please note that the exponent @xmath206 given by ( [ quantilerates2 ] ) for the learning rate in ( [ quantilerates ] ) is independent of the quantile level @xmath159 , of the number @xmath148 of additive components in @xmath207 , and of the dimensions @xmath208 and @xmath209 further note that @xmath210 , if @xmath211 , and @xmath212 if @xmath213 . because @xmath214 can be arbitrarily close to @xmath215 , the learning rate , which is independent of the dimension @xmath216 and given by theorem [ quantilethm ] , is close to @xmath217 for large values of @xmath177 and is close to @xmath218 or better , if @xmath211 .      to state our general learning rates',\n",
       " ', we need an assumption on a _ variance - expectation bound _ which is similar to definition [ noisecond ] in the special case of quantile regression .',\n",
       " '[ assumption3 ] we assume that there exist an exponent @xmath219 $ ] and a positive constant @xmath220 such that @xmath221    assumption [ assumption3 ] always holds true for @xmath222 . if the triple @xmath223 satisfies some conditions , the exponent @xmath224 can be larger .',\n",
       " 'for example , when @xmath12 is the pinball loss ( [ pinloss ] ) and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath225 for some @xmath196 $ ] and @xmath226 as defined in @xcite , then @xmath227 .',\n",
       " '[ mainratesthm ] suppose that @xmath228 is bounded by a constant @xmath229 almost surely . under assumptions [ assumption1 ] to [ assumption3 ] ,',\n",
       " 'if we take @xmath198 and @xmath230 for some @xmath231 , then for any @xmath232 , with confidence at least @xmath200 we have @xmath233 where @xmath234 is given by @xmath235 and @xmath202 is constant independent of @xmath203 or @xmath204 ( to be given explicitly in the proof ) .',\n",
       " 'we now add some theoretical and numerical comparisons on the goodness of our learning rates with those from the literature . as already mentioned in the introduction',\n",
       " ', some reasons for the popularity of additive models are flexibility , increased interpretability , and ( often ) a reduced proneness of the curse of high dimensions .',\n",
       " 'hence it is important to check , whether the learning rate given in theorem [ mainratesthm ] under the assumption of an additive model favourably compares to ( essentially ) optimal learning rates without this assumption . in other words ,',\n",
       " 'we need to demonstrate that the main goal of this paper is achieved by theorem [ quantilethm ] and theorem [ mainratesthm ] , i.e. that an svm based on an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , provided the assumption of an additive model is satisfied .',\n",
       " 'our learning rate in theorem [ quantilethm ] is new and optimal in the literature of svm for quantile regression .',\n",
       " 'most learning rates in the literature of svm for quantile regression are given for projected output functions @xmath236 , while it is well known that projections improve learning rates @xcite . here the projection operator @xmath237 is defined for any measurable function @xmath10 by @xmath238 sometimes this is called clipping .',\n",
       " 'such results are given in @xcite .',\n",
       " 'for example , under the assumptions that @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , the approximation error condition ( [ approxerrorb ] ) is satisfied for some @xmath239 , and that for some constants @xmath240 , the sequence of eigenvalues @xmath241 of the integral operator @xmath117 satisfies @xmath242 for every @xmath243 , it was shown in @xcite that with confidence at least @xmath200 , @xmath244 where @xmath245 here the parameter @xmath246 measures the capacity of the rkhs @xmath247 and it plays a similar role as half of the parameter @xmath147 in assumption 2 . for a @xmath193 kernel and @xmath112',\n",
       " ', one can choose @xmath246 and @xmath147 to be arbitrarily small and the above power index @xmath248 can be taken as @xmath249 .',\n",
       " 'the learning rate in theorem [ quantilethm ] may be improved by relaxing assumption 1 to a sobolev smoothness condition for @xmath121 and a regularity condition for the marginal distribution @xmath250 .',\n",
       " 'for example , one may use a gaussian kernel @xmath251 depending on the sample size @xmath203 and @xcite achieve the approximation error condition ( [ approxerrorb ] ) for some @xmath252 .',\n",
       " 'this is done for quantile regression in @xcite .',\n",
       " 'since we are mainly interested in additive models , we shall not discuss such an extension .',\n",
       " '[ gaussmore ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and the additive kernel @xmath72 be given by ( [ gaussaddform ] ) with @xmath253 in example [ gaussadd ] as @xmath52.\\\\ ] ] if the function @xmath121 is given by ( [ gaussfcn ] ) , @xmath191 almost surely for some constant @xmath192 , and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath145 and @xmath199 , ( [ quantilerates ] ) holds with confidence at least @xmath200 .    it is unknown whether the above learning rate can be derived by existing approaches in the literature ( e.g. @xcite ) even after projection .',\n",
       " 'note that the kernel in the above example is independent of the sample size .',\n",
       " 'it would be interesting to see whether there exists some @xmath99 such that the function @xmath57 defined by ( [ gaussfcn ] ) lies in the range of the operator @xmath254 .',\n",
       " 'the existence of such a positive index would lead to the approximation error condition ( [ approxerrorb ] ) , see @xcite .    let us now add some numerical comparisons on the goodness of our learning rates given by theorem [ mainratesthm ] with those given by @xcite .',\n",
       " 'their corollary 4.12 gives ( essentially ) minmax optimal learning rates for ( clipped ) svms in the context of nonparametric quantile regression using one gaussian rbf kernel on the whole input space under appropriate smoothness assumptions of the target function .',\n",
       " 'let us consider the case that the distribution @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , where @xmath255 , and assume that both corollary 4.12 in @xcite and our theorem [ mainratesthm ] are applicable .',\n",
       " 'i.e. , we assume in particular that @xmath6 is a probability measure on @xmath256 $ ] and that the marginal distribution @xmath257 has a lebesgue density @xmath258 for some @xmath259 . furthermore , suppose that the optimal decision function @xmath260 has ( to make theorem [ mainratesthm ] applicable with @xmath261 $ ] ) the additive structure @xmath207 with each @xmath104 as stated in assumption [ assumption1 ] , where @xmath262 and @xmath263 , with minimal risk @xmath86 and additionally fulfills ( to make corollary 4.12 in @xcite applicable ) @xmath264 where @xmath265 $ ] and @xmath266 denotes a besov space with smoothness parameter @xmath267 .',\n",
       " 'the intuitive meaning of @xmath248 is , that increasing values of @xmath248 correspond to increased smoothness .',\n",
       " 'we refer to ( * ? ? ? * and p. 44 ) for details on besov spaces .',\n",
       " 'it is well - known that the besov space @xmath268 contains the sobolev space @xmath269 for @xmath270 , @xmath271 , and @xmath272 , and that @xmath273 .',\n",
       " 'we mention that if all @xmath41 are suitably chosen wendland kernels , their reproducing kernel hilbert spaces @xmath43 are sobolev spaces , see ( * ? ? ?',\n",
       " '* thm . 10.35 , p. 160 ) .',\n",
       " 'furthermore , we use the same sequence of regularizing parameters as in ( * ? ? ?',\n",
       " '4.9 , cor . 4.12 ) , i.e. , @xmath274 where @xmath275 , @xmath276 , @xmath277 $ ] , and @xmath278 is some user - defined positive constant independent of @xmath279 . for',\n",
       " 'reasons of simplicity , let us fix @xmath280 .',\n",
       " 'then ( * ? ? ?',\n",
       " '4.12 ) gives learning rates for the risk of svms for @xmath159-quantile regression , if a single gaussian rbf - kernel on @xmath281 is used for @xmath159-quantile functions of @xmath177-average type @xmath170 with @xmath255 , which are of order @xmath282 hence the learning rate in theorem [ quantilethm ] is better than the one in ( * ? ? ?',\n",
       " '4.12 ) in this situation , if @xmath283 provided the assumption of the additive model is valid .',\n",
       " 'table [ table1 ] lists the values of @xmath284 from ( [ explicitratescz2 ] ) for some finite values of the dimension @xmath216 , where @xmath285 .',\n",
       " 'all of these values of @xmath284 are positive with the exceptions if @xmath286 or @xmath287 .',\n",
       " 'this is in contrast to the corresponding exponent in the learning rate by ( * ? ?',\n",
       " '* cor . 4.12 ) , because @xmath288    table [ table2 ] and figures [ figure1 ] to [ figure2 ] give additional information on the limit @xmath289 .',\n",
       " 'of course , higher values of the exponent indicates faster rates of convergence .',\n",
       " 'it is obvious , that an svm based on an additive kernel has a significantly faster rate of convergence in higher dimensions @xmath216 compared to svm based on a single gaussian rbf kernel defined on the whole input space , of course under the assumption that the additive model is valid .',\n",
       " 'the figures seem to indicate that our learning rate from theorem [ mainratesthm ] is probably not optimal for small dimensions . however , the main focus of the present paper is on high dimensions .',\n",
       " '.[table1 ] the table lists the limits of the exponents @xmath290 from ( * ? ? ?',\n",
       " '* cor . 4.12 ) and @xmath291 from theorem [ mainratesthm ] , respectively , if the regularizing parameter @xmath292 is chosen in an optimal manner for the nonparametric setup , i.e. @xmath293 , with @xmath294 for @xmath295 and @xmath296 .',\n",
       " 'recall that @xmath297 $ ] .',\n",
       " '[ cols= \" > , > , > , > \" , ]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[\"article_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbb0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latex2text import LatexNodes2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9bbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1e3de32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in test_dict[\"article_text\"]:\n",
    "    text.append(LatexNodes2Text().latex_to_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6521a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models .',\n",
       " 'it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models .',\n",
       " 'many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space @xmath0 , see e.g. @xcite . in the last years',\n",
       " 'many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g. @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and the references therein . of course , the least squares loss function is differentiable and has many nice mathematical properties , but it is only locally lipschitz continuous and therefore regularized kernel based methods based on this loss function typically suffer on bad statistical robustness properties , even if the kernel is bounded .',\n",
       " 'this is in sharp contrast to kernel methods based on a lipschitz continuous loss function and on a bounded loss function , where results on upper bounds for the maxbias bias and on a bounded influence function are known , see e.g. @xcite for the general case and @xcite for additive models .',\n",
       " 'therefore , we will here consider the case of regularized kernel based methods based on a general convex and lipschitz continuous loss function , on a general kernel , and on the classical regularizing term @xmath1 for some @xmath2 which is a smoothness penalty but not a sparsity penalty , see e.g. @xcite .',\n",
       " 'such regularized kernel based methods are now often called support vector machines ( svms ) , although the notation was historically used for such methods based on the special hinge loss function and for special kernels only , we refer to @xcite .    in this paper we address the open question , whether an svm with an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , if the assumption of an additive model is satisfied .',\n",
       " 'our leading example covers learning rates for quantile regression based on the lipschitz continuous but non - differentiable pinball loss function , which is also called check function in the literature , see e.g. @xcite and @xcite for parametric quantile regression and @xcite , @xcite , and @xcite for kernel based quantile regression .',\n",
       " 'we will not address the question how to check whether the assumption of an additive model is satisfied because this would be a topic of a paper of its own .',\n",
       " 'of course , a practical approach might be to fit both models and compare their risks evaluated for test data .',\n",
       " 'for the same reason we will also not cover sparsity .',\n",
       " 'consistency of support vector machines generated by additive kernels for additive models was considered in @xcite . in this paper',\n",
       " 'we establish learning rates for these algorithms .',\n",
       " 'let us recall the framework with a complete separable metric space @xmath3 as the input space and a closed subset @xmath4 of @xmath5 as the output space .',\n",
       " 'a borel probability measure @xmath6 on @xmath7 is used to model the learning problem and an independent and identically distributed sample @xmath8 is drawn according to @xmath6 for learning .',\n",
       " 'a loss function @xmath9 is used to measure the quality of a prediction function @xmath10 by the local error @xmath11 .',\n",
       " '_ throughout the paper we assume that @xmath12 is measurable , @xmath13 , convex with respect to the third variable , and uniformly lipschitz continuous satisfying @xmath14 with a finite constant @xmath15 .',\n",
       " '_    support vector machines ( svms ) considered here are kernel - based regularization schemes in a reproducing kernel hilbert space ( rkhs ) @xmath0 generated by a mercer kernel @xmath16 . with a shifted loss function @xmath17 introduced for dealing',\n",
       " 'even with heavy - tailed distributions as @xmath18 , they take the form @xmath19 where for a general borel measure @xmath20 on @xmath21 , the function @xmath22 is defined by @xmath23 where @xmath24 is a regularization parameter .',\n",
       " 'the idea to shift a loss function has a long history , see e.g. @xcite in the context of m - estimators .',\n",
       " 'it was shown in @xcite that @xmath22 is also a minimizer of the following optimization problem involving the original loss function @xmath12 if a minimizer exists : @xmath25    the additive model we consider consists of the _ input space decomposition _',\n",
       " '@xmath26 with each @xmath27 a complete separable metric space and a _ hypothesis space _',\n",
       " '@xmath28 where @xmath29 is a set of functions @xmath30 each of which is also identified as a map @xmath31 from @xmath3 to @xmath5 .',\n",
       " 'hence the functions from @xmath32 take the additive form @xmath33 .',\n",
       " 'we mention , that there is strictly speaking a notational problem here , because in the previous formula each quantity @xmath34 is an element of the set @xmath35 which is a subset of the full input space @xmath36 , @xmath37 , whereas in the definition of sample @xmath8 each quantity @xmath38 is an element of the full input space @xmath36 , where @xmath39 .',\n",
       " 'because these notations will only be used in different places and because we do not expect any misunderstandings , we think this notation is easier and more intuitive than specifying these quantities with different symbols .',\n",
       " 'the additive kernel @xmath40 is defined in terms of mercer kernels @xmath41 on @xmath27 as @xmath42 it generates an rkhs @xmath0 which can be written in terms of the rkhs @xmath43 generated by @xmath41 on @xmath27 corresponding to the form ( [ additive ] ) as @xmath44 with norm given by @xmath45 the norm of @xmath46 satisfies @xmath47    to illustrate advantages of additive models , we provide two examples of comparing additive with product kernels .',\n",
       " 'the first example deals with gaussian rbf kernels .',\n",
       " 'all proofs will be given in section [ proofsection ] .',\n",
       " '[ gaussadd ] let @xmath48 , @xmath49 ] and @xmath50 ^ 2. ] let @xmath51 and @xmath52. ] ] the additive kernel @xmath53 is given by @xmath54 furthermore , the product kernel @xmath55 is the standard gaussian kernel given by @xmath56 define a gaussian function @xmath57 on @xmath58 ^ 2 ] depending only on one variable by @xmath59 then @xmath60 but @xmath61 where @xmath62 denotes the rkhs generated by the standard gaussian rbf kernel @xmath63 .',\n",
       " 'the second example is about sobolev kernels .',\n",
       " '[ sobolvadd ] let @xmath64 , @xmath65 ] and @xmath58^s. ] let @xmath66 : = {u∈l_2([0,1 ] ) ; d^αu ∈l_2([0,1 ] ) |α|≤1} ] ] be the sobolev space consisting of all square integrable univariate functions whose derivative is also square integrable .',\n",
       " 'it is an rkhs with a mercer kernel @xmath67 defined on @xmath68 ^ 2 ] .',\n",
       " 'if we take all the mercer kernels @xmath69 to be @xmath67 , then @xmath70 ] for each @xmath71 .',\n",
       " 'the additive kernel @xmath72 is also a mercer kernel and defines an rkhs @xmath73}. ] ] however , the multivariate sobolev space @xmath74^s)] , consisting of all square integrable functions whose partial derivatives are all square integrable , contains discontinuous functions and is not an rkhs .',\n",
       " 'denote the marginal distribution of @xmath6 on @xmath27 as @xmath75 . under the assumption that @xmath76 for each @xmath71 and that @xmath43 is dense in @xmath29 in the @xmath77-metric , it was proved in @xcite that @xmath78 in probability as long as @xmath79 satisfies @xmath80 and @xmath81 .',\n",
       " 'the rest of the paper has the following structure .',\n",
       " 'section [ ratessection ] contains our main results on learning rates for svms based on additive kernels . learning rates for quantile regression',\n",
       " 'are treated as important special cases .',\n",
       " 'section [ comparisonsection ] contains a comparison of our results with other learning rates published recently .',\n",
       " 'section [ proofsection ] contains all the proofs and some results which can be interesting in their own .',\n",
       " 'in this paper we provide some learning rates for the support vector machines generated by additive kernels for additive models which helps improve the quantitative understanding presented in @xcite .',\n",
       " 'the rates are about asymptotic behaviors of the excess risk @xmath82 and take the form @xmath83 with @xmath84 .',\n",
       " 'they will be stated under three kinds of conditions involving the hypothesis space @xmath0 , the measure @xmath6 , the loss @xmath12 , and the choice of the regularization parameter @xmath85 .',\n",
       " 'the first condition is about the approximation ability of the hypothesis space @xmath0 .',\n",
       " 'since the output function @xmath19 is from the hypothesis space , the learning rates of the learning algorithm depend on the approximation ability of the hypothesis space @xmath0 with respect to the optimal risk @xmath86 measured by the following approximation error .',\n",
       " '[ defapprox ] the approximation error of the triple @xmath87 is defined as @xmath88    to estimate the approximation error , we make an assumption about the minimizer of the risk @xmath89    for each @xmath90 , define the integral operator @xmath91 associated with the kernel @xmath41 by @xmath92 we mention that @xmath93 is a compact and positive operator on @xmath94 . hence we can find its normalized eigenpairs @xmath95 such that @xmath96 is an orthonormal basis of @xmath94 and @xmath97 as @xmath98 . fix @xmath99 .',\n",
       " 'then we can define the @xmath100-th power @xmath101 of @xmath93 by @xmath102 this is a positive and bounded operator and its range is well - defined .',\n",
       " 'the assumption @xmath103 means @xmath104 lies in this range .',\n",
       " '[ assumption1 ] we assume @xmath105 and @xmath106 where for some @xmath107 and each @xmath108 , @xmath109 is a function of the form @xmath110 with some @xmath111 .',\n",
       " 'the case @xmath112 of assumption [ assumption1 ] means each @xmath113 lies in the rkhs @xmath43 .',\n",
       " 'a standard condition in the literature ( e.g. , @xcite ) for achieving decays of the form @xmath114 for the approximation error ( [ approxerrordef ] ) is @xmath115 with some @xmath116 . here',\n",
       " 'the operator @xmath117 is defined by @xmath118 in general , this can not be written in an additive form .',\n",
       " 'however , the hypothesis space ( [ additive ] ) takes an additive form @xmath119 .',\n",
       " 'so it is natural for us to impose an additive expression @xmath120 for the target function @xmath121 with the component functions @xmath113 satisfying the power condition @xmath110 .',\n",
       " 'the above natural assumption leads to a technical difficulty in estimating the approximation error : the function @xmath113 has no direct connection to the marginal distribution @xmath122 projected onto @xmath27 , hence existing methods in the literature ( e.g. , @xcite ) can not be applied directly .',\n",
       " 'note that on the product space @xmath123 , there is no natural probability measure projected from @xmath6 , and the risk on @xmath124 is not defined .    our idea to overcome the difficulty is to introduce an intermediate function @xmath125 .',\n",
       " 'it may not minimize a risk ( which is not even defined ) .',\n",
       " 'however , it approximates the component function @xmath113 well .',\n",
       " 'when we add up such functions @xmath126 , we get a good approximation of the target function @xmath121 , and thereby a good estimate of the approximation error .',\n",
       " 'this is the first novelty of the paper .',\n",
       " '[ approxerrorthm ] under assumption [ assumption1 ] , we have @xmath127 where @xmath128 is the constant given by @xmath129      the second condition for our learning rates is about the capacity of the hypothesis space measured by @xmath130-empirical covering numbers .    let @xmath131 be a set of functions on @xmath21 and @xmath132 for every @xmath133 the * covering number of @xmath131 * with respect to the empirical metric @xmath134 , given by @xmath135 is defined as @xmath136 and the * @xmath130-empirical covering number * of @xmath137 is defined as @xmath138    [ assumption2 ] we assume @xmath139 and that for some @xmath140 , @xmath141 and every @xmath142 , the @xmath130-empirical covering number of the unit ball of @xmath43 satisfies @xmath143    the second novelty of this paper is to observe that the additive nature of the hypothesis space yields the following nice bound with a dimension - independent power exponent for the covering numbers of the balls of the hypothesis space @xmath0 , to be proved in section [ samplesection ] .',\n",
       " '[ capacitythm ] under assumption [ assumption2 ] , for any @xmath144 and @xmath145 , we have @xmath146    the bound for the covering numbers stated in theorem [ capacitythm ] is special : the power @xmath147 is independent of the number @xmath148 of the components in the additive model .',\n",
       " 'it is well - known @xcite in the literature of function spaces that the covering numbers of balls of the sobolev space @xmath149 on the cube @xmath150^s] of the euclidean space @xmath151 with regularity index @xmath152 has the following asymptotic behavior with @xmath153 : @xmath154 here the power @xmath155 depends linearly on the dimension @xmath148 .',\n",
       " 'similar dimension - dependent bounds for the covering numbers of the rkhss associated with gaussian rbf - kernels can be found in @xcite .',\n",
       " 'the special bound in theorem [ capacitythm ] demonstrates an advantage of the additive model in terms of capacity of the additive hypothesis space .',\n",
       " 'the third condition for our learning rates is about the noise level in the measure @xmath6 with respect to the hypothesis space . before stating the general condition',\n",
       " ', we consider a special case for quantile regression , to illustrate our general results .',\n",
       " 'let @xmath156 be a quantile parameter .',\n",
       " 'the quantile regression function @xmath157 is defined by its value @xmath158 to be a @xmath159-quantile of @xmath160 , i.e. , a value @xmath161 satisfying @xmath162 the regularization scheme for quantile regression considered here takes the form ( [ algor ] ) with the loss function @xmath12 given by the pinball loss as @xmath163    a noise condition on @xmath6 for quantile regression is defined in @xcite as follows . to this end , let @xmath164 be a probability measure on @xmath165 and @xmath166 . then a real number @xmath167 is called @xmath159-quantile of @xmath164 , if and only if @xmath167 belongs to the set @xmath168) ≥',\n",
       " 'τ q([t , ∞)) ≥1-τ} . ] ] it is well - known that @xmath169 is a compact interval .',\n",
       " '[ noisecond ] let @xmath166 .    1 .',\n",
       " 'a probability measure @xmath164 on @xmath165 is said to have a * @xmath159-quantile of type @xmath170 * , if there exist a @xmath159-quantile @xmath171 and a constant @xmath172 such that , for all @xmath173 ] , we have @xmath174 2 .',\n",
       " 'let @xmath175 ] .',\n",
       " 'we say that a probability measure @xmath20 on @xmath176 has a * @xmath159-quantile of @xmath177-average type @xmath170 * if the conditional probability measure @xmath178 has @xmath179-almost surely a @xmath159-quantile of type @xmath170 and the function @xmath180 where @xmath181 is the constant defined in part ( 1 ) , satisfies @xmath182 .',\n",
       " 'one can show that a distribution @xmath164 having a @xmath159-quantile of type @xmath170 has a unique @xmath159-quantile @xmath183 .',\n",
       " 'moreover , if @xmath164 has a lebesgue density @xmath184 then @xmath164 has a @xmath159-quantile of type @xmath170 if @xmath184 is bounded away from zero on @xmath185 ] since we can use @xmath186} ] in ( [ tauquantileoftype2formula ] ) .',\n",
       " 'this assumption is general enough to cover many distributions used in parametric statistics such as gaussian , student s @xmath187 , and logistic distributions ( with @xmath188 ) , gamma and log - normal distributions ( with @xmath189 ) , and uniform and beta distributions ( with @xmath190 ] ) .',\n",
       " 'the following theorem , to be proved in section [ proofsection ] , gives a learning rate for the regularization scheme ( [ algor ] ) in the special case of quantile regression .',\n",
       " '[ quantilethm ] suppose that @xmath191 almost surely for some constant @xmath192 , and that each kernel @xmath41 is @xmath193 with @xmath194 for some @xmath195 .',\n",
       " 'if assumption [ assumption1 ] holds with @xmath112 and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 ] , then by taking @xmath197 , for any @xmath198 and @xmath199 , with confidence at least @xmath200 we have @xmath201 where @xmath202 is a constant independent of @xmath203 and @xmath204 and @xmath205    please note that the exponent @xmath206 given by ( [ quantilerates2 ] ) for the learning rate in ( [ quantilerates ] ) is independent of the quantile level @xmath159 , of the number @xmath148 of additive components in @xmath207 , and of the dimensions @xmath208 and @xmath209 further note that @xmath210 , if @xmath211 , and @xmath212 if @xmath213 . because @xmath214 can be arbitrarily close to @xmath215 , the learning rate , which is independent of the dimension @xmath216 and given by theorem [ quantilethm ] , is close to @xmath217 for large values of @xmath177 and is close to @xmath218 or better , if @xmath211 .      to state our general learning rates',\n",
       " ', we need an assumption on a _ variance - expectation bound _ which is similar to definition [ noisecond ] in the special case of quantile regression .',\n",
       " '[ assumption3 ] we assume that there exist an exponent @xmath219 ] and a positive constant @xmath220 such that @xmath221    assumption [ assumption3 ] always holds true for @xmath222 . if the triple @xmath223 satisfies some conditions , the exponent @xmath224 can be larger .',\n",
       " 'for example , when @xmath12 is the pinball loss ( [ pinloss ] ) and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath225 for some @xmath196 ] and @xmath226 as defined in @xcite , then @xmath227 .',\n",
       " '[ mainratesthm ] suppose that @xmath228 is bounded by a constant @xmath229 almost surely . under assumptions [ assumption1 ] to [ assumption3 ] ,',\n",
       " 'if we take @xmath198 and @xmath230 for some @xmath231 , then for any @xmath232 , with confidence at least @xmath200 we have @xmath233 where @xmath234 is given by @xmath235 and @xmath202 is constant independent of @xmath203 or @xmath204 ( to be given explicitly in the proof ) .',\n",
       " 'we now add some theoretical and numerical comparisons on the goodness of our learning rates with those from the literature . as already mentioned in the introduction',\n",
       " ', some reasons for the popularity of additive models are flexibility , increased interpretability , and ( often ) a reduced proneness of the curse of high dimensions .',\n",
       " 'hence it is important to check , whether the learning rate given in theorem [ mainratesthm ] under the assumption of an additive model favourably compares to ( essentially ) optimal learning rates without this assumption . in other words ,',\n",
       " 'we need to demonstrate that the main goal of this paper is achieved by theorem [ quantilethm ] and theorem [ mainratesthm ] , i.e. that an svm based on an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , provided the assumption of an additive model is satisfied .',\n",
       " 'our learning rate in theorem [ quantilethm ] is new and optimal in the literature of svm for quantile regression .',\n",
       " 'most learning rates in the literature of svm for quantile regression are given for projected output functions @xmath236 , while it is well known that projections improve learning rates @xcite . here the projection operator @xmath237 is defined for any measurable function @xmath10 by @xmath238 sometimes this is called clipping .',\n",
       " 'such results are given in @xcite .',\n",
       " 'for example , under the assumptions that @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , the approximation error condition ( [ approxerrorb ] ) is satisfied for some @xmath239 , and that for some constants @xmath240 , the sequence of eigenvalues @xmath241 of the integral operator @xmath117 satisfies @xmath242 for every @xmath243 , it was shown in @xcite that with confidence at least @xmath200 , @xmath244 where @xmath245 here the parameter @xmath246 measures the capacity of the rkhs @xmath247 and it plays a similar role as half of the parameter @xmath147 in assumption 2 . for a @xmath193 kernel and @xmath112',\n",
       " ', one can choose @xmath246 and @xmath147 to be arbitrarily small and the above power index @xmath248 can be taken as @xmath249 .',\n",
       " 'the learning rate in theorem [ quantilethm ] may be improved by relaxing assumption 1 to a sobolev smoothness condition for @xmath121 and a regularity condition for the marginal distribution @xmath250 .',\n",
       " 'for example , one may use a gaussian kernel @xmath251 depending on the sample size @xmath203 and @xcite achieve the approximation error condition ( [ approxerrorb ] ) for some @xmath252 .',\n",
       " 'this is done for quantile regression in @xcite .',\n",
       " 'since we are mainly interested in additive models , we shall not discuss such an extension .',\n",
       " '[ gaussmore ] let @xmath48 , @xmath49 ] and @xmath50 ^ 2. ] let @xmath51 and the additive kernel @xmath72 be given by ( [ gaussaddform ] ) with @xmath253 in example [ gaussadd ] as @xmath52. ] ] if the function @xmath121 is given by ( [ gaussfcn ] ) , @xmath191 almost surely for some constant @xmath192 , and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 ] , then by taking @xmath197 , for any @xmath145 and @xmath199 , ( [ quantilerates ] ) holds with confidence at least @xmath200 .    it is unknown whether the above learning rate can be derived by existing approaches in the literature ( e.g. @xcite ) even after projection .',\n",
       " 'note that the kernel in the above example is independent of the sample size .',\n",
       " 'it would be interesting to see whether there exists some @xmath99 such that the function @xmath57 defined by ( [ gaussfcn ] ) lies in the range of the operator @xmath254 .',\n",
       " 'the existence of such a positive index would lead to the approximation error condition ( [ approxerrorb ] ) , see @xcite .    let us now add some numerical comparisons on the goodness of our learning rates given by theorem [ mainratesthm ] with those given by @xcite .',\n",
       " 'their corollary 4.12 gives ( essentially ) minmax optimal learning rates for ( clipped ) svms in the context of nonparametric quantile regression using one gaussian rbf kernel on the whole input space under appropriate smoothness assumptions of the target function .',\n",
       " 'let us consider the case that the distribution @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , where @xmath255 , and assume that both corollary 4.12 in @xcite and our theorem [ mainratesthm ] are applicable .',\n",
       " 'i.e. , we assume in particular that @xmath6 is a probability measure on @xmath256 ] and that the marginal distribution @xmath257 has a lebesgue density @xmath258 for some @xmath259 . furthermore , suppose that the optimal decision function @xmath260 has ( to make theorem [ mainratesthm ] applicable with @xmath261 ] ) the additive structure @xmath207 with each @xmath104 as stated in assumption [ assumption1 ] , where @xmath262 and @xmath263 , with minimal risk @xmath86 and additionally fulfills ( to make corollary 4.12 in @xcite applicable ) @xmath264 where @xmath265 ] and @xmath266 denotes a besov space with smoothness parameter @xmath267 .',\n",
       " 'the intuitive meaning of @xmath248 is , that increasing values of @xmath248 correspond to increased smoothness .',\n",
       " 'we refer to ( * ? ? ? * and p. 44 ) for details on besov spaces .',\n",
       " 'it is well - known that the besov space @xmath268 contains the sobolev space @xmath269 for @xmath270 , @xmath271 , and @xmath272 , and that @xmath273 .',\n",
       " 'we mention that if all @xmath41 are suitably chosen wendland kernels , their reproducing kernel hilbert spaces @xmath43 are sobolev spaces , see ( * ? ? ?',\n",
       " '* thm . 10.35 , p. 160 ) .',\n",
       " 'furthermore , we use the same sequence of regularizing parameters as in ( * ? ? ?',\n",
       " '4.9 , cor . 4.12 ) , i.e. , @xmath274 where @xmath275 , @xmath276 , @xmath277 ] , and @xmath278 is some user - defined positive constant independent of @xmath279 . for',\n",
       " 'reasons of simplicity , let us fix @xmath280 .',\n",
       " 'then ( * ? ? ?',\n",
       " '4.12 ) gives learning rates for the risk of svms for @xmath159-quantile regression , if a single gaussian rbf - kernel on @xmath281 is used for @xmath159-quantile functions of @xmath177-average type @xmath170 with @xmath255 , which are of order @xmath282 hence the learning rate in theorem [ quantilethm ] is better than the one in ( * ? ? ?',\n",
       " '4.12 ) in this situation , if @xmath283 provided the assumption of the additive model is valid .',\n",
       " 'table [ table1 ] lists the values of @xmath284 from ( [ explicitratescz2 ] ) for some finite values of the dimension @xmath216 , where @xmath285 .',\n",
       " 'all of these values of @xmath284 are positive with the exceptions if @xmath286 or @xmath287 .',\n",
       " 'this is in contrast to the corresponding exponent in the learning rate by ( * ? ?',\n",
       " '* cor . 4.12 ) , because @xmath288    table [ table2 ] and figures [ figure1 ] to [ figure2 ] give additional information on the limit @xmath289 .',\n",
       " 'of course , higher values of the exponent indicates faster rates of convergence .',\n",
       " 'it is obvious , that an svm based on an additive kernel has a significantly faster rate of convergence in higher dimensions @xmath216 compared to svm based on a single gaussian rbf kernel defined on the whole input space , of course under the assumption that the additive model is valid .',\n",
       " 'the figures seem to indicate that our learning rate from theorem [ mainratesthm ] is probably not optimal for small dimensions . however , the main focus of the present paper is on high dimensions .',\n",
       " '.[table1 ] the table lists the limits of the exponents @xmath290 from ( * ? ? ?',\n",
       " '* cor . 4.12 ) and @xmath291 from theorem [ mainratesthm ] , respectively , if the regularizing parameter @xmath292 is chosen in an optimal manner for the nonparametric setup , i.e. @xmath293 , with @xmath294 for @xmath295 and @xmath296 .',\n",
       " 'recall that @xmath297 ] .',\n",
       " '[ cols= \" > , > , > , > \" , ]']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "bff39695",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "08d9e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "96eee1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def remove_synonyms(word):\n",
    "    # Get all the synonyms of the word\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "\n",
    "    # If the word has synonyms, return None\n",
    "    if len(synonyms) > 1:\n",
    "        return None\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def preprocess(document):\n",
    "    preprocessed_document = []  # Create an empty list to store preprocessed sentences\n",
    "\n",
    "    for sentence in document:\n",
    "        # Step 1: Replace '\\n' with space\n",
    "        sentence = sentence.replace('\\n', ' ')\n",
    "\n",
    "        # Step 2: Segmentation (if needed)\n",
    "        # In your case, the input is already a list of sentences\n",
    "\n",
    "        # Step 3: Use a regular expression to keep only letters and numbers (remove non-alphanumeric characters)\n",
    "        sentence = ' '.join(word for word in sentence.split() if not word.startswith('@'))\n",
    "        sentence = re.sub(r'\\W+', ' ', sentence)\n",
    "\n",
    "#         # Step 4: Tokenization\n",
    "        words = word_tokenize(sentence)\n",
    "\n",
    "#         Step 5: Removing Stop Words and words with synonyms\n",
    "#         words = [word for word in words if word not in stopwords.words('english') and remove_synonyms(word) is not None]\n",
    "\n",
    "#         Step 6: Word Stemming\n",
    "#         stemmer = PorterStemmer()\n",
    "#         words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "        preprocessed_document.append(words)\n",
    "    return preprocessed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e39cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('arxiv-metadata-oai-snapshot.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75a7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b64a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd65bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>23 pages, 3 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2008-01-13</td>\n",
       "      <td>[[Pan, Hongjun, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>11 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>None</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Callan, David, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>Alberto Torchinsky</td>\n",
       "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>None</td>\n",
       "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2013-10-15</td>\n",
       "      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0704.0996</td>\n",
       "      <td>Gautam Sengupta</td>\n",
       "      <td>Anurag Sahay, Gautam Sengupta</td>\n",
       "      <td>Brane World Black Rings</td>\n",
       "      <td>22 pages, 1 figures, typos corrected, referenc...</td>\n",
       "      <td>JHEP 0706:006,2007</td>\n",
       "      <td>10.1088/1126-6708/2007/06/006</td>\n",
       "      <td>IITK/PHY/2007/84</td>\n",
       "      <td>hep-th</td>\n",
       "      <td>None</td>\n",
       "      <td>Five dimensional neutral rotating black ring...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 9 Apr 2007...</td>\n",
       "      <td>2009-11-13</td>\n",
       "      <td>[[Sahay, Anurag, ], [Sengupta, Gautam, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0704.0997</td>\n",
       "      <td>Dan Coman</td>\n",
       "      <td>Dan Coman and Evgeny A. Poletsky</td>\n",
       "      <td>Stable algebras of entire functions</td>\n",
       "      <td>11 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CV</td>\n",
       "      <td>None</td>\n",
       "      <td>Suppose that $h$ and $g$ belong to the algeb...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 9 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Coman, Dan, ], [Poletsky, Evgeny A., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0704.0998</td>\n",
       "      <td>Louise Nyssen</td>\n",
       "      <td>Louise Nyssen (I3M)</td>\n",
       "      <td>Test vectors for trilinear forms, when two rep...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.NT</td>\n",
       "      <td>None</td>\n",
       "      <td>Let F be a finite extension of Qp and G be G...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 7 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Nyssen, Louise, , I3M]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0704.0999</td>\n",
       "      <td>George Lusztig</td>\n",
       "      <td>G. Lusztig</td>\n",
       "      <td>Generic character sheaves on disconnected grou...</td>\n",
       "      <td>12 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.RT</td>\n",
       "      <td>None</td>\n",
       "      <td>We relate a generic character sheaf on a dis...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 7 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Lusztig, G., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0704.1000</td>\n",
       "      <td>Liming Zhang</td>\n",
       "      <td>L.M. Zhang, et al (for the Belle Collaboration)</td>\n",
       "      <td>Measurement of D0-D0bar mixing in D0-&gt;Ks pi+ p...</td>\n",
       "      <td>6 pages, 4 figures, Submitted to Physical Revi...</td>\n",
       "      <td>Phys.Rev.Lett.99:131803,2007</td>\n",
       "      <td>10.1103/PhysRevLett.99.131803</td>\n",
       "      <td>BELLE-CONF-0702</td>\n",
       "      <td>hep-ex</td>\n",
       "      <td>None</td>\n",
       "      <td>We report a measurement of D0-D0bar mixing i...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 7 Apr 2007...</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>[[Zhang, L. M., ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           submitter  \\\n",
       "0    0704.0001      Pavel Nadolsky   \n",
       "1    0704.0002        Louis Theran   \n",
       "2    0704.0003         Hongjun Pan   \n",
       "3    0704.0004        David Callan   \n",
       "4    0704.0005  Alberto Torchinsky   \n",
       "..         ...                 ...   \n",
       "995  0704.0996     Gautam Sengupta   \n",
       "996  0704.0997           Dan Coman   \n",
       "997  0704.0998       Louise Nyssen   \n",
       "998  0704.0999      George Lusztig   \n",
       "999  0704.1000        Liming Zhang   \n",
       "\n",
       "                                               authors  \\\n",
       "0    C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                      Ileana Streinu and Louis Theran   \n",
       "2                                          Hongjun Pan   \n",
       "3                                         David Callan   \n",
       "4             Wael Abu-Shammala and Alberto Torchinsky   \n",
       "..                                                 ...   \n",
       "995                      Anurag Sahay, Gautam Sengupta   \n",
       "996                   Dan Coman and Evgeny A. Poletsky   \n",
       "997                                Louise Nyssen (I3M)   \n",
       "998                                         G. Lusztig   \n",
       "999    L.M. Zhang, et al (for the Belle Collaboration)   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Calculation of prompt diphoton production cros...   \n",
       "1             Sparsity-certifying Graph Decompositions   \n",
       "2    The evolution of the Earth-Moon system based o...   \n",
       "3    A determinant of Stirling cycle numbers counts...   \n",
       "4    From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "..                                                 ...   \n",
       "995                            Brane World Black Rings   \n",
       "996                Stable algebras of entire functions   \n",
       "997  Test vectors for trilinear forms, when two rep...   \n",
       "998  Generic character sheaves on disconnected grou...   \n",
       "999  Measurement of D0-D0bar mixing in D0->Ks pi+ p...   \n",
       "\n",
       "                                              comments  \\\n",
       "0              37 pages, 15 figures; published version   \n",
       "1                To appear in Graphs and Combinatorics   \n",
       "2                                  23 pages, 3 figures   \n",
       "3                                             11 pages   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "995  22 pages, 1 figures, typos corrected, referenc...   \n",
       "996                                           11 pages   \n",
       "997                                               None   \n",
       "998                                           12 pages   \n",
       "999  6 pages, 4 figures, Submitted to Physical Revi...   \n",
       "\n",
       "                                   journal-ref                            doi  \\\n",
       "0                     Phys.Rev.D76:013009,2007     10.1103/PhysRevD.76.013009   \n",
       "1                                         None                           None   \n",
       "2                                         None                           None   \n",
       "3                                         None                           None   \n",
       "4    Illinois J. Math. 52 (2008) no.2, 681-689                           None   \n",
       "..                                         ...                            ...   \n",
       "995                         JHEP 0706:006,2007  10.1088/1126-6708/2007/06/006   \n",
       "996                                       None                           None   \n",
       "997                                       None                           None   \n",
       "998                                       None                           None   \n",
       "999               Phys.Rev.Lett.99:131803,2007  10.1103/PhysRevLett.99.131803   \n",
       "\n",
       "            report-no       categories  \\\n",
       "0    ANL-HEP-PR-07-12           hep-ph   \n",
       "1                None    math.CO cs.CG   \n",
       "2                None   physics.gen-ph   \n",
       "3                None          math.CO   \n",
       "4                None  math.CA math.FA   \n",
       "..                ...              ...   \n",
       "995  IITK/PHY/2007/84           hep-th   \n",
       "996              None          math.CV   \n",
       "997              None          math.NT   \n",
       "998              None          math.RT   \n",
       "999   BELLE-CONF-0702           hep-ex   \n",
       "\n",
       "                                               license  \\\n",
       "0                                                 None   \n",
       "1    http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2                                                 None   \n",
       "3                                                 None   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "995                                               None   \n",
       "996                                               None   \n",
       "997                                               None   \n",
       "998                                               None   \n",
       "999                                               None   \n",
       "\n",
       "                                              abstract  \\\n",
       "0      A fully differential calculation in perturba...   \n",
       "1      We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2      The evolution of Earth-Moon system is descri...   \n",
       "3      We show that a determinant of Stirling cycle...   \n",
       "4      In this paper we show how to compute the $\\L...   \n",
       "..                                                 ...   \n",
       "995    Five dimensional neutral rotating black ring...   \n",
       "996    Suppose that $h$ and $g$ belong to the algeb...   \n",
       "997    Let F be a finite extension of Qp and G be G...   \n",
       "998    We relate a generic character sheaf on a dis...   \n",
       "999    We report a measurement of D0-D0bar mixing i...   \n",
       "\n",
       "                                              versions update_date  \\\n",
       "0    [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1    [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "2    [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2008-01-13   \n",
       "3    [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2007-05-23   \n",
       "4    [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2013-10-15   \n",
       "..                                                 ...         ...   \n",
       "995  [{'version': 'v1', 'created': 'Mon, 9 Apr 2007...  2009-11-13   \n",
       "996  [{'version': 'v1', 'created': 'Mon, 9 Apr 2007...  2007-05-23   \n",
       "997  [{'version': 'v1', 'created': 'Sat, 7 Apr 2007...  2007-05-23   \n",
       "998  [{'version': 'v1', 'created': 'Sat, 7 Apr 2007...  2007-05-23   \n",
       "999  [{'version': 'v1', 'created': 'Sat, 7 Apr 2007...  2019-08-12   \n",
       "\n",
       "                                        authors_parsed  \n",
       "0    [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1             [[Streinu, Ileana, ], [Theran, Louis, ]]  \n",
       "2                                   [[Pan, Hongjun, ]]  \n",
       "3                                  [[Callan, David, ]]  \n",
       "4    [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]  \n",
       "..                                                 ...  \n",
       "995          [[Sahay, Anurag, ], [Sengupta, Gautam, ]]  \n",
       "996          [[Coman, Dan, ], [Poletsky, Evgeny A., ]]  \n",
       "997                          [[Nyssen, Louise, , I3M]]  \n",
       "998                                  [[Lusztig, G., ]]  \n",
       "999                                 [[Zhang, L. M., ]]  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ca644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['perturb', 'chromodynam', 'photon', 'hadron', 'collid', ''], ['nexttolead', 'perturb', 'quarkantiquark', '', 'gluon', '', '', '', 'gluongluon', 'subprocess', '', 'allord', 'resumm', 'initialst', 'gluon', 'nexttonexttolead', 'logarithm', ''], ['the', ''], ['fermilab', 'tevatron', '', 'cdf', ''], ['diphoton', 'hadron', 'collid', '', 'lhc', '', ''], ['diphoton', 'higg', 'boson', 'lhc', '', '']]\n",
      "[['we', '', '', '', '', 'ell', '', '', 'pebbl', '', '', '', '', 'ell', '', '', 'algorithm', ''], [''], ['', 'pebbl', 'streinu', 'tuttenashwilliam', 'arbor', ''], ['we', '', '', '', 'ell', '', '', 'pebbl', ''], ['our', 'pebbl', 'gabow', '', 'gabow', 'westermann', 'hendrickson', '']]\n",
      "[['the', 'earthmoon', '2004', '', ''], ['the', 'earthmoon', 'moonearth', ''], ['the', '259000', '', 'roch', ''], ['the', 'tidal', 'earthmoon', ''], ['the', 'earthmoon', '439', '', '', '', '', '', '', ''], ['thi', '438', '', '', '', '', '']]\n",
      "[['we', 'stirl', 'singlesourc', ''], ['the', 'biject', 'signrevers', '']]\n",
      "[['', '', '', '', '', '', 'alphag', '', '', 'dyadic', ''], ['thi', '', '', '', '', 'dyadic', '']]\n",
      "[['we', 'twoparticl', 'tunabl', 'feshbach', ''], ['the', 'boson', '', ''], ['threedimension', ''], [''], ['offdiagon', '', 'odlro', '', ''], ['bc', ''], ['', 'odlro', 'boson', ''], ['', '', 'kf', '', '', '', '', '', '', '', '', '']]\n",
      "[['', 'polym', '', ''], ['', ''], ['schroeding', 'polym', ''], ['the', ''], ['', 'polym', 'schroeding', 'polym', ''], ['continuum', '', '', 'schroeding', ''], ['we', '', 'oscil', '', '']]\n",
      "[[''], ['', '', ''], ['the', '', ''], ['the', '', 'shockinduc', '', ''], ['these', '', 'without', 'spatiallyresolv', ''], ['', 'quasiisentrop', 'shockreleas', '', '']]\n",
      "[['we', 'irac', 'c2d', 'spitzer', 'serpen', 'starform', ''], ['bona', 'fide', '', 'yso', '', 'extragalact', ''], ['we', 'yso', ''], ['we', '235', '085', 'deg2', 'irac', ''], ['yso', '2mass', 'photometri', ''], ['we', '', 'colorcolor', 'stardiskenvelop', 'subset', 'stardisk', ''], ['these', '', 'mani', 'activ', ''], ['we', 'yso', 'serpen', '001', 'lsun', '260', ''], ['the', 'yso', 'extragalact', 'yso', ''], ['nomin', 'lessevolv', 'yso', 'extragalact', 'twopoint', 'extragalact', ''], ['we', 'xray', 'serpen', 'yso', 'spitzer', '']]\n",
      "[['subgraph', 'hypercub', ''], ['semicub', '', 'djokovi', '', '', '', 'winkler', ''], ['these', 'arbitrari', ''], [''], ['the', '', ''], ['', '']]\n",
      "[['heck', 'eigensystem', 'hilbertsiegel', ''], ['we', '', '', 'sqrt', '', '', '', '', ''], ['', 'hilbertsiegel', 'eigenform', 'eigenform', '']]\n",
      "[['', 'bruinier', '', '', '', '', '', '', 'n0', '', '', '', 'infti', '', 'af', '', '', '', 'lambda12', '', '', 'gamma0', '', '', '', '', 'mathbb', '', '', '', '', '', '', '', 'modulo', '', '', ''], ['', 'rankincohen', '', 'modular', '', 'geq', '', ''], ['', 'modulo', '', 'pgeq5', '', '', 'hurwitz', ''], ['we', 'overpartit', '']]\n",
      "[['serr', 'padic', 'coeffici', 'modular', '', 'sl2', '', 'mathbb', '', '', '', '', '', 'p2357', '', ''], ['', 'serr', 'holomorph', 'modular', '', '', '', '', '4n', '', '', '', 'n124', '', ''], ['among', 'coeffici', 'modular', ''], ['borcherd', '', 'eisentein', '', '', ''], ['', 'coeffici', 'siegel', 'modular', 'maass', 'ikeda', '']]\n",
      "[['integr', '']]\n",
      "[['the', 'spinor', 'tendimension', 'superstr', 'supersymmetr', '', 'integr', 'spinor', 'superspac', ''], ['thi', 'integr', 'kinemat', 'oneloop', 'twoloop', 'massless', 'fourpoint', 'ramond', '']]\n",
      "[['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['we', 'nonspect', 'cabibbosuppress', ''], ['the', 'hadron', 'nonrelativist', 'oscil', ''], ['our', 'diquark', ''], ['', 'selex', ''], ['thi', 'would', '', 'selex', '', '']]\n",
      "[['', '', 'hya', '1991', '2001', ''], ['spinmodul', ''], ['the', '500600', ''], ['these', '', 'corot', 'roch', ''], ['', 'tomogram', ''], ['these', '', 'wynn', '', '1999', '', '', 'bell', 'et', ''], ['', '2002', '', 'norton', 'et', ''], ['', '2004', '', 'hya', '', 'roch', ''], ['onto', 'magnetospher', '', 'bell', 'et', ''], ['', '2005', '', 'hya', ''], ['hbeta', 'hgamma', '', 'halpha', '', '', '', 'broadbas', '', '', '']]\n",
      "[['we', 'callia', '', ''], ['we', ''], ['we', 'selfdual', 'evendimension', '', '', ''], ['we', '']]\n",
      "[['onedimension', 'gr', '', 'obner', '']]\n",
      "[['the', 'hadron', '', 'q2', '', 'd0', '', '', 'nue', ''], ['we', 'fb', '', '', 'babar', 'pepii', 'electronpositron', 'collid', ''], ['the', '', 'd0', '', '', '', 'rd', '', '', 'd0', '', '', 'nue', '', '', 'd0', '', '', '', '', '0927', '', '0007', '', '0012', ''], ['from', '', '', 'd0', '', '', '', '', 'q20', '', '', '0727', '', '0007', '', '0005', '', '0007', 'statist', '', '', '', '']]\n",
      "[['productactiv', 'enzym', 'enzym', ''], ['stochast', 'catalyt', 'enzym', ''], ['the', 'meanfield', 'hopf', '']]\n",
      "[['we', 'nonlinear', 'stochast', 'noncommut', 'whose', ''], ['', 'stochast', 'via', '', 'algebra', 'via', ''], ['we', 'stochast', 'algebra', 'via', '', ''], ['we', 'stochast', 'munthekaa', 'determinist', ''], ['we', 'stochast', 'castel', '', ''], ['these', 'stochast', ''], ['they', 'stochast', 'munthekaa', ''], ['', 'castel', '', 'uniformli', 'stochast', ''], ['multipl', 'stochast', '']]\n",
      "[['the', 'solar', 'chromospher', '', 'structur', '', '', ''], ['chromospher', 'longstand', ''], ['solar', 'chromospher', 'carlsson', 'chromospher', '0850', ''], ['the', '', 'alma', '', '', 'solar', ''], ['', 'bima', '', '', '50150', '158', 'toward', 'shortperiod', 'internetwork', ''], ['', 'alma', '', 'solar', '']]\n",
      "[['the', 'quasi2d', 'spinwav', 'ferrimagnet', 'spaceresolv', 'brillouin', ''], [''], ['', 'socal', 'dipolar', ''], ['nonlinear', '', ''], ['the', '']]\n",
      "[['we', 'electronphonon', 'carlo', 'stochast', '', 'enabl', 'approximationfre', 'matsubara', ''], ['we', '', 'lehmann', '', 'frohlich', 'polaron', '', 'rashbapekar', 'excitonpolaron', '', 'jahntel', 'polaron', '', 'exciton', '', 'interact', 'phonon', 'tj', '']]\n",
      "[['zerodivisor', '', 'zd', '', 'cayleydickson', '', 'cdp', '', 'ndimension', 'hypercomplex', '', '', '', '', '', 'fractal', '', 'therebi', '', 'scalefre', ''], ['metafract', '', '', '', '', '', '', 'octahedr', '', 'boxkit', '', '', 'zd', '', ''], ['bitmanipul', '', '', 'fractal', 'other', '']]\n",
      "[['we', 'inplan', 'phonon', 'gammapoint', 'graphen', 'interlandaulevel', ''], ['the', '', 'gband', 'graphen', 'raman', '', 'interlandaulevel', '', '', '', '', '', '', '', '', '', 'b0', '', 'electronphonon', '', 'fillingfactor', 'circularli', '']]\n",
      "[['we', 'pfaffian', 'hafnian', 'lieb', 'inequ', 'semidefinit', ''], ['we', 'hafnian', 'inequ', 'revesz', 'sarantopoulo', 'function', '', 'sometim', '', '', '', '']]\n",
      "[['', 'xqm', '', '', 'goldston', 'boson', ''], ['the', 'goldston', 'boson', 'intepret', 'nucleon', 'flavorspin', ''], ['', '', 'xqm', '', 'goldston', 'boson', 'nucleon', ''], ['from', 'hamiltonian', '', 'xqm', '', '', ''], ['goldston', 'boson', 'nucleon', 'flavorspin', '']]\n",
      "[['we', 'phonon', 'electronphonon', 'dmft', ''], ['', 'electronphonon', '', '', '', '', 'bandmott', 'phonon', ''], ['', '', 'sinc', 'sensit', '', ''], ['', '', 'the', 'kondo']]\n",
      "[['we', '', '', '', '', '', '', '', '', ''], ['thi', 'sampledandhold', ''], ['tev', 'hadron', 'collid', '', '', 'diffract', 'proton', ''], ['we', '100fold', ''], ['proton', '01', 'microrad', ''], ['thi', 'proton', 'lhc', '']]\n",
      "[['we', 'neutrino', '', 'nsi', '', '', 'neutrino', 'supernova', '', '', 'we', 'nsi', 'neutrino', 'threeneutrino', '', 'nsiinduc', '', 'deleptonis', ''], ['we', 'nsi', 'cherenkov', '', 'either', '', 'barnu', '', '', '', '', '', '', '', '', '', '', '', 'detect', 'neutron', '', 'nue', '', ''], ['we', '', 'barnu', '', 'nsiinduc', ''], ['thi', 'nonunivers', 'nsi', '', '', 'flavorchang', 'nsi', '', '', '', '', '']]\n",
      "[['we', '', 'dda', '', ''], ['we', '', 'dda', ''], ['', 'cubic', 'noncub', 'scatter', ''], ['', 'cubic', 'noncub', ''], ['the', '', 'dda', 'scatter', 'dda', '']]\n",
      "[['thi', 'arxiv', '', 'qbio0701050', '', '1990', '']]\n",
      "[['we', ''], ['the', 'mani', 'discret', ''], ['the', 'discret', 'cubic', ''], [''], ['we', '', ''], ['discret', '']]\n",
      "[['the', 'multisit', 'phosphorylationdephosphoryl', 'repeatedli', ''], ['thi', 'bistabl', 'ultrasensit', 'without', ''], ['', 'multisit', 'phosphorylationdephosphoryl', '', ''], ['we', 'analyt', '', '', '', 'n1', '', '', '', '', '', '', '', '2n1', '', '', 'n2', '', 'mapk', '', '', '', '', '', 'michaelismenten', 'quasisteadi', '', 'n1', '', '', '', 'michaelismenten', 'quasisteadi', '', '']]\n",
      "[['', 'dda', '', '', 'dda', ''], ['m105', 'mie', ''], ['angleresolv', 'comput', 'steepli', '', ''], ['the', 'parallel', 'dda', '', '', ''], ['']]\n",
      "[['we', '', 'dda', '', '', ''], ['we', '', ''], ['we', 'dda', '', ''], ['', 'dda', 'among', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', '', 'r2rapi', '', 'pipi', ''], ['', 'yndurain', '', 'omn', '', 'isospin', '', '', 'nonstrang', '', 'r2rapis075pm', '007', 'fm2', ''], ['thi', 'muskhelishviliomn', '', '', 'r2rapis061pm', '004', 'fm2', ''], ['', '', ''], ['we', 'reanalyz', 'yndurain', 'pipi', '', 'swave', 'i0', 'tmatric', ''], ['', 'r2raspi065pm', '005', 'fm2', ''], ['the', 'swave', 'i0', 'pipi', ''], ['asymptot', '']]\n",
      "[['freeness', '', 'freeness', 'meaning', 'complexvalu', ''], ['', '', 'condit', 'rtransform', 'multilinear', '']]\n",
      "[['we', 'riemannian', 'riemannian', '', 'noncommut', '', '', '', 'isometr', '', 'noncommut', '', ''], ['', '', '', '', '', 'woronowicz', 'soltan', ''], ['we', 'noncommut', 'equivari', ''], ['we', 'commut', 'noncommut', '', '', '', 'hajac', '', 'holomorph', 'noncommut', '']]\n",
      "[[''], [''], [''], ['we', 'truthvalu', 'system', ''], ['']]\n",
      "[['we', 'nonequilibrium', '', 'lbm', '', ''], ['these', 'without', '', ''], ['', 'lbm', '', '', 'lbm', 'nonequilibrium', '', 'nonequilibrium', ''], ['', '', '', 'nonequilibrium', '', '', '', '', '', '', 'nonequilibrium', '', '', ''], ['the', 'lbm', '', ''], ['the', '', '1d', 'atherm', 'liddriven', '2000', '7500', '', ''], ['applic', 'entrop', 'nonentrop', 'quasiequilibria', '']]\n",
      "[['we', 'astrophys', '', 'solar', '', 'interstellar', '', '', '', ''], ['the', 'anisotrop', 'ion', 'cyclotron', ''], ['the', '', 'without', ''], ['collision', ''], [''], ['physic', '', ''], ['', 'inerti', '', 'ion', 'gyroscal', '', 'alfven', '', 'rmhd', 'collision', 'collisionless', '', 'compress', '', 'obey', 'alfven', ''], ['', '', 'ion', 'gyroscal', '', '', 'kineticalfvenwav', '', 'kaw', '', 'fluidlik', 'rmhd', 'phasespac', 'ion', ''], ['the', 'inertialrang', 'collisionless', 'waveparticl', 'ion', 'gyroscal', 'collision', 'ion', ''], ['the', 'kaw', 'gyroscal', ''], ['kolmogorovstyl', ''], ['astrophys', 'spacephys', '']]\n",
      "[['thi', 'shallowwat', 'nonlinear', 'variablecoeffici', 'kortewegd', 'vri', ''], ['we', 'whitham', '', 'integr', ''], ['thi', 'enabl', 'adiabat', '', 'chezi', '', '', 'undular', '', ''], ['', 'undular', ''], ['thi', 'nonloc', 'nonlinear', 'undular', '', 'adiabat', '']]\n",
      "[['', 'diosi', '', 'feldmann', 'kosloff', ''], ['the', ''], ['the', ''], ['the', 'per', 'classicalquantum', ''], ['both', '']]\n",
      "[['the', '', '', ''], ['the', 'aircraft', 'nondestruct', ''], ['thi', ''], ['the', '', ''], [''], ['', '', ''], ['the', '', 'sinc', ''], ['thi', 'nondestruct', 'aircraft', '']]\n",
      "[['we', 'lisa', '', 'mldc', '', ''], ['we', 'endtoend', 'gridbas', 'preprocess', '', 'carlo', 'postprocess', ''], ['we', '', 'carlo', ''], ['we', 'carlo', '']]\n",
      "[['we', 'fano', 'dpolytop', 'the', '', 'the', 'fano', 'dpolytop', '', ''], ['7622', 'fano', '6polytop', '72256', 'fano', '7polytop', '']]\n",
      "[['', '', ''], ['', 'ae', '', ''], ['ae', 'statist', ''], ['ae', ''], ['', '', '', '', 'ica', '', ''], ['the', 'ica', ''], ['the', 'nondestruct', 'aircraft', '']]\n",
      "[['', 'teleport', ''], ['the', 'physicist', 'teleport', 'nonscientist', ''], ['the', '', '', 'teleport', '']]\n",
      "[['we', 'spacetim', '', 'interact', '', 'spacetim', ''], ['we', 'riemannian', '', 'oneparamet', 'either', 'selfadjoint', ''], ['we', 'analyt', 'selfadjoint', 'semigroup', 'oneparamet', '', 'lorentzian', ''], ['the', '', 'whose', 'lorentzian', 'antid', '']]\n",
      "[['the', 'finsler', ''], ['we', 'global', '', '', '', 'mani', 'finsler', '', 'minkowskian', '', 'berwald', '', 'landesberg', '', 'landesberg', '', '', '', 'reduc', '', '', '', 'reduc', '', '', '', 'reduc', '', 'quasi', '', '', 'reduc', '', '', '', '', '', '', 'finsler', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['the', 'finsler', ''], ['finsler', ''], ['mani', '', '', 'global', ''], ['', ''], ['although', '', '', '', 'finsler', '']]\n",
      "[['hardylorentz', '', '', '', '', '', '', '', '', '', '', 'ple', '', '', '', '', 'qle', 'infti', '', ''], ['we', '', '', 'integr', '']]\n",
      "[['firstprincipl', ''], ['the', 'potassiumgraphit', 'semiloc', '', 'dft', '', ''], ['', 'intercal', 'interlay', 'nonloc', ''], ['thi', 'seamlessli', 'dft', 'waal', '', 'vdwdf', '', '', 'phi', ''], [''], ['lett', ''], ['', '246401', '', '2004', '', '', ''], ['the', 'vdwdf', '', ''], ['for', 'potassiumintercal', '', '', '', ''], ['subsurfac', ''], ['the', 'vdwdf', '', 'semiloc', '', '']]\n",
      "[['we', 'nemat', 'interact', 'via', 'gaussian', ''], ['relev', 'zerotemperatur', 'mani', '', '', ''], ['among', 'pressuredriven', '']]\n",
      "[['we', 'interplay', 'hund', 'twoorbit', 'eg', ''], ['we', ''], ['the', 'orbit', '', ''], ['we', 'hund', ''], ['halffil', '', '']]\n",
      "[['shall', ''], ['', 'shall', 'consensu', '', '', 'dobzhanski', '', 'mayr', '', ''], ['', 'shall', 'paradox', '', ''], ['', 'shall', '', 'would', ''], ['shall', 'unitar', '', 'teleolog', '', ''], [''], ['', 'shall', '', '', '', 'though', '', ''], ['shall', 'antimatt', ''], ['shall', '']]\n",
      "[['we', 'singlelin', 'hattr205013', '', 'f7v', 'mdwarf', ''], ['the', '', '', 'p2230736', '0000010', '', '', '', '', 'e0012', '0021', '', ''], ['we', 'singlelin', 'undergo', ''], ['thi', 'massradiu', '', 'mr2', '', '', ''], ['for', 'hattr205013', '', 'tidal', '', ''], ['our', '', '', '', 'rm', '', '', 'rm', '', '', '289', '', '', '', '', 'rm', '', '', '128', '004', '', 'rsun', ''], ['our', '', '', '', 'rm', '', '', '0167', '0006', '', 'rsun', '', 'semimajor', '', '', '', '754', '030', 'rsun', '', '00351', '00014', '', ''], ['our', 'singlelin', 'semimajor', '', '', '', 'rm', '', '', '0124', '0010', '', 'msun', '', '', 'rm', '', '', '104', '013', '', 'msun', ''], ['our', 'hattr205013', 'massradiu', '', 'doublelin', ''], ['the', 'massradiu', '']]\n",
      "[['we', 'lowli', '', '', '', '', 'sim10500', '', 'mevnucleon', '', ''], ['', 'e1', '', '', 'e2', '', '', 'mevnucleon', ''], ['relev', 'mevnucleon', 'mevnucleon', ''], ['radioact', '']]\n",
      "[['', '', 'relev', ''], ['the', '', '', '', ''], ['the', '', '', '', 'koldobski', '', 'finitedimension', 'subspac', '', '', ''], ['', 'onto', 'subspac', 'integralgeometr', ''], ['we', '', '', ''], [''], ['we', '']]\n",
      "[['', 'viterbi', '', 'hmm', '', ''], ['our', 'twostat', 'hmm', '', '', '', '', 'hmm', '', 'theta', '', 'mlog', '', '', '', 'without', 'viterbi', ''], ['viterbi', '', '', '', '', '', '', 'genom', 'chromosom', '', ''], ['we', 'viterbi', 'hmm', '']]\n",
      "[['neutrinoless', 'nonacceler', ''], ['thi', 'neutrinoless', '76ge', ''], ['76ge', '', 'igex', 'heidelbergmoscow', 'neutrinoless', ''], ['neutrinoless', '']]\n",
      "[['we', 'offshel', 'onshel', 'nilpot', 'becchirouetstoratyutin', '', 'brst', '', 'antibrst', 'lagrangian', '', '', '', '', '4d', '', '', '', 'abelian', '1form', 'superfield', ''], ['', '', '', 'nilpot', '', '', '', 'lagrangian', '', 'superfield', ''], ['', '4d', '', '', 'abelian', '1form', '', 'superfield', '4d', '', '', '', 'supermanifold', 'parametr', 'spacetim', 'xmu', '', 'mu', '', '', '', '', '', 'grassmannian', 'theta', 'bartheta', ''], ['nilpot', '', '', 'brst', '']]\n",
      "[['we', ''], ['schur', ''], ['the', 'coeffici', 'littlewoodrichardson', ''], ['we', 'sagan', ''], ['the', ''], ['we', 'equivari', 'grassmannian', 'coeffici', ''], ['the', 'knutson', 'combinator', ''], ['we', 'littlewoodrichardson', 'algebra', 'casimir', 'algebra', 'imman', 'okounkov', 'olshanski', '']]\n",
      "[['', '', 'lagrangian', '', '', 'spinor', '', ''], ['equationsrel', '', 'lagrangian', '', ''], ['the', 'paracommut', ''], ['the', ''], ['thi', 'via', 'redefinit', '', ''], ['that', 'admiss', ''], ['the', '', '', 'redefinit', ''], [''], ['the', 'bilinear', '']]\n",
      "[['epitaxi', 'selfassembl', '', 'saqd', '', 'nanostructur', 'optoelectron', '', 'photodetector', 'nanoscal', ''], ['saqd', ''], ['', '', ''], ['saqd', ''], ['filmheight', ''], ['atomicscal', 'random', '', '', '', '', 'saqd', 'nearcrit', ''], ['the', 'anisotropi', 'saqd', ''], ['', 'saqd', 'stochast', '', 'statist', 'saqd', '']]\n",
      "[['', 'petojev', '2006', '', '', 'petojevi', '', '', '', '', '', '', '', 'kurepa', '', 'kurepa', '1971', '', ''], ['', '', 'petojev', '2006', '', ''], ['', '', '', '', '', '', '', '']]\n",
      "[['the', '', 'invert', '', ''], ['we', 'cohomolog', 'subspac', 'subspac', ''], ['thi', 'cohomolog', '', '', ''], ['dynam', '', 'uniquess', ''], ['cohomolog', 'cohomolog', 'suffici', '', '', '', 'subsystem', '', ''], ['becaus', 'subsheav', 'subsheaf', 'cohomolog', ''], ['cohomolog', 'canon', 'derham', 'cohomolog', ''], ['our', 'holomorph', '']]\n",
      "[['the', 'fraction', 'aharonovbohm', '', 'fabo', '', '', ''], ['', '', ''], ['observ', '']]\n",
      "[['', '']]\n",
      "[['nonlinear', 'pde', ''], ['the', 'nonlinear', ''], ['', '', '', 'pde', '', '', ''], ['', 'firstord', 'pde', '', '', 'pde', ''], ['firstord', 'pde', 'pde', ''], ['the', '', 'mani', 'pde', ''], ['pde', 'nonlinear', 'pde', '']]\n",
      "[['we', 'kollar', 'inject', '', '', ''], ['', 'kollar', 'cohomolog', 'inject', ''], ['our', '', 'ahler', '', 'zariski', '', 'ahler', ''], ['we', 'neither', '', 'desingular', '', 'leray', '']]\n",
      "[['thi', 'socal', 'inject', 'morita', '', 'bimodul', 'morphism', 'inject', '', 'morita', '', '', '', 'bimodul', 'project', 'zimmermannhuisgen', '', ''], ['', 'bimodul', 'morphism', '', 'morita', 'semicontext', 'morita', '', ''], ['inject', 'morita', '', 'adstat', '', 'subcategori', 'subcategori', 'coloc', 'morita', ''], ['we', 'morita', '', '', '', 'ast', '', 'inject', 'morita', '']]\n",
      "[[''], ['we', 'swave', '', 'pwave', '', 'dwave', 'radial', '', '3p0', '', ''], ['', '']]\n",
      "[['kobayashimaskawa', 'cp', '', 'cp', 'flavorchang', ''], ['the', '']]\n",
      "[['the', 'spacetim', ''], [''], ['thi', 'pesrpect', ''], ['', '']]\n",
      "[['we', 'spacetim', ''], ['we', 'revisit', 'spheric', 'ndimens', ''], ['thi', 'brane', '']]\n",
      "[['we', 'nonselfadjoint', 'algebra', '', '', 'e1', '', '', '', '', '', '', '', '', 'f1', '', '', '', '', '', '', '', '', '', '', 'ei', '', '', 'fj', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ek', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['these', 'algebra', '', 'toeplitz', 'algebra', '', '', '', '']]\n",
      "[['we', '', 'gcmf', '', 'halfmass', '', 'rhoh', '', 'mto', 'rhoh', 'gcmf', ''], ['we', 'toward', '', 'twobodi', ''], ['we', 'gcmf', '', 'rhoh', '', '', 'galactocentr', 'rgc', '', 'relaxationdriven', 'massloss', 'dmdt', '', 'muev', '', 'rhoh', '', '', ''], ['', 'wellknown', 'mto', 'rgc', ''], ['thi', '', '', 'gcmf', '', 'mto', 'rhoh', '', 'relaxationdriven', '', 'rhoh', 'rgc', ''], ['our', 'tidal', '', 'muev', '', 'rhot', '', '', 'muev', '', 'sigmat', '', '', '', 'physic', '', 'rhot', 'sigmat', '', 'rhoh', ''], ['', 'muev', 'gcmf', '', 'although', 'toward', '', ''], ['our', 'anisotropi', '']]\n",
      "[['we', 'd4', 'poincar', 'algebra', ''], ['poincar', 'algebra', 'rmatric', 'zakrzewski', 'abelian', ''], ['rmatric', 'zakrzewski', '']]\n",
      "[['we', 'f1', 'spinor', 'boseeinstein', '', 'bec', '', '', 'integr', 'spinor', 'nonlinear', 'schr', '', '', '', 'dinger', 'selffocus', 'nonlin', ''], ['we', 'nonvanish', ''], ['the', ''], ['onesoliton', ''], ['', '', 'domainwal', '', 'dw', '', 'phaseshift', '', '', ''], ['the', 'dwtype', 'ferromagnet', 'nonzero', 'pstype', '', ''], ['we', 'twosoliton', ''], ['', 'spinmix', 'dwtype', ''], ['the', ''], ['', 'matterwav', 'spinor', 'bec', '']]\n",
      "[['the', 'geometri', 'microcanon', ''], ['thi', '', '', '', 'spacetim', 'geometri', 'saddlepoint', '', 'lorentzian', '', ''], ['they', 'instanton', ''], ['inflationari', 'instanton', 'undergo', 'whose', 'lowenergi', 'dynam', ''], ['', '', '', '', 'quasiequilibrium', 'microcanon', '']]\n",
      "[['we', 'freeli', ''], ['we', 'largescal', 'hydrodynam', '', 'inelast', ''], ['we', 'lagrangian', 'nonstationari', ''], ['these', '', ''], ['the', 'closepack', ''], ['', '', '', '', 'sim', '', 'tct', '', '', '', '', '', ''], ['the', '', 'sim', '', '', 'tct', '', '', '', '', '', '', 'discontinu', '', ''], ['the', '', 'isobar', '', ''], ['', '', '', '', '', 'hydrodynam', ''], ['we', 'onedimension', 'hydrodynam', 'numer', ''], ['', 'univers', '', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'covari', 'spacetim', 'ppwave', ''], ['spacetim', 'lagrangian', '', '', 'ppwave', '', 'offshel', '', 'scalar', ''], ['tensori', ''], ['boson', 'onshel', 'ppwave', 'worldsheet', 'whose', 'ppwave', ''], ['worldsheet', 'conform', ''], ['we', 'ppwave', 'nonpolynomi', '', 'csft', '', ''], ['', 'offshel', 'ppwave', 'ansatz', 'dilaton', 'redefinit', 'csft', ''], ['becaus', 'offshel', 'ppwave', ''], ['', 'massless', 'ppwave', '', 'csft', ''], ['boson', 'neveuschwarz', 'superstr', '']]\n",
      "[['we', 'stochast', 'onedimension', ''], ['', '', '', ''], [''], ['when', '', '', '', 'whose', ''], ['we', 'asymptot', '', 'kn', '', '', '', '', 'nto', 'infti', '', '', '', 'kn', '', '', '', '', '', '', '', ''], ['our', '', 'kn', '', '', '', ''], ['', '']]\n",
      "[['our', '', '', '', '', '', '', '', '', '', '', '', 's1', '', '', '', '', 'n1', '', '', '', 'hmto', '', '', '', '', '', ''], ['', 'epsilon', '', '', '', '', 'hmto', '', '', '', '', '', '', '', '', 'f1', '', '', '', '', 'n1', '', '', 'epsilon', '', '', '']]\n",
      "[['the', '', 'energet', 'photon', ''], ['opal', '', '', 'nanosecond', 'luminisc', 'antistock', ''], ['opal', ''], ['opal', 'nonlinear', 'luminisc', 'disribut', 'emmit', 'opal', ''], ['nonlinear', 'longterm', 'luminisc', ''], ['luminisc', 'opal', '']]\n",
      "[['statist', ''], ['via', ''], ['the', 'object', ''], ['', '', 'optim', ''], ['nonparametr', ''], ['the', ''], ['', 'nonparametr', ''], ['the', '', ''], ['both', ''], ['from', '', '']]\n",
      "[['', 'rop', '', 'recurs', 'samplingoptim', ''], ['', 'asa', '', ''], [''], [''], ['pathtre', '', '', 'trd', '', 'among', '']]\n",
      "[['we', 'finit', 'torsionfre', 'finit', 'mani', ''], ['', 'embed', ''], ['', '', '', 'automorph', '', '', '', '', '', 'finit', 'kazhdan', '', '', 'conjugaci', '']]\n",
      "[['we', 'fermion', ''], [''], ['fermion', 'continuum', '']]\n",
      "[['selfenergi', 'oxid', ''], ['electronphonon', 'selfenergi', '', '', 'misconcept', 'oxid', ''], ['phonon', 'selfenergi', '', '', 'cuprat', 'superconductor', 'via', 'photoemiss', '', 'arp', '', '', '', 'renorm', '', 'interband', 'bilay', '', ''], ['we', '', '']]\n",
      "[['we', 'semianalyt', ''], ['we', 'lens', ''], ['', 'margin', '', 'cdm', '', 'cdm', '', '', '', '', 'msun', '', 'subhalo', '', '', '3000km', '', '', '', 'xray', '', '', '4200km', ''], ['these', '', '', 'acceler', 'cdm', 'without', ''], ['', '50005400km', '', '', 'would', 'subclust', ''], ['', '', '', '4500km', '', '', '', 'would', 'unrealist', '', 'cdm', '', '7x', '', '', 'msun', 'cdm', '', '', '', 'msun', ''], ['our', 'generalis', '', 'eg', '', '', '4500km', '', 'mondian', 'lens', 'et', ''], ['', '2007', '', ''], ['', 'mondian', '', '', 'hdm', '', '06time', '', '', 'msun', '', 'cdm', '', '1time', '', '', 'msun', '', 'lens', '']]\n",
      "[['we', 'asymptot', 'arbitrari', ''], ['thi', 'via', 'geometri', 'pansu', ''], ['', 'commensur', '', 'we', 'asymptot', '', ''], ['renorm', '', ''], ['we', '', 'ergod', ''], ['we', 'burago', 'stoll', 'nilpot', '']]\n",
      "[['248dimension', 'algebra', '', 'algebra', 'fortyfour', '', 'twentyeight', 'fortyfour', '']]\n",
      "[['we', 'conform', ''], ['our', ''], ['thi', 'longo', '']]\n",
      "[['', 'cdma', '', '', 'cdma', '', '', 'nonzero', '', 'statist', ''], ['the', ''], ['we', 'gaussian', '', 'biawgn', '', '', '', 'random', '']]\n",
      "[['for', 'semidefinit', '', '', '', '', '', 'ando', 'zhan', 'inequ', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'unitarili', '', 'nonneg', '', '', '', '', '', 'infti', '', '', '', '', ''], ['these', 'inequ', 'nonneg', 'concav', '', '', 'nonneg', '', '', '', 'bourin', 'uchiyama', '', 'kosem', '', ''], ['whether', 'inequ', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ando', '', '', '', '', '', '', 'nonneg', 'concav', '', '', '', '', ''], ['we', '', '', 'affirm', '', '', ''], ['', '', '', 'majoris', 'hermitian', '', '', '', 'hermitian', '', 'bourinuchiyama', 'kosem', '', '']]\n",
      "[['the', ''], ['the', ''], ['', '', '', '', 'n1', '', 'spacetim', ''], ['', '', 'either', '', 'spacetim', ''], ['', '', 'the', ''], ['', '', '', '', 'n2', '', '', '', '', '', '', 'n1', '', 'nonaxisymmetr', 'asymptot', 'spacetim', '']]\n",
      "[['1968', '1974', 'veneziano', 'boson', '']]\n",
      "[['we', 'algebra', 'cohomolog', '']]\n",
      "[['the', 'piecewis', '', 'c0', '', ''], ['the', 'discontinu', 'hypersurfac', ''], ['the', 'meanvalu', 'geometri', 'hypersurfac', '', ''], ['', '']]\n",
      "[['orient', 'selfdual', '', 'algebra', '', '', '', 'algebra', 'endomorph', ''], ['we', 'serr', 'thi', ''], ['we', '']]\n",
      "[['we', 'symplect', '', 'symplectomorph', 'other', ''], ['we', '', '', 'hamiltonian', '', 'lagrangian', 'submanifold', '', 'palber', 'pbiranocornea', '', '', '', '', 'poissoncommut', 'subalgebra', ''], ['', 'semisimpl', 'homolog', 'symplect', ''], ['the', 'floertheoret', 'symplect', 'quasist', '']]\n",
      "[['antiquark', 'quarkquark', '', 'antiquark', '', 'cal', '', '', '', '', '', '', '', 'inelast', '', '', ''], ['', 'cal', '', '', '', 'alphas2', '', '', '', 'twistfour', 'quarkquark', '', 'antiquark', '', 'rescatt', 'landaupomeranchuckmidg', '', 'lpm', '', 'gluon', 'bremsstrahlung', 'parton', ''], ['quarkgluon', '', '', '', '', 'quarkquark', '', 'antiquark', '', '', '', 'cfca49', '', 'gluon', ''], ['kinemat', ''], ['the', '', 'antiquark', '', 'quarkantiquark', 'antiquark', '', '', ''], ['the', 'antiquark', 'antiquark', '', 'qualit', 'hadron', 'semiinclus', ''], ['the', 'quarkantiquark', 'gluon', 'fraction', '', 'heavyion', '']]\n",
      "[[''], ['the', 'whose', ''], ['the', ''], ['the', '', '', 'creationannihil', '']]\n",
      "[['2sat', '']]\n",
      "[['from', 'firstprincipl', '', '', '', 'nanowir', 'halfmetal', ''], ['they', 'spindirect', '', ''], ['', 'ferromagnet', 'nanowir', 'spindirect', 'spinpolar', ''], ['the', 'spindepend', 'dopant', '', 'nanowir', ''], ['', 'spintron', 'nanowir', '']]\n",
      "[['we', 'arbitrari', '', 'countabl', '', '', '', '', '', 'cla', '', '', 'algebra', '', 'cla', '', 'equivari', '', 'gcla', '', '', '', 'cla', '', 'ergod', '']]\n",
      "[['we', '', 'g2', '', 'chern', 'homolog', '', 'suq', '', '', '', '', 'suq', '', '', '', ''], ['', '', 'g2', '', 'nontrivi', 'chern', 'equivari', '', 'suq', '', '', '', '']]\n",
      "[['zerodivisor', '', 'zd', '', 'cayleydickson', '', 'cdp', '', 'ndimension', 'hypercomplex', '', '', '', '', '', 'fractal', '', 'therebi', '', 'scalefre', ''], ['metafract', '', '', '', '', '', '', 'octahedr', '', 'boxkit', '', '', 'zd', '', ''], ['bitmanipul', '', '', 'fractal', 'other', '']]\n",
      "[['nanoelectron', ''], ['swnt', ''], ['', 'swnt', 'closepack', '', 'swnt', ''], ['', 'blodgett', 'monolay', 'swnt', '', 'coval', 'polym', 'function', 'pmpv', 'swnt', 'dce', ''], ['hysteresi', 'swnt', 'microscopi', 'raman', ''], ['the', 'monolay', 'swnt', 'microfabr', '', '3ma', 'swnt', '']]\n",
      "[['we', 's12', 'antiferromagnet', 'nearestneighbor', 'plaquett', 'fourspin', '', 'aw', ''], ['sandvik', '', 'phi', ''], [''], ['lett', ''], ['', 'bf', '', '', '227202', '', '2007', '', '', ''], ['thi', 'undergo', 'dimer', ''], ['we', 'dimer', '', 'dimer', '', 'lowenergi', '', 'quasiparticl', ''], ['we', '', ''], ['', 'meanfield', '', '', 'sinc', '', '']]\n",
      "[['we', 'homotopi', '', 'cal', '', ''], ['we', 'homotopi', 'selfequival', 'nonneg', '', 'cal', '', 'codimens', '']]\n",
      "[['we', 'spacetim', ''], ['nambugoto', '', '', '', '']]\n",
      "[['we', 'ion', ''], ['strongexcit', 'without', 'lambdick', '', 'hamiltonian', 'jaynescum', 'without', '', 'rwa', '', ''], ['the', 'enabl', 'eigensolut', '', 'rwa', ''], ['we', '', 'nonrwa', 'energ', 'rwa', ''], ['if', 'ion', '', 'ion', ''], ['without', 'rwa', '', 'relev', '', '']]\n",
      "[['we', 'layerbylay', 'singlecryst', 'al2o3', 'thinfilm', '', '', ''], ['singlecryst', 'aplan', '', 'o2', ''], ['the', 'al2o3', 'layerbylay', ''], ['xray', 'diffract', 'al2o3', '', ''], ['thi', '', ''], ['misfit', 'al2o3', 'underlay', '', '']]\n",
      "[['we', 'success', 'ceag', '', '', '', '', '', '', 'anisotrop', '', ''], ['we', 'ceag', '', '', '', '', 'undergo', 'antiferromagnet', '', '', 'rm', '', '', '', 'the', 'anisotrop', ''], ['the', '', '', '', 'metamagnet', '', '', 'rm', 'm1', '', '', '', 'koe', '', '', 'rm', 'm2', '', '', '', '447', 'koe', '', '', '', '', '', '', 'mu', '', 'rm', '', '', ''], ['the', '', 'cef', '', 'ceag', '', '', '', '', 'quasiquartet', ''], ['the', '']]\n",
      "[['', 'babar', 'bell', '', '', ''], ['', '', 'd0', 'kpi', '', '', '', 'yprime', '', '', '', '', 'cp', '', '', '', '', '', '', ''], ['the', '', '', 'besiii', '', '', '3770', '', '', ''], ['we', '', 'rm', '', ''], ['', 'besiii', '', 'dbar', '', '', '', 'cp', 'besiii', '']]\n",
      "[['n1', 'su', '', '', 'su', '', '', '', 'bifundament', '', 'seiberg', 'n1', ''], ['fterm', 'superpotenti', '', 'iia', 'brane', 'metast', 'nonsupersymmetr', ''], ['orientifold', '6plane', '', 'n1', 'su', '', '', '', '', '', 'bifundament', ''], ['', 'n1', 'su', '', '', 'sp', '', '', '', '']]\n",
      "[['dipoledipol', 'boseeinstein', 'spin', ''], ['we', '', 'hamiltonian', '', 'nonlinear', 'sigma', ''], ['grosspitaevskii', '', 'upon', 'geometri', 'longrang', 'anisotrop', 'dipoledipol', '']]\n",
      "[['the', 'phonon', '', '', 'numer', '', 'phonon', 'phaser', '', 'arxiv', '', 'condmat0303188', '', 'arxiv', '', 'condmat0402640', '', 'arxiv', '', 'nlincg0703050', '', 'longtim', 'refractor', '', '', 'determinist', 'electromagnet', ''], ['', 'depin', ''], ['thi', ''], ['the', 'refractor', '', ''], ['phonon', '']]\n",
      "[['we', 'pseudoconvex', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['anisotrop', 'thermoelast', ''], ['we', '', '', '', '', 'lq', '', '']]\n",
      "[['the', 'currentvoltag', '', '', 'mgb2', 'caxi', ''], ['mu0h', '5t', '', 'liquidglass', 'isotherm', ''], ['', 'quasitwodimens', '', 'quasi2d', '', ''], ['', 'mu0', '', '', '5t', '', '', 't17k', '', 'isotherm', '', 'dimension', ''], ['we', 'sigma', 'quasiparticl', ''], ['interestingli', '', 'quasi2d', '', 'selffield', '']]\n",
      "[['sub100', 'nanomagnet', 'technolog', '', ''], ['', '', 'nanodot', 'undergo', '', 'firstord', '', 'forc', '', ''], ['nanodot', '', 'forc', '', 'hysteresi', ''], ['the', 'nanodot', 'coerciv', 'forc', 'nanodot', ''], ['the', 'nanodot', '', 'nucleat', 'butterflylik', 'forc', 'micromagnet', ''], ['', 'forc', '', 'nucleat', '']]\n",
      "[[''], [''], ['sinc', '', ''], [''], ['to', 'xray', ''], ['the', '', 'selfconsist', ''], [''], ['we', 'swiftxrt', 'grb', ''], ['ccd', '', 'readoutmod', 'pileup', '', 'bin', '', ''], [''], ['the', '', '', 'wwwswiftacukxrtcurv', '', '', 'grb', 'xrt', ''], ['when', 'grb', '', '']]\n",
      "[['aubri', 'lagrangian', '', '', '', ''], ['', 'morsesard', '', '', 'subsolut', 'hamiltonjacobi', '']]\n",
      "[['algebra', '', '', 'algebra', 'superalgebra', 'cartan', 'algebra', ''], ['superalgebra', '', '', 'superbrown', 'supermelikyan', 'superalgebra', ''], ['superalgebra', 'cartan', '']]\n",
      "[['', '', 'basicparticl', '2000', '', 'johansson', '', ''], ['the', '', '', 'polariz', 'vacuuon', '', 'pvaculeon', 'vaculeon', '', '', '', '', '', 'interact', ''], ['the', '', 'nova', 'sci', '', '2005', '', 'journaleprint', ''], ['vacuuon', '']]\n",
      "[['we', 'electr', '', 'qpc', '', ''], ['sourcedrain', 'qpc', '', 'qpc', '', '', '', 'qpc', ''], ['the', 'qpc', 'qpc', ''], ['the', '', 'qpc', 'conduct', 'qpc', 'pinchedoff', ''], ['we', 'counterflow', 'phononinduc', 'qpc', '']]\n",
      "[['we', '62micron', '77micron', '', 'pah', '', 'qso', '', 'spitzerir', 'cloverleaf', 'lens', 'qso', '', 'h1413117', '', 'z256', '', ''], ['the', 'pah', 'farinfrar', 'ultralumin', 'pg', 'qso', '', 'starburst', 'cloverleaf', 'farinfrar', '', '54e12', 'lsun', '', 'lens', '', ''], ['the', 'cloverleaf', 'qso', '', 'lbol', '', '7e13', 'lsun', '', '', 'msunyr', '', '', '3e7yr', '', '']]\n",
      "[['causal', 'dissip', '', 'spacetim', 'qgp', ''], ['energymomentum', ''], ['qgp', '', '', 'eg', ''], ['equilibr', '', '', '', '', ''], [''], [''], ['for', '', 'causal', ''], ['nonequilibrium', '', '']]\n",
      "[['we', 'ion', 'timedepend', 'oscil', ''], ['the', 'ion', 'motion', 'laserinduc', ''], ['als', 'et', ''], ['', 'phi', ''], [''], ['lett', ''], ['', '220401', '', '2005', '', '', 'exponenti', 'could', '', '', 'gibbonshawk', '', 'hamiltonian', ''], ['we', '', 'ion', 'gibbonshawk', '', '']]\n",
      "[['the', '32dimension', 'interplay', 'trigintaduonion', 'octonion', 'sedenion', 'electromagnet', '', '', ''], ['trigintaduonion', 'electromagnet', '', '', '', '', '', ''], ['trigintaduonion', 'hyperstrong', 'strongweak', '', '', 'subquark', '', ''], ['the', '']]\n",
      "[[''], ['redirect', ''], [''], ['', 'oam', '', 'holonomi', '']]\n",
      "[['we', 'extrem', 'kerr', ''], ['for', '', 'ajm', '', '09524m', '', 'whose', 'lz', '', 'latu', 'rectum', ''], ['thi', '', '', '', ''], ['', 'sinc', '', '', 'horizonskim', '', ''], ['our', '', '', '', 'horizonskim', ''], ['the', '', '', 'horizonskim', '', 'toward', 'prograd', ''], ['', '', '', 'toward', '', ''], ['uptod', 'teukolskyflux', '', '', '', 'horizonskim', '', ''], ['kludg', 'postnewtonian', 'teukolskyflux', '', 'horizonskim', ''], ['we', '', '', ''], ['', 'spacebas', 'lisa', '']]\n",
      "[['highresolut', 'hst', 'widefield', '', '', '', '', 'm5', '', 'ngc', '5904', '', ''], ['the', '', ''], ['bimod', '', 'm3', '', '47tucana', '', 'ngc6752', '', ''], ['', '', 'm5', 'could', '', '', '2040', '', '', ''], ['tidal', ''], ['if', '', 'could', '', '', '']]\n",
      "[['adscft', 'antid', 'spacetim', ''], ['the', 'bekensteinhawk', '', '', '', 'wherea', 'sublead', 'ln', '', '', ''], ['thi', 'sublead', 'conform', '', 'eg', ''], ['onedimension', 'statist', '', ''], ['the', 'wellknown', 'twodimension', 'conform', '']]\n",
      "[['the', 'selfconsist', 'instanton', 'pseudoparticl', 'pseudoparticl', ''], ['the', 'pseudoparticl', '']]\n",
      "[['nonperturb', 'renorm', 'phi4', ''], ['', ''], ['would', 'hamiltonian', '', '', '', '', '', '', ''], ['we', 'wegner', '', '', ''], ['the', 'phi4', '', '', ''], ['we', 'coeffici', 'perturb', '', ''], ['wegnerhoughton', '']]\n",
      "[['instanton', 'interact', 'variat', ''], ['the', 'instanton', '', 'gluon', '', '', '', 'caloron', ''], ['the', 'oneloop', 'lagrangian', '']]\n",
      "[['we', 'discretuum', '', '', 'phi', '', '', '', '', 'phi', '', '', '', '', '', 'phi', '', '', '', '', 'random', ''], ['we', '', 'rho', '', 'phi', '', '', '', 'inflaton', ''], ['', 'infti', '', '', 'rho', '', 'phi', '', '', '', ''], ['the', 'exponenti', '', 'tto', 'infti', '', '']]\n",
      "[['sinc', 'iagrg', '2004', '', '', ''], ['the', '', 'observ', '', '', '', 'hamiltonian', ''], ['these', ''], ['thi', '', '', '', 'mathrm', '', '', '', '', 'iagrg', '2007', '']]\n",
      "[['', ''], ['the', 'parameter', '', 'gammaoint', '', 'rm', '', '', 'bf', '', 'cdot', '', 'bf', '', '', '', 'bf', '', '', '', '', '', '', 'bf', '', '', '', 'bf', '', '', '', ''], ['', 'superfluid', 'irrot', '', ''], ['superfluid', ''], ['bec', '', '', '', ''], ['the', 'fermion', 'superfluid', 'fermion', ''], ['bec', '', 'superfluid', '', 'nonlinear', '', 'typeii', 'superconductor', '']]\n",
      "[['statist', 'kim', '', 'mandel', '', ''], ['soc', ''], [''], ['', '433', '', '1987', '', '', 'stochast', 'nonimag', 'transmittedlight', ''], ['with', '', 'mueller', '', '', ''], ['', 'povm', '', ''], ['thi', '', 'ahnert', 'payn', '', 'phi', ''], [''], ['', '012330', '', '', '2005', '', '', '', 'photon', '', 'povm', '', 'enabl', 'mueller', '']]\n",
      "[['the', 'decoher', '', '', 't1', '', '', 't2', '', '', 'equationofmot', '', '', ''], ['', 'hyperfin', '', 'dresselhau', 'spinorbit', '', 'bulkphonon', '', '', '', '', 'spinphonon', 'phononinduc', '', '', 'bulksurfacephonon', 'hyperfin', ''], ['the', 'decoher', ''], ['', 'spinorbit', ''], ['the', 'equationofmot', '', 't1', '', 'dephas', '', 't2', '', '', 'either', 'markovian', 'nonmarkovian', ''], ['when', 'mani', '', 'spinorbit', ''], ['', 'andor', 'spinorbit', '', 'equationofmot', 'mani', ''], ['', 'dephas', '', 'though', '']]\n",
      "[['thi', 'cauchi', ''], ['the', ''], ['the', 'conform', '', 'lichnerowicz', '', ''], ['', 'conform', 'transversetraceless', 'conform', '', ''], ['', 'neutron', '', '']]\n",
      "[['the', 'spin12', '', '', '', 'j1', '', 'j2', '', 'j3', '', '', '', '', '', '', 'j1', '', 'j3', '', '', 'j2', '', '', '', '', '', '', 'j1', '', 'j2', '', '', 'j3', '', '', 'nonfrustr', '', ''], ['the', 'renorm', '', 'dmrg', '', '', 'renorm', '', 'tmrg', '', ''], ['the', '', '', ''], ['', '', 'wavevector', '', 'qapi', '', '', 'a012345', '', '', '', 'm16', '', 'q0', '', '', '2pi', '', '', '4pi', '', '', 'couplingsindepend', ''], ['the', 'dmrg', 'zerofield', 'nice', '', ''], ['lowli', ''], ['', 'doublepeak', '', ''], ['xxz', 'anisotropi', 'af', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'tmrg', '']]\n",
      "[['the', 'yyo', '', '', ''], ['the', '', '', 'pdf', '', 'whose', ''], ['yo', '', '', ''], ['the', 'upon', ''], ['the', ''], ['with', '', ''], ['the', ''], ['the', ''], ['yo', '', '', ''], ['the', 'pdf', ''], ['the', ''], ['the', 'determinist', '']]\n",
      "[['the', 'wignertransform', 'timedepend', 'hartre', '', 'fock', '', 'bogoliubov', '', '', ''], ['thi', 'particlenumb', ''], ['', ''], ['particlenumb', ''], ['eigenfrequ', 'semiclass', '', '', '2delta', '', '', ''], ['the', '']]\n",
      "[['oscil', '', '', ''], ['the', '', '', '', ''], ['thi', '', ''], [''], ['thi', 'oscil', 'halfinteg', '']]\n",
      "[['inmedium', 'selfenergi', 'hadron', ''], ['with', '', '', 'lagrangian', '', '', ''], ['we', 'hadron', 'massdepend', ''], ['quantit', '']]\n",
      "[['the', '', '', ''], ['we', '', 'statist', 'collision', 'radi', ''], [''], ['the', '', 'wwwsronrugnlvdtakradexindexshtml', ''], ['the', 'databas', '', 'lamda', '', '', ''], ['the', ''], [''], ['thi', '']]\n",
      "[['thi', '']]\n",
      "[['overview', 'multicompon', 'hardspher', ''], ['for', '', 'thermodynam', '', 'percusyevick', ''], [''], ['', 'squarewel', '', '']]\n",
      "[['', 'scaleinvari', '4737', ''], ['the', 'scaleinvari', '', '', '', '0309', '', '', '', '', '', 'deltac', '', '066', '', ''], ['the', ''], ['the', 'gaussian', '', '']]\n",
      "[['we', 'highresolut', 'angleresolv', 'photoemiss', '1textit', '', '', 'tise', '', '', '', '', '', '', 'roomtemperatur', '', 'lowtemperatur', '', 'chargedens', ''], ['photoemiss', '', 'renormalis', 'highsymmetri', 'brillouin', 'backfold', ''], ['exciton', ''], ['thi', 'exciton', 'chargedens', '1textit', '', '', 'tise', '', '', '', '', '', '']]\n",
      "[['we', 'hii', '', 'orl', '', 'collision', '', 'cel', '', 'interstellar', '', '', 'tenoriotagl', '', '1996', '', ''], ['', 'supernova', 'superbubbl', 'supernova', ''], ['supernova', '', 'metalrich', 'metalrich', 'droplet', ''], ['metalrich', 'droplet', 'photoion', ''], ['dure', '', 'metalrich', 'droplet', '', 'orlcel', ''], ['', 'the', 'astrophys', '', '']]\n",
      "[['we', '', 'cn', '', 'raman', '', 'gruneisen', 'phonon', ''], ['the', 'phonon', 'abinitio', 'phonon', ''], ['zonecentr', '', 'gruneisen', ''], ['the', 'phonon', 'librat', 'translat', 'cn', '', 'librat', ''], ['xray', 'diffract', '']]\n",
      "[['statist', ''], ['the', ''], ['sinc', '', ''], ['the', ''], ['from', '', ''], ['the', 'twodimension', 'random', '']]\n",
      "[['largescal', '', 'crucial', ''], ['for', 'quasicryst', '', '', 'inexist', ''], ['we', 'quasicrystallin', ''], ['we', 'socal', '', 'optim', ''], ['these', 'abinitio', ''], ['', 'eam', 'decagon', 'alnico', '', 'icosahedr', 'cacd', '', 'icosahedr', 'decagon', 'mgzn', 'quasicryst', ''], ['the', '']]\n",
      "[['', '', '', '', 'codimens', '', '', 'cinfti', '', '', '', '', ''], ['the', '', '', '', '', '', '', '', ''], ['', 'reeb', '', 'reeb', '', 'centertyp', ''], [''], ['eell', '', 'kuee', '', 'realvalu', 'nondegener', ''], ['', ''], ['to', '', 'codimens', '', 'centersaddl', 'saddlesaddl', '', '', ''], ['', '', 'haeflig', 'novikov', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['if', '', '', '', '', '', 'diffeomorph', '', 's1', '', '', 'haeflig', ''], ['', '', '', 'novikovtyp', '']]\n",
      "[['semisimpl', 'algebra', '', 'represen', 'we', 'mth', 'frobeniusschur', '', '', '', 'representationtheoret', ''], ['we', '', '', 'mth', 'for', 'algebra', '', '', '', '', '2n', '', '', '', '2n1', '', 'sp', '', '2n', '', '', '2n1', '', '4n5', '', '4n3', '2n1', '', '']]\n",
      "[['fraction', 'brane', 'whose', 'supersymmetr', '', 'dsb', 'brane', '', ''], ['we', '', 'via', 'noncompact', 'brane', '', 'metast', 'supersymmetri', '', 'sqcd', ''], ['we', 'simplifi', 'oneloop', 'pseudomoduli', 'via', ''], ['thi', ''], ['thi', '', 'dp1', '', 'hepth0607218', ''], ['the', 'dsb', 'brane', '', 'arbitrari', 'superpotenti', '']]\n",
      "[['', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', 'isgurwis', '', ''], ['the', 'heavylight', 'chiral', ''], ['coeffici', '', '1nc', '', 'chiral', 'lagrangian', '', '', 'heavylight', 'chiral', '']]\n",
      "[['we', 'radi', ''], ['undergo', '', 'synchrotron', 'ambient', ''], ['semianalyt', ''], ['the', 'synchrotron', '', 'blazar', '', '']]\n",
      "[['the', 'axion', ''], ['the', '', '', 'astrophys', '']]\n",
      "[['the', 'incommensur', 'spinpeierl', 'quasi', 'onedimension', 'spinpeierl', 'tiox', '', 'tiobr', 'tiocl', '', 'inelast', ''], ['the', 'anomal', 'firstord', 'spinpeierl', 'incommensur', 'spinpeierl', '', '', '', '', '', '', ''], ['the', 'interchain', 'spinpeierl', 'incommensur', ''], ['', 'raman', 'vocl', 'tiox', 'phonon', '']]\n",
      "[['the', 'monocero', 'snrrosett', 'veryhighenergi', '', 'vhe', '', 'gammaray', 'highenergi', 'egret', ''], ['vhe', ''], ['the', ''], ['highenergi', 'gammaray', ''], ['nanten', '', 'could', 'gammaray', 'via', 'hadron', ''], ['we', 'gammaray', '', 'j0632058', '', 'monocero', 'snr', ''], ['thi', ''], ['xray', '1rx', 'j0632583054857', '', 'bestar', 'mwc', '148', 'andor', 'gammaray', '3eg', 'j06340521', ''], ['']]\n",
      "[['we', 'twodimension', 'shastrysutherland', 'qualit', 'qubit', 'tetram', ''], [''], ['', '']]\n",
      "[['we', 'zno', ''], ['we', 'multicent', '']]\n",
      "[['the', '', '', '', 'btopipi', '', 'controversi', 'statist', '', 'frequentist', 'bayesian', ''], ['we', 'relev', '', '', ''], ['reparametr', ''], ['we', 'parametr', 'gronau', '', '', '', '', 'i32', '', '', 'isospin', ''], ['besid', '', '', '', 'parametr', '', 'relev', 'frequentist', 'bayesian', ''], ['the', 'relev', '', '', '', '', '', 'alphasim', 'pi4', '', '', 'arbitrari', '', 'i12', '', '']]\n",
      "[['although', 'gaussbonnet', '', '', 'solar', ''], ['we', 'solar', 'postnewtonian', 'distribut', ''], ['we', '', '1r7', '', 'lightbend', ''], ['we', '', 'cassini', '', '', 'gaussbonnet', ''], ['we', 'latetim', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'photochrom', 'diarylethen', 'selfconsist', 'nonequilibrium', ''], ['the', 'strikingli', ''], ['the', '', ''], ['the', ''], ['the', 'onoff', '', ''], ['', '']]\n",
      "[['', '', '', ''], ['the', '', ''], ['doublet', '']]\n",
      "[['we', ''], ['variat', 'multicompon', '', '', '', 'proton', ''], [''], ['we', ''], ['the', 'hugoniot', ''], ['the', 'equationofst', '']]\n",
      "[['we', 'tomograph', 'photon', ''], ['', 'although', '', 'tunabl', 'quantum', 'nonclass', ''], ['the', '']]\n",
      "[['', '', 'neutron', '', '', 'isovector', ''], ['critic', ''], ['the', 'gtr', '', '', ''], ['neutron', '']]\n",
      "[['we', '', '', 'photon', '', '', ''], ['our', ''], ['', 'gabas', ''], ['we', '', '']]\n",
      "[['we', 'xray', 'spectromicroscop', 'singlecrystallin', 'femnco', 'bilay', '', '001', '', '', 'xray', '', 'xmcd', '', '', 'xmld', '', 'dichroism', 'l3', 'photoelectron', 'microscopi', '', 'peem', '', ''], ['ferromagnet', 'antiferromagnet', 'femn', 'crystallograph', ''], ['we', 'xmld', '', 'magnetocrystallin', 'anisotropi', 'xmld', ''], ['we', '', 'ferromagnet', 'femnco', 'suffici', 'xmld', '']]\n",
      "[['thi', '', '1010', '', '', 'swcnt', '', '', '', '', 'tbmd', '', ''], ['we', '', '1010', '', '023', '006', '300k', ''], ['strech', ''], ['the', '', '', 'poisson', '010', '', '0395', 'tpa', '', '8323', '', '0285', '', '', '300k', ''], ['300k', '900k', '', 'poisson', ''], ['', 'poisson', ''], ['1200k', '1800k', '', 'swcnt', 'alreadi', ''], ['swcnt', '300k', '900k', '']]\n",
      "[['', 'agn', '', ''], ['extragalact', 'gev', 'tev', '', 'blazar', ''], ['agn', 'glast', '', 'obviou', '', '']]\n",
      "[['we', 'potfit', 'firstprincipl', ''], ['largescal', 'physic', ''], ['we', '', '', ''], ['the', 'success', 'intermetal', '', 'notabl', 'quasicryst', '']]\n",
      "[['we', 'neutrino', '', 'mavan', '', 'supersymmetr', ''], ['the', 'supersymmetri', '', 'supersymmetri', '', ''], ['neutrino', ''], ['neutrino', 'lefthand', 'neutrino', ''], ['the', 'lefthand', 'neutrino', '']]\n",
      "[['we', 'he23474342', '', 'whose', 'intergalact', 'heii', ''], ['heii', '', 'he23474342', '', 'qsoj235034328', '', 'z2282', '', '', 'vartheta359', '', 'arcmin', '', '', 'qsoj235004319', '', 'z2302', '', '', 'vartheta877', '', 'arcmin', '', 'qsoj234954338', '', 'z2690', '', '', 'vartheta1628', '', 'arcmin', '', ''], ['thi', 'overdens', 'largescal', ''], ['heii', '', 'extragalact', ''], ['we', 'he23474342', 'statist', ''], ['', ''], ['', ''], ['we', '', 'although', 'qsoj234954338', ''], ['', 'overdens', ''], ['', 'radi', 'intergalact', ''], ['from', 'qsoj234954338', 'myr', '']]\n",
      "[['we', '', 'random', ''], ['thi', 'enabl', 'random', ''], ['random', '', 'random', 'nonzero', 'random', ''], ['we', '']]\n",
      "[['the', '', 'k1', '', 'richard', 'higman', 'monoid', '', '', 'k1', '', '', 'monoid', '', 'inv', '', 'k1', '', '', 'biject', 'inject', ''], ['the', 'monoid', '', 'k1', '', '', '', ''], ['', 'k1', '', 'inv', '', 'k1', '', 'congruencesimpl', 'their', '', '', 'k1', '', 'inv', '', 'k1', '', 'j0simpl', '', 'k1', 'nonzero', 'dclass', ''], ['they', 'submonoid', 'multipl', 'cuntz', 'algebra', ''], ['they', 'finit', '', 'their', 'conpcomplet', ''], ['', '', '', '', ''], ['', '', '', '', '', '', '', '', '']]\n",
      "[['sk', 'neutrino', '', '', '', '', 'zenith', '', 'zenith', 'neutrino', ''], ['', '', 'sk', '', 'neutrino', ''], ['concret', '', 'muonlik', 'qel', ''], ['for', '', '', 'carlo', '', 'sk', ''], ['', '', '', 'without', ''], ['from', 'zenith', 'distributon', '', 'sk', '', '', '', '', 'neutrino', 'neutrino', 'sk', '', 'andor', 'neutrino', '']]\n",
      "[['protein', 'unexpect', '', 'polypeptid', ''], ['these', '', 'protein', ''], ['our', 'protein', '', '', ''], ['', 'ubiquitin', 'hydrolas', '', 'proteasom', ''], ['protein', 'typic', 'sometim', ''], ['', 'transcarbamylas', 'protein', ''], ['the', 'enzymat', 'protein', ''], ['we', 'unknot', 'protein', '']]\n",
      "[['we', '', '', 'halpha', 'whose', ''], ['we', '18m', 'perkin', '', '', '', ''], ['morpholog', '', 'irr', 'without', ''], ['the', '', '03', '', '', ''], ['the', 'halpha', ''], ['', 'masstoluminos', 'halpha', '']]\n",
      "[['we', 'realtim', 'domainwal', 'onedimension', 'anisotrop', 'ferromagnet', ''], ['', 'dynam', 'heisenbergis', ''], ['', '', '', '', '', '', '', '', '']]\n",
      "[['we', 'qubit', '', 'interact', '', '', ''], ['the', 'qubit', ''], ['we', 'qubitset', ''], ['decoher', 'qubit', '', 'qubit', ''], ['we', 'decoher', 'rabi', '', 'qubit', ''], ['thi', 'backact', 'qubit', ''], ['backact', '', '', 'qubitset', ''], ['either', 'strongcoupl', '', 'backact', ''], ['', 'qubit', 'strongcoupl', '', 'resembl', 'spinboson', '']]\n",
      "[['we', 'modular', 'frobeniusperron', 'pgroup', ''], ['we', 'nilpot', 'sylow', ''], ['if', 'frobeniusperron', 'grouptheoret', ''], ['', 'semisimpl', 'quasihopf', 'algebra', 'grouptheoret', ''], ['our', 'lagrangian', 'subcategori', 'modular', '', 'quasili', 'bialgebra', 'manin', '', '']]\n",
      "[['we', 'eikosiheptaplet', 'chral', ''], ['we', 'arbitrari', '']]\n",
      "[['random', 'boolean', ''], ['we', 'lynch', 'kauffman', 'random', '', '', ''], ['lynch', 'connect', 'boolean', ''], ['we', 'arbitrari', 'connect', '', '', 'random', 'boolean', ''], ['lynch', '', '', 'boolean', ''], [''], ['', 'connect', 'random', '']]\n",
      "[['we', 'polariton', 'inelast', 'microcav', ''], ['we', 'excitonphoton', 'nonperturb', 'exciton', 'photon', '', 'photon', 'electronhol', 'continuum', ''], ['', 'raman', 'phonon', 'polariton', 'iivi', 'microcav', 'cdte', '']]\n",
      "[['irreduc', 'coxet', '', '', '', '', '', '', '', 't1', '', 't2', '', '', '', 'td', '', '', 'coxet', '', '', '', 'csi1si2', 'cdotssid', '', 'coxet', '', '', '', '', '', '', 'sii', '', 'coxet', '', '', '', '', '', '', 'i12', '', '', '', '', '', '', '', '', '', '', '', 'i12', '', '', '', '', '', '', '', ''], ['for', '', ''], ['the', '', '', 'goulden', '', 'albeit', ''], ['we', '', 'bn', '', 'bona', '', 'bousquet', '', 'label', 'leroux', ''], ['our', '', 'dn', '', ''], ['these', '', '', '', '', 'r1le', 'r2le', '', 'rl', '', '', 'multichain', '', 'pi1l', 'pi2l', '', 'pil', '', 'noncross', 'poset', '', 'poset', '', 'pii', '', '', '', '', '', '', '', 'pi1', '', ''], ['we', 'enum', 'noncross', 'via', ''], ['', 'multichain', 'noncross', 'krewera', ''], ['', 'rankselect', '', 'dn', '', 'noncross', 'poset', '', '', '', '', '', '', 'dn', '', '']]\n",
      "[['the', 'electromagnet', 'polariz', 'nucleon', '', 'alphap', '', '', '', '', '', '', '', 'alphan', '', '', '', '', '', '', '', '', '', 'alphat', '', '', '', 'betat', '', '', '', '', '', '', '', '', '', '', '', '', '1232', '', '', '', '', '', '', '', '', '', '', ''], ['the', '', 'deltaalphap12pm', '06', '', '', '', 'deltabetap12mp', '06', '', '', 'deltaalphan08pm', '', '', 'deltabetan20mp', '', ''], ['thi', 'polariz', 'twophoton', '', 'sigma', '', '', 'msigma666', '', 'mev', 'twophoton', '', '', 'gammagamma', '', '', 'kev', '']]\n",
      "[['weyl', '', 'heck', 'algebra', 'heckeclifford', 'algebra', ''], ['for', 'algebra', '', 'pbw', '', 'intertwin', '', ''], ['we', 'algebra', '', ''], ['', 'heck', 'algebra', 'lusztig', 'heck', 'algebra', '']]\n",
      "[['we', 'measurementbas', ''], ['project', ''], ['thi', 'qubit', 'measurementbas', '']]\n",
      "[['we', 'spitzer', '348', ''], ['our', 'spitzer', 'ttauri', '0i', 'protostar', ''], ['the', '348', 'statist', 'diskless', ''], ['our', 'spitzer', '348', 'protostar', 'anticorrel', 'spatial', 'ttauri', '', 'central', ''], ['the', 'protostar', 'filamentari', ''], ['we', 'protostellar', '', 'starless', '', 'protostellar', '348', ''], ['we', '348', '', '', '', ''], ['', 'subclust', ''], ['', 'spitzer', '']]\n",
      "[['we', 'interact', 'superconduct', ''], ['josephson', 'superconduct', '', 'firstord', '', 'nonequilibrium', ''], ['both', 'andreev', 'josephson', ''], ['', '', 'supercurr', '']]\n",
      "[['we', 'xray', 'pulsar', 'psr', 'j13576429', '', 'kyr', '', 'xmmnewton', 'chandra', ''], ['we', 'powerlaw', '', 'photon', 'gamma14', 'kt160', ''], ['for', 'kpc', '', '210', 'kev', '12e32', 'erg', '', 'spindown', 'psr', 'j13576429', 'xray', ''], ['the', 'chandra', 'posit', 'pulsar', '3e31', 'erg', '210', 'kev', 'pulsar', ''], ['we', '', 'xray', 'pulsar', '']]\n",
      "[['we', 'twomod', ''], ['we', 'rateequ', 'random', ''], ['', 'timescal', '', 'lase', ''], ['the', 'onedimension', 'langevin', 'multipl', ''], ['our', '', '']]\n",
      "[['deconfin', 'neutron', 'astrophys', 'neutron', '']]\n",
      "[['we', ''], ['if', 'ostrik', '', ''], ['to', '', '', 'pivot', '', 'functor', '']]\n",
      "[['we', 'supernova', '', '', '1987a', '', 'chandra', 'xray', '', 'sinc', '1999', ''], ['we', '', 'chandra', '', '', '', 'chandra', '', '2006', '2007', ''], ['1987a', '', 'chandra', '', 'xray', '1987a', 'ringlik', 'circumstellar', '', 'csm', '', ''], ['the', 'csm', '', '1987a', 'xray', ''], ['', '2007', '', '', 'xray', '1987a', '', '', 'rm', '', '', '', 'sim', '', '', '', '', '', '', '', '', 'erg', '', '', '', '', '', '05', '', '', '', 'kev', ''], ['xray', 'twocompon', '', '', '', 'sim', '', '03', 'kev', ''], ['interact', 'csm', '', 'xray', '', '', '', 'sim', '', '1400', '', '', '', '', '', '2004', '', '', '', '', 'sim', '', '6000', '', '', '', '', '', '', '']]\n",
      "[['we', 'superpotenti', '', '', 'cohomogen', 'ricciflat', ''], ['we', '', '', 'superpotenti', '', '', ''], ['either', 'irreduc', 'summand', 'subsystem', 'superpotenti', 'calabiyau', 'fano', '', 'ahlereinstein', '']]\n",
      "[['the', 'semidegre', 'outdegre', 'indegre', ''], ['we', 'suffici', 'semidegre', 'n2', 'k1', 'klink', ''], ['the', 'semidegre', 'manoussaki', '1990', ''], ['we', 'semidegre', 'suffici', 'korder', '', ''], ['']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'twofield', '', ''], ['we', 'analyt', 'isocurvatur', '', 'slowrol', ''], ['we', 'numer', 'isocurvatur', ''], ['we', 'explicitli', '', '', '', '', 'isocurvatur', '']]\n",
      "[['thi', 'gct3', '', 'arxiv', '', 'cs0501076', '', 'cscc', '', '', ''], ['the', '', '', 'nonvanish', 'littlewoodrichardson', 'coeffici', '', 'combinator', '', 'vol', ''], ['', '', '2012', '', 'pp', ''], ['103110', ''], ['', '', 'ketan', 'mulmuley', '', 'hari', 'narayanan', 'milind', 'sohoni', '', 'the', 'gct5', '', '', 'blackbox', 'derandom', 'derandom', '', 'foc', '2012', '', '', '', 'arxiv12095993', '', 'cscc', '', '', '', '', '', 'ketan', 'mulmuley', '']]\n",
      "[['onedimension', '', 'ptsymmetr', 'shortrang', '', '', ''], ['rungekuttadiscret', 'schroeding', 'coeffici', 'via', 'complexif', 'potentialcharacter', '']]\n",
      "[['', 'tau', '', '', '', 'brownian', '', 'x1t', '', '', '', 'xtn', '', '', 'a1', '', '', '', '', '', '', '', 'x1', '', '', '', 'xn', '', '', '', '', 'x1', '', '', '', 'xn', '', ''], ['we', 'asymptot', '', '', 'tau', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ttoinfti', '', '', '', '', '', '', '', '', '']]\n",
      "[['densityfunct', 'graphen', 'ctermin', '1x16hsic', ''], ['we', '', '', 'coval', '', 'graphenetyp', ''], ['the', 'graphen', '', 'waal', ''], ['for', 'sitermin', '', '', 'wherea', 'cface', 'semimetal', 'graphen', '', '']]\n",
      "[['multipleinput', 'multipleoutput', '', 'mimo', '', '', 'precod', '', 'select', ''], ['random', '', 'rvq', '', '', 'precod', 'random', 'codebook', '', 'isotrop', ''], ['we', 'iid', ''], ['', '', 'ratemaxim', '', 'precod', 'codebook', ''], ['we', 'beamform', '', 'rankon', 'precod', '', '', ''], ['with', 'beamform', 'rvq', 'asymptot', '', '', 'asymptot', ''], ['the', 'rvq', 'reducedrank', 'beamform', 'random', 'subspac', ''], ['we', 'precod', 'arbitrari', '', 'asymptot', 'rvq', '', '', 'mmse', '', '', ''], ['finites', ''], ['', 'mmse', '', 'wherea', '']]\n",
      "[['morphic', '', 'uniformli', '', ''], ['', 'noneras', 'morphism', ''], ['polynomialtim', ''], ['decid', '']]\n",
      "[['we', 'nontherm', 'g328402', 'pulsar', 'supernova', '', 'either', '', ''], ['xray', 'xmm', '', 'xray', 'photon', 'index2', '', 'xray', 'g328402', '', 'xray', ''], ['we', '', '', 'g328402', '', ''], ['we', '', 'though', 'g328402', '03', ''], ['', 'pulsar', '', '1400', '', '', 'mji', 'kpc2', '', 'kpc', ''], ['', 'g328402', 'pulsar', '', 'pwn', '', 'pwn', 'supernova', '', 'snr', '', 'hydrodynam', 'pwn', 'snr', ''], ['', 'g328402', '', '', '', 'pulsar', '', '', '1012', '', 'neutron', '', '', '', 'undetect', 'snr', '', '', '1051', 'erg', '', '', 'ejecta', '', '', 'solar', '', 'supernova', '', 'n003', '', '', '', '']]\n",
      "[['twoparticl', 'awaysid', 'auau', '', 'pp', '', '', 'dau', 'auau', ''], ['', 'gluon', '', '', '', 'cerenkov', 'gluon', '', 'hydrodynam', 'machcon', 'shockwav', ''], ['threeparticl', '', 'cerenkov', '', ''], ['', '', '', '', 'machcon', '', 'qcdcerenkov', ''], ['we', '3particl', 'azimuth', '', '', ''], ['', 'pp', '', '', 'dau', 'auau', '', 'sqrt', '', '', 'nn', '', '', '', 'gev', ''], [''], ['v2', 'v4', ''], ['the', 'machcon', '']]\n",
      "[['we', '', '', 'cdm', '', '', '', '', '', '', '', ''], ['with', '', ''], ['', 'resembl', '']]\n",
      "[['gammaray', 'susi', 'dsph', ''], ['thi', '', '', ''], ['we', ''], ['', 'glast', '']]\n",
      "[['we', 'magnetohydrodynam', '', 'mhd', '', '', 'quasistat', '', 'asymptot', 'mhd', 'random', 'supernova', ''], ['thi', 'synchrotron', '', 'mhd', '', ''], ['the', '', 'ejecta', 'versu', '', 'selfsimilar', 'mhd', ''], ['the', '']]\n",
      "[['we', '3particl', 'azimuth', '', '', '', '', 'gevc', '', '', '', '', 'gevc', ''], ['pp', '', 'dau', 'auau', '', 'sqrt', '', '', 'nn', '', '', 'gev', '', ''], ['we', '3particl', 'auau', ''], ['', '', '', 'qcdv', '', '', 'erenkov', ''], [''], ['', 'v2', '', '', 'v4', '', '']]\n",
      "[['', 'cib', '', '', 'put', '', ''], ['', 'cib', 'cib', 'spitzer', ''], ['cib', 'highz', 'grb', 'blazar', '', '', ''], ['thi', 'glast', '', 'energet', '']]\n",
      "[['xray', 'seyfert', '', '', ''], ['we', 'anal', 'xmmnewton', 'seyfert', 'ngc', '3783', ''], ['detil', 'timeresolv', 'timescal', '', '', '', '', 'crosscorrel', ''], ['', 'redshift', '5361', 'kev', ''], ['the', 'timescal', '0310', 'kev', 'continuum', ''], ['the', 'timescal', 'redshift', 'continuum', 'timescal', '107', 'msun', ''], ['redshft', 'xray', '', '']]\n",
      "[['isotop', 'gsi', 'aladin', 'neutron', ''], ['124sn', '', '124la', '107sn', 'isotop', ''], ['the', 'isotop', 'neutron', ''], ['the', 'isotop', 'limitingtemperatur', '']]\n",
      "[['', ''], ['thi', '', '', '', 'const', ''], ['', '', '', '', ''], ['for', ''], ['bimetr', ''], ['the', ''], ['schwarzschild', 'analyt', ''], ['', '', ''], ['for', '', '', 'cdm', '', ''], ['']]\n",
      "[['thi', '', 'gct', '', '', 'geometri', ''], ['the', ''], ['', '', '', '', '', '', '', '', 'specif', '', 'nonvanish', 'geometri', '', 'plethysm', '', 'probelm', '', '', '', '', 'thi', 'complexitytheoret', '', 'specif', '', '', ''], ['nonneg', 'coeffici', '', ''], ['these', 'kazhdanlusztig', 'multipl', '', '', 'drinfeldjimbo', ''], ['the', ''], ['', '', '', '']]\n",
      "[['the', 'basalt', 'asteroid', 'mineralog', 'basalt', 'meteorit', ''], ['basalt', 'asteroid', 'vtype', ''], ['', 'vtype', 'asteroid', '', '', '7472', '', 'kumakiri', '', '10537', '', '1991', 'ry16', '', '', '', '285', 'ua', '', ''], ['these', 'roig', 'gilhutton', '', '2006', '', 'icaru', '183', '', '411', '', 'sloan', ''], ['the', 'calar', '', '', '2006', ''], ['the', 'asteroid', 'shortward', '070', 'longward', '075', 'vtype', 'asteroid', ''], ['', '065', 'mineralog', 'asteroid', ''], ['basalt', 'asteroid', ''], ['we', ''], ['our', '', '', '1459', '', 'magnya', '', 'asteroid', '', '7472', '', 'kumakiri', '', '10537', '', '1991', 'ry16', 'basalt', '']]\n",
      "[['we', 'holomorph', '']]\n",
      "[['', 'dysonschwing', ''], ['hopf', 'algebra', '', 'perturb', 'renorm', 'algebra', ''], ['the', 'hochschild', 'cohomolog', 'hopf', 'algebra', 'slavnovtaylor', 'dysonschwing', ''], ['we', 'dysonschwing', ''], ['geometri', '', 'integr', '', '', '']]\n",
      "[['perturb', 'manyparticl', '', 'landauzen', 'ultracold', '', 'spinless', 'quasion', 'tunabl', ''], ['the', 'regularchaot', 'manybodi', '']]\n",
      "[['', 'et', ''], ['', '2007', '', '', 'among', '', 'epeakegamma', '', '', 'ghirlanda', '', '', ''], ['we', '']]\n",
      "[['', 'boson', '', '', '', '', '', 'helic', 'fermion', ''], ['mani', ''], ['lhc', '', '', '', 'helic', '', 'ell', 'et', '', '', '', ''], ['we', '', '', 'ww', '', '', '', ''], ['to', '', 'sim', '', '', 'fb', '', '', '', '', '', '', '', '', '', '', 'tev', '', '', '', ''], ['thi', 'helic', 'lepton', '', '', '']]\n",
      "[['we', 'hypersurfac', '', '', '']]\n",
      "[['we', 'radiativelydriven', 'photoion', 'highmass', 'xray', 'x1', ''], ['the', 'hydrodynam', '', 'xstar', 'photoion', '', 'hullac', '', 'carlo', ''], ['we', '', '', '', 'twodimension', 'timedepend', 'x1', '', 'emiss', 'xray', '']]\n",
      "[['the', 'astrometr', 'interferometri', 'exoplanet', ''], ['', 'routin', 'microarcsecond', '', 'microarcsecond', ''], ['we', 'ripl', '', 'interferometr', '', 'vlba', 'lowmass', '', 'subjovian', ''], ['vlba', 'bandwidth', 'astrometr', ''], ['', 'could', 'astrometr', 'microarcsecond', '', 'characterizaiton', ''], ['ripl', 'astrometr', ''], ['the', 'astrometr', ''], ['for', 'vlba', 'vlba', '', 'astrometr', '', 'lowmass', '', '', '', 'coronagraphi', '', 'interferometri', ''], ['for', 'ska', '', 'solartyp', ''], ['astrometr', ''], ['the', 'astrometr', 'astrometri', 'roadmap', 'exoplanet', '']]\n",
      "[['nanometers', 'rayleighplesset', ''], ['timedepend', '', '', '', '', 'continuum', ''], ['the', '', '', 'vsimeqgammaeta', '', '', '', '', 'sim', '', '1nm', '', ''], ['the', 'nanoassembl', 'protein', 'nonequilibrium', '']]\n",
      "[['we', 'adscft', 'finitetemperatur', ''], ['', 'hydrodynam', 'lowmomentum', 'realtim', 'adscft', '', ''], ['we', 'hydrodynam', 'lowli', 'quasinorm', 'pbrane', ''], ['we', 'viscosityentropi', 'dual', ''], ['']]\n",
      "[['superconduct', 'quasi2d', '', 'dca', '', ''], ['the', '', 'nonloc', '', 'lowestord', ''], ['the', 'electronphonon', 'bandwidth', ''], ['the', 'superconduct', ''], ['migdal', '', 'eliashberg', ''], ['', 'fermisurfac', 'swave', 'halffil', ''], ['the', 'hohenberg', 'bc', '']]\n",
      "[['maser', ''], ['mase', ''], ['']]\n",
      "[['we', 'quasiparticl', 'antiferromagnet', ''], ['the', '', 'dmft', '', 'antiferromagnet', ''], ['selfconsist', 'dmft', 'renorm', '', 'nrg', '', ''], ['the', 'quasiparticl', ''], ['the', 'quasiparticl', 'nrg', 'selfenergi', '', ''], ['they', ''], ['we', '', 'bf', '', 'quasiparticl', ''], ['we', 'lutting', 'antiferromagnet', '']]\n",
      "[['the', 'currentspindens', 'spindensityfunct', 'exactexchangeonli', ''], ['spinorbit', 'split', ''], ['we', '', '', '', 'nonmagnet', '', '', '', 'exactexchang', 'currentspindens', 'spindens', '']]\n",
      "[['mhv', 'perturb', 'yangmil', '', 'oneloop', 'yangmil', ''], ['we', 'counterterm', '', 'mhv', '', ''], ['these', 'counterterm', 'yangmil', '', '', 'worldsheet', 'yangmil', 'lightcon', ''], ['', 'oneloop', '', 'twopoint', 'counterterm', 'oneloop', '', 'allplu', 'helic', 'yangmil', '', '']]\n",
      "[['', 'transresist', ''], ['fermiliquid', 'relev', 'quasiparticl', 'could', 'transresist', '', 'interlay', ''], ['']]\n",
      "[['the', 'supersymmetr', 'n2', '', 'd4', 'ungaug', 'supergrav', 'supersymmetri', 'spinori', 'geometri', ''], ['12supersymmetr', 'timelik', '', 'supersymmetr', ''], ['thi', '12supersymmetr', '', 'ads4', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['electromagnet', ''], ['the', '', 'glu1', '', 'glu2', '', '', '', '', 'pss1', '', 'anisotrop', '', '', 'whose', 'permitt', '', '', 'lambdanu', '', '', 'mu', '', 'lambdanu', '', '', '', '', '', 'var0', '', 'lambdanu', '', '', 'mu', '', 'lambdanu', '', '', '', '', ''], ['electromagnet', 'timedomain', 'timedepend', ''], ['thi', 'permitt', '', '', ''], ['we', 'schr', '', 'oding', 'electromagnet', 'hamiltonian', ''], ['we', 'electromagnet', 'selfadjoint', ''], ['', 'selfadjoint', 'unitarili', 'electromagnet', '', 'var0', '', 'lambdanu', '', '', 'mu', '', 'lambdanu', '', '', ''], ['', 'sinc', '', ''], ['our', '', 'glu1', '', 'glu2', '', '', '', '', 'pss1', '', 'electromagnet', ''], ['', 'anisotrop', ''], ['', '']]\n",
      "[['weakcoupl', 'luttingerward', 'thermodynam', ''], ['these', 'variat', 'selfenergyfunct', 'without', ''], ['lutting', ''], ['we', 'nonperturb', ''], ['nontrivi', 'twosit', ''], ['the', 'meanfield', '']]\n",
      "[['we', 'interactiondriven', 'twodimension', 'metalinsul', '', '2dmit', '', '', 'vacancyinterstiti', ''], ['we', 'wignermott', 'selfdop', '', 'resembl', 'conceptu', 'he3', ''], ['the', 'mani', '2dmit', '']]\n",
      "[['we', 'subspac', 'subspac', ''], ['we', 'maxim', 'subspac', ''], ['', 'maxim', 'subspac', ''], ['we', 'nondegener', 'subspac', 'codeword', 'nondegener', '2ktotal', '', 'maxim', '', 'subspac', ''], ['nondegener', '', 'subspac', '', '', 'shor', 'qubit', 'subspac', '']]\n",
      "[['', '', '', '', 'mu', 'mu', ''], ['axialvector', 'alreadi', '', '', '', '', '', '', 'mu', 'mu', ''], ['', '', '', 'k0', '', 'k0', 'kl', '', '', 'mu', 'mu', '', 'scalarpseudoscalar', '', '', 'mu', 'mu', ''], ['we', '', '', 'mu', 'mu', '']]\n",
      "[['we', 'serpen', '', '', '160micron', 'spitzer', ''], ['2400', '24um', '', '70um', '', '160um', ''], ['we', '24um', 'carlo', 'spitzer', ''], ['we', '', '', 'serpen', '', '050', 'deg2', 'lowextinct', '', 'deg2', 'subset', 'swire', 'elai', 'n1', ''], ['these', 'identifi', 'serpen', 'either', ''], ['we', '', 'yso', '']]\n",
      "[['undoubtli', 'supersymmetr', 'supersymmetr', ''], ['we', 'sbottom', 'cern', 'hadron', 'collid', 'sbottom', 'subsequ', 'sbottom', 'neutralino', '', 'fermion', 'supersymmetri', 'boson', ''], ['we', 'sbottom', 'sbottom', 'neutralino', 'suffici', '']]\n",
      "[['we', 'threepoint', '', '3pcf', '', 'highresolut', 'dissipationless', 'lcdm', 'galaxys', 'subhalo', ''], ['we', 'subhalo', '', '3pcf', ''], ['', '3pcf', '', 'qualit', '2dfgr', ''], ['we', '3pcf', 'bin', ''], ['we', '3pcf', ''], ['the', '3pcf', 'cdm', 'subhalo', '']]\n",
      "[['we', 'lunar', 'dustenshroud', 'afgl', '5440', ''], ['the', '', '4um', 'highspe', 'spectrophotomet', 'expressli', ''], ['we', 'singles', ''], ['we', 'radi', 'circumstellar', ''], ['we', '', 'tmax', '', '950', '', '50k', '', '5um', '05', '', '01', ''], ['the', 'r2', 'ivez', '', 'elitzur', 'radi', 'hydrodynam', ''], ['our', '60um', 'without', 'massloss', '']]\n",
      "[['these', 'symplect', '', '', ''], ['the', '', 'symplect', '', 'project', ''], ['we', 'orbifold', 'symplect', '', ''], ['we', 'chenruan', 'orbifold', 'cohomolog', 'abelian', 'symplect', ''], ['we', 'project', ''], ['we', '', 'stacki', 'polytop', '']]\n",
      "[['the', 'perturb', 'renorm', '', '', ''], ['thi', 'although', ''], ['the', 'selfenergi', 'tridimension', ''], ['', '', '', '', ''], ['', '']]\n",
      "[['thi', 'collision', '', ''], ['we', 'selfstir', 'flybi', ''], ['although', '', 'collision', ''], ['', ''], ['asteroid', '', '', '2003', 'el61', '', '', 'would', 'collision', ''], ['the', 'collision', '', '', '', '']]\n",
      "[['trigonometr', 'polyharmon', ''], ['for', 'hyperfunct', ''], ['the', 'suffici', 'subspac', 'hyperfunct', '']]\n",
      "[['', '', 'we', 'xray', '', 'lens', '', 'lens', '', '1e065756', ''], ['xray', 'bulletlik', 'subclust', '', 'lens', 'centroid', 'collisionless', '', 'xray', '', ''], ['', 'dataset', '', 'selfinteract', 'crosssect', 'per', '', 'sigmam', '', ''], ['', '', 'higherqu', 'dataset', 'nbodi', '1e065756', 'selfinteract', '', ''], ['', 'sigmam', '', 'nonobserv', 'subclust', 'centroid', ''], ['thi', '', '', '', 'sigmam', '', 'cm2g', ''], ['if', 'subclust', 'masstolight', '', 'sigmam', '', '07', 'cm2g', '', 'subclust', 'masstolight', '', '', ''], ['our', '', '05', '', '5cm2g', 'collisionless', '']]\n",
      "[['we', 'dbrane', 'instanton', 'holomorph', 'dbrane', 'orbifold', ''], ['these', 'instanton', 'superpotenti', 'prepotenti', ''], ['brane', 'instanton', 'fermion', 'zeromod', 'supertransl', ''], ['they', 'instanton', '', ''], ['we', 'orientifold', 'zeromod', 'superpotenti', ''], ['these', '', '']]\n",
      "[['we', 'infinitereynold', '', 'kraichnankazantsev', 'whitenois', '', 'hoelder', '', ''], ['', '', '', '', 'stochast', '']]\n",
      "[['the', 'gluon', 'hydrodynam', 'skyrmion', 'gluon', 'semiclass', ''], ['']]\n",
      "[['bl', 'lac', ''], ['bl', 'lac', 'pk', '2155304', 'infraredopt', '', '', ''], ['we', 'silla', '', ''], ['vrijhk', ''], ['pk', '2155304', '2005', ''], ['the', '', 'photometri', ''], ['', '', ''], ['', ''], ['the', '', '', '', ''], ['the', '', 'uvxray', ''], [''], ['', 't12', '', '', '']]\n",
      "[['iin', 'supernova', 'multicompon', 'balmer', '', 'balmer', '', '', '', ''], ['we', 'among', 'sne', 'iin', 'polarimetr', '', ''], ['the', '', '', 'sne', 'iinlik', 'circumstellar', 'sne', ''], ['spectropolarimetr', 'iin', '', 'interact', 'sne', '', 'iin', 'subclass', '']]\n",
      "[['we', 'nir', 'a062000', 'spex', 'irtf', ''], ['the', 'continuum', 'heii', ''], ['deredden', 'a062000', 'a062000', 'k7v', '', '', 'unless', 'k7v', '', 'nir', 'a062000', ''], ['', 'k3v', 'a062000', '', '', 'a062000', 'k3v', ''], ['a062000', 'a062000', ''], ['roch', 'lobefil', 'a062000', '', 'ch', '', '', ''], ['the', '822', '', ''], ['frone', '', '', '2001', '', 'et', ''], ['', '1994', '', '', 'a062000', 'mbh', '', '9706', 'msolar', '']]\n",
      "[['we', 'computeraid', '', ''], ['to', '', 'gridbas', 'qubit', ''], ['we', 'polynomialtim', '', '', 'congestionfre', 'dataflowbas', 'qubit', ''], ['', 'dataflowbas', 'stateoftheart', 'gridbas', 'pipelin', '', '']]\n",
      "[['the', 'bl', 'lac', '3c', '66a', 'multiwavelength', 'juli', '2003', '2004', ''], ['the', '', 'sed', '', 'electromagnet', '', 'xray', '', 'vhe', '', 'gammaray', ''], ['', 'timedepend', 'lepton', 'sed', 'multiwavelength', ''], ['our', 'could', 'success', 'sed', 'vhe', 'gammaray', '', 'gev', ''], ['the', 'intergalact', '', 'iibr', '', 'highenergi', '3c', '66a', ''], ['', '', 'blr', '', '3c', '66a', 'gammaray', 'photon', '', '', 'xray', 'gammaray', 'photon', 'synchrotron', 'selfcompton', ''], ['we', 'xray', ''], ['the', 'hysteresi', 'xray', 'multiday', '']]\n",
      "[['', 'how', ''], ['', 'thi', '', 'verylow', ''], ['', '', 'gj', '674', '', 'm25', 'd45', '', ''], ['', '469', ''], ['', 'these', '2planet', 'keplerian', 'mearth', ''], ['', '', 'gj', '674', '35day', ''], ['thi', 'inhomogen', ''], ['the', '469day', 'bonafid', '', 'gj', '674b', ''], ['', 'neptunemass', 'mdwarf', '', ''], ['we', 'metal', 'without', '', ''], ['', 'metal', '']]\n",
      "[['we', ''], ['our', '', 'determinist', 'continuum', '', '', 'interact', '']]\n",
      "[['we', 'l1204', 'onsala', '25m', '', '', '', '', '', '', '', '', '', 'htco', ''], ['the', 's140', '', '', '', '', ''], ['thi', '', ''], ['', '', '', '', '', '', 'though', ''], ['notabl', '', 's140', '', '', '', '', '', '', '', '', '', '', '', '', 'sim', '', '', ''], ['we', ''], ['the', '', '', 'optic', 'toward', '', '', ''], ['', 'photodissoci', '', '', 'photon', '']]\n",
      "[['', 'we', 'pfaffian', 'dimer', '', ''], ['we', ''], ['these', 'dimer', '']]\n",
      "[['we', 'taylur', '', 'fortran', 'complexvalu', 'arbitrari', '', ''], ['the', 'potenti', 'exponentialrel', 'could', '', '']]\n",
      "[['leq', '', '', '', '', ''], ['', 'arclength', '', '', '', ''], [''], ['', '', 'supremum', 'subset', 'norm', 'infimum', '', '', '', '', '', '', '', '', 'xin', '', ''], ['', '']]\n",
      "[['the', '', '', '', 'continuum', ''], ['', 'synchrotron', 'largescal', ''], ['the', ''], ['the', '', '', 'toward', ''], ['xray', 'toward', ''], ['obassoci', ''], ['']]\n",
      "[['simplici', 'the', 'leray', '', '', 'homolog', 'subcomplex', ''], ['simplici', '', 'cardin', 'preimag', '', '', '', '', 'leq', '', '', 'r1', ''], ['helli', 'amenta', '']]\n",
      "[['we', 'numer', 'barrettcran', 'riemannian', ''], ['we', 'qdeform', 'arbitrari', 'spacetim', ''], ['we', 'observ', '', 'spinspin', ''], ['we', '', '', '']]\n",
      "[['we', '', 'vla', '', '21cm', 'faceon', 'ngc', '1058', '', ''], ['our', 'interstellar', '', '', 'kmsec', '', 'gaseou', ''], ['the', '', '', ''], ['the', '']]\n",
      "[['', '', 'dissip', ''], ['paczynski', 'ostrik', '', 'shortperiod', '', '', '', 'shortperiod', ''], ['', 'evolutionari', '', 'system', '', 'either', '', '', '', ''], ['the', 'longperiod', 'interact', '', 'nova', 'crb', 'oph', '', ''], ['their', ''], ['the', '', '', '', 'reformul', 'explicitli', '']]\n",
      "[['overview', 'astrophys', '']]\n",
      "[['thi', 'convolut', 'spacetim', 'blockfad', ''], ['we', 'punctur', 'viterbi', 'convolut', 'without', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'temperley', '', 'lieb', 'heck', 'algebra', 'coxet', '', '', '', '', 'geq', '', '', ''], ['we', 'dieck', ''], ['', '', 'coeffici', 'kazhdan', '', 'lusztig', '']]\n",
      "[['we', 'analyt', 'asymptot', 'quasinorm', 'schwarzschild', 'monodromi', 'motl', 'neitzk', ''], ['our', '']]\n",
      "[['graphen', 'multilay', 'epitaxi', 'carbid', ''], ['thi', 'graphen', 'builtin', 'undop', ''], ['', ''], ['anomal', '', 'antiloc', '', ''], ['epitaxi', 'graphen', 'quasiballist', '', 'cryogen', ''], ['paradox', '', 'graphen', '', 'mobil', 'epitaxi', 'graphen', ''], ['materialepitaxi', 'graphen', ''], ['these', 'ballist', 'highspe', 'nanoelectron', '']]\n",
      "[['the', '', '', 'thermoacoust', 'photoacoust', '']]\n",
      "[['gammaray', '', 'grb', '', 'gev', 'egret', '', 'gev', ''], ['milagro', '', '', '', '', '', '', 'cherenkov', 'gev', 'tev', ''], ['we', '106', 'gammaray', '', 'grb', '', 'sinc', '2000', 'bats', '', 'bepposax', '', 'hete2', '', '', 'ipn', ''], ['']]\n",
      "[['we', ''], ['liquidga', 'coexist', ''], ['we', ''], [''], ['', 'observ', ''], ['bimod', ''], ['we', ''], ['the', 'bimod', '']]\n",
      "[['we', 'berezinskiikosterlitzthouless', 'twodimension', 'josephsoncoupl', 'boseeinstein', ''], ['josephson', '', '', '', 'vortexfre', ''], ['with', 'jt', '', ''], ['we', 'jt', '']]\n",
      "[['we', 'nbodi', ''], ['', '', ''], ['nbody4', '', '', 'tidal', ''], ['we', '', ''], ['', '', '', 'corecollaps', '', 'gyr', '20000', '', ''], ['', 'masssegreg', ''], ['we', ''], ['for', 'coreradiu', 'corecollaps', '', '', '', ''], ['we', '']]\n",
      "[['we', 'raman', '', ''], ['we', 'raman', 'outcoupl', 'outcoupl', ''], ['thi', '', ''], ['we', 'raman', 'outcoupl', 'whose', 'wavefunct', '', 'typic', '']]\n",
      "[['', 'hadron', 'collid', '', ''], ['longstand', '', '', 'unsafeti', '', '', '', ''], ['seedless', '', ''], ['the', '2n', 'among', '', 'hadron', ''], ['thi', 'n2', 'ln', '', '', '', '', 'siscon', '', 'whose', ''], ['carlo', '', '', '', '', 'parton', 'hadron', ''], ['', 'seedless', 'inclus', '', '', 'multijet', 'observ', '']]\n",
      "[['we', 'revisit', 'interplay', 'chargedtoneutr', '', '', '', '', '', '', '', '', '', '', ''], ['we', 'isospin', 'i0', 'i1', ''], ['we', 'i1', ''], ['the', 'applic', '', '', '', '', '', 'phi', '', '1020', '', '', '', 'chargedtoneutr', 'isoscalar', 'isovector', ''], ['', 'isotop', 'strongscatt', 'kinemat', '']]\n",
      "[['we', 'resumm', 'interplay', 'showermatrix', 'lhc', ''], ['we', 'boson', 'hadron', 'collid', '']]\n",
      "[['', '', 'mathcal', '', '', '', '', 'ominim', '', '', '', '', 'subset', '', 'k1k2ell', '', '', 'defin', '', '', '', 'displaylin', '', 'pi1', '', '', 'k1k2ell', '', '', 'k1', '', '', '', 'pi2', '', '', 'k1k2ell', '', '', 'ell', '', '', '', 'pi3', '', '', 'k1', '', '', '', '', '', '', '', ''], ['for', '', '', 'mathcal', '', '', '', '', 'a1', '', '', '', '', '', 'subset', '', '', 'k1k2', '', '', '', '', '', '', '', '', '', '', 'subset', '', '', 'k1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'pi3', '', '', '', '', '', 'leq', 'leq', '', ''], ['we', '', '', '', '', '', '', '', '', '', 'mathcal', '', '', '', '', 'a1', '', '', '', '', '', 'defin', '', '', '', 'pi1', '', 'pi2', '', '', '', '', '', '', '', '', '', 'ell', '', '', '', 'homotopi', '', '', '', '', '', '', '', 'displaystyl', '', 'cdot', '', '', 'k11', '', '', '', '', '', 'homotopi', '', 'displaystyl', '', 'cdot', '', '', 'k13', '', '', '', ''], ['', 'thi', 'ominim', '', '', 'bv', '', 'semialgebra', 'semipfaffian', ''], ['', '']]\n",
      "[['twistor', 'mani', 'twistor', '', 'among', 'hamiltonian', ''], ['1tphysic', ''], ['we', '2tphysic', 'twistor', '', ''], ['unexpect', ''], ['su', '', '', 'conform', 'su', '', '', '', '', 'massless', '', '', ''], ['thi', ''], ['', '']]\n",
      "[['we', 'carbonoxygen', '', '', ''], ['the', '09', 'msun', '', '06', 'msun', 'threedimension', 'sph', ''], ['we', '', 'unless', '', 'sph', ''], ['', '', 'quasistat', '', 'differenti', '', 'centrifug', ''], ['we', 'sph', 'onedimension', 'hydrodynam', ''], ['the', 'neutrino', '', ''], ['thi', ''], ['our', 'supernova', ''], ['', 'eventu', 'would', '', '', '']]\n",
      "[['for', 'arbitrari', 'banach', 'c0group', '', '', 'xin', '', '', '', 'kmodul', ''], ['jacksontyp', 'inequ', 'mani', '', '', '']]\n",
      "[['we', 'weakfield', '', 'postnewtonian', 'chernsimon', ''], ['', 'parameter', 'postnewtonian', 'pn', ''], ['we', 'ppn', 'chernsimon', '', 'chernsimon', 'ppn', ''], ['we', 'nonlinear', 'spacetim', ''], ['gravitoelectromagnet', '', 'framedrag', 'gyroscop', ''], ['we', 'chernsimon', 'could', 'chernsimon', '', '', '']]\n",
      "[['we', ''], ['the', ''], ['the', '', '', 'electronphonon', ''], [''], ['exponenti', 'anomal', '']]\n",
      "[['realvalu', '', 'recurs', '', 'kleen', 'recurs', ''], ['concis', '', 'inaccuraci', ''], ['', 'recurs', '', '', 'recurs', ''], ['differenti', '', '', '']]\n",
      "[['for', '', 'singleindex', '', '', 'nonparametr', ''], ['', '', 'singleindex', '', '', 'singleindex', ''], ['the', 'singleindex', 'multivari', '', 'whether', 'singleindex', ''], ['singleindex', 'coeffici', '', 'rootn', 'asymptot', ''], ['suffici', ''], ['asymptot', ''], ['outofsampl', '']]\n",
      "[['fluoresc', 'ultrahigh', 'fluoresc', ''], ['to', '', '', '', 'nonneglig', 'cherenkov', 'multiplescatt', ''], ['the', '', ''], ['malargu', '', '', '', 'apf', '', ''], ['these', 'fluoresc', '', 'fluoresc', ''], ['thi', '', '', '', 'apf', '']]\n",
      "[['thi', '', ''], ['', 'sinc', ''], ['', '', '', '', ''], ['the', '', '', '', 'cybernet', '', '', '', '', ''], ['these', '', '']]\n",
      "[['we', 'striat', 'microtubul', ''], ['microtubul', '', '', 'unalign', ''], ['microscopi', 'compression', ''], ['', 'forceveloc', '', ''], ['the', '']]\n",
      "[['we', '', '', '', 'ngamma', '', '', '', '', '', 'ngamma', '', '', ''], ['we', '', '', '', '', '', 'ngamma', '', '', 'doublebeta', ''], ['gebas', 'doublebeta', '2041kev', '3062kev', '', '', 'via', '', '', '', 'ngamma', '', '', ''], ['the', '', '', '', 'doublebeta', ''], ['', '', '', '', '', 'ngamma', '', '', ''], ['we', 'nextgener', 'neutrinoless', 'doublebeta', '']]\n",
      "[['premainsequ', 'protoplanetari', '', 'circumbinari', 'onto', 'circumstellar', ''], ['', '', ''], ['thi', 'observ', ''], ['premainsequ', 'uz', 'tau', 'we', 'bvri', 'photometri', '', 'uz', 'tau', '', 'bestfit', '1916', '', '004', ''], ['thi', '1913', '', ''], ['the', 'uz', 'tau', 'random', '', '', ''], ['the', 'halpha', '', '', ''], ['the', 'uz', 'tau', '', 'circumbinari', '', 'timescal', '']]\n",
      "[['the', 'everincreas', 'realworld', 'multimechanismgovern', ''], ['', 'network', ''], ['', '', ''], ['', '', ''], ['', 'undergo', 'scalefre', ''], ['', 'nontrivi', 'disassort', ''], ['we', ''], ['', 'smallworld', '', 'coeffici', '']]\n",
      "[['the', 'hamiltonian', '', 'hcp', '', ''], ['the', 'biject', '', '', '', 'the', 'hcp', '', 'nonisomorph', 'hamiltonian', 'hamiltonian', ''], ['pnp', '']]\n",
      "[['', 'we', 'vlbi', 'ghzpeakedspectrum', '', '', ''], ['of', '', 'janski', '', 'phj', '', '', '2002', '', '', 'other', ''], ['we', '', '', 'cso', '', ''], ['', 'we', 'vlbi', ''], ['of', '', '', 'minidoublelob', '', 'cso', '', 'agn', 'could', 'edgeon', ''], ['thi', 'doublelob', '', 'cso', '', 'phj', ''], ['the', 'j03230534', '', 'j11350021', '', 'j13520232', '', 'j20580540', '', 'j21230112', 'j23250344', '', 'doublelob', '', 'kpc', '', 'cso', ''], ['j10570012', '', 'j16000037', 'j17532750', 'corejet', '']]\n",
      "[['microscopi', '', 'mfm', '', 'ferromagnet', ''], ['vertic', ''], [''], ['thi', 'mfm', ''], ['our', '', '']]\n",
      "[['for', 'nbodi', '', ''], [''], ['our', 'subperc', 'z0', 'z3', ''], ['we', '']]\n",
      "[['gapless', '', 'kappa', '', '', '', 'bedtttf', '', '', '', '', '', '', 'cn', '', '', '', '', 'anisotrop', '', 's12', '', 'meanfield', ''], ['quasionedimension', 'anisotropi', '', 'onedimension', '', '1d', '', ''], ['oneparticl', 'anisotropi', '', 'jj', '', '1d', '', 'gapless', '1d', ''], ['thi', 'onedimension', 'gapless', '']]\n",
      "[['we', 'photon', 'interact', 'conform', '', 'moduligravexciton', '', ''], ['we', 'photon', '', '', 'photon', ''], ['we', '', 'grb', '', 'photon', 'gravexciton', '']]\n",
      "[['we', 'manydimension', ''], ['the', 'coeffici', '']]\n",
      "[['we', 'supermass', '', '', 'supermass', 'sersic', '', '', '', '', 'sersic', '10k', ''], ['the', '', '', ''], ['sersic', '', 'latetyp', ''], ['we', 'parameteris', 'supermass', 'schechter', '', 'lowmass', '', 'logarithm', '', '1alpha', '', '07', 'earlytyp', ''], ['', '', '106', 'msun', '', 'supermass', 'earlytyp', 'rho', '', '', 'earlytyp', '', '', '', '3512', '', 'h3', '', '', 'msun', 'mpc', '', '', '', 'latetyp', 'rho', '', '', 'latetyp', '', '', '', '1005', '', 'h3', '', '', 'msun', 'mpc', '', '', ''], ['the', 'carlo', 'mbhn', '', 'sersic', '', 'malmquist', ''], ['the', '', '', 'supermass', '', '', '', '', '', '3212', '', '', '', 'h70', ''], ['that', '', '', '', '00070003', '', 'h3', '', '', 'per', 'supermass', '']]\n",
      "[['we', 'riemannian', 'ricci', '', ''], ['', 'ricci', 'bakryemeri', ''], ['the', 'garciario', 'fernandezlopez', '']]\n",
      "[['we', '', 'anm', '', ''], ['anm', ''], ['pionnucleon', 'nonchir', 'pseudoscalar', '', '', '', '', 'pseudovector', '', 'pv', '', 'via', 'nonlinear', ''], ['for', ''], ['', 'chiral', 'lagrangian', 'shortdist', '', '', ''], ['the', '', 'snm', '', ''], ['nucleon', '', 'hnl', '', '']]\n",
      "[['', '', 'boson', '', 'rashba', 'spinorbit', '', '', 'mesoscop', ''], ['kondo', 'sidecoupl', ''], ['', 'drastic', ''], ['the', 'kondo', ''], ['without', '']]\n",
      "[['fraction', '', 'onedimension', '', 'either', 'fraction', ''], ['the', '', '', ''], ['thi', 'relev', '']]\n",
      "[['we', 'ferromagnet', 'stateoftheart', ''], ['to', '', 'rusit', 'srruo3', '', 'srruo3', 'ferromagnet', ''], ['ti4', '', 'srtio3', '', '', ''], ['', 'ruoru', 'connect', '', 't2g', 'eg', ''], ['', '', '', '', '', '', 'ef', '', 'ef', 'halfmetal', 'ferromagnet', ''], ['the', 't2g', '', 'eg', 'judici', '', ''], ['thi', '', '', 'halfmetal', 'ferromagnet', '', 'spinbas', '']]\n",
      "[['medvinski', 'emph', '', 'et', '', '', ''], ['medvinski', '', ''], ['tikhonova', '', 'aliev', '', 'bl', '', '', 'malchow', '', 'phi', ''], [''], ['textbf', '', '', '', '021915', '', '2001', '', '', 'marcu', 'garvi', 'emph', '', 'et', '', '', 'garvi', 'trenchea', '', ''], [''], ['optim', ''], ['textbf', '', '', '', '775791', '', '2007', '', '', 'spatial', 'reactiondiffus', 'phytoplanktonzooplankton', '', '', 'patchi', ''], ['', 'plankton', 'furtherli', 'would', 'turinghopf', ''], ['our', '', 'farfield', 'coeffici', 'phytoplankton', 'zooplankton', ''], ['', 'farfield', ''], ['our', 'nonlinear', ''], ['', 'spatial', '']]\n",
      "[['multipartit', '', 'ion', '', 'etc', ''], ['we', 'qubit', '', 'uqcm', '', ''], ['we', 'uqcm', ''], ['the', 'dlevel', '']]\n",
      "[['we', 'pseudospectrum', 'nonselfadjoint', ''], ['our', 'microloc', '', ''], ['the', 'weyl', 'complexvalu', ''], ['we', 'suffici', 'weyl', '', ''], ['when', '', '', ''], ['we', '', '']]\n",
      "[['we', ''], ['', 'wavenumb', ''], ['thi', '', '', 'scaleresolv', '', ''], ['we', '', '', '', ''], ['', '', '', ''], ['we', ''], ['from', 'kolmogorov', '', '1941', '', '', '113', ''], ['thi', '', 'wavenumb', '', '', '', '74000', 'leq', 'leq', '170000', '', '', '']]\n",
      "[['', 'statist', '', ''], ['', ''], ['recurs', 'logarithm', ''], ['logarithm', '', 'addit', '', ''], ['nonaddit', '', '', '', 'statist', '', 'addit', 'recurs', 'logarithm', ''], ['', 'mathai', ''], ['mathai', '', ''], ['mathai', 'kerridg', '', 'inaccuraci', '', '']]\n",
      "[['we', 'srru', '', '1x', '', 'tixo3', 'photoemiss', '', 'srruo3', 'srtio3', ''], ['the', 'metalinsul', '', '05', ''], [''], ['', 'pseudogap', '', 'subsequ', 'interestingli', '', 'suffici', 'anomal', ''], ['lineshap', 'interplay', '']]\n",
      "[['we', 'electroweak', 'supersymmetr', '', 'mssm', '', '', '', '', '', '', ''], ['thi', 'higg', 'doublet', '', 'superfield', ''], ['we', 'oneloop', 'electroweak', 'firstord', ''], ['', 'higg', 'boson', ''], ['', 'higg', 'boson', '']]\n",
      "[['thi', 'fraction', 'reactiondiffus', 'caputo', 'timederiv', 'rieszfel', 'fraction', 'spacederiv', ''], ['the', 'hfunction', ''], ['the', 'mani', '', 'notabl', 'mainardi', 'et', ''], ['', '2001', '', '2005', '', 'spacetim', 'fraction', '', 'saxena', 'et', ''], ['', '2006a', '', '', 'fraction', ''], ['the', 'rieszfel', 'fraction', 'reactiondiffus', 'spacetim', 'fraction', '', 'fraction', '', 'spacefract', '', 'timefract', ''], ['these', 'express', 'hfunction', '']]\n",
      "[['we', 'random', 'nonzero', ''], ['the', 'chiral', 'qcdlike', ''], ['we', '', 'mu', '', '', '', 'discontinu', 'chiral', 'bankscash', ''], ['the', '']]\n",
      "[['thi', ''], ['codon', '', 'aminoacyl', '']]\n",
      "[['the', 'largescal', 'spacetim', ''], ['the', ''], ['thi', '', 'restat', ''], ['the', '', '', ''], ['', 'fivedimension', ''], ['the', '', 'without', '', '', '', 'the', '', '', '', 'fourdimension', 'largescal', 'spacetim', '', '', '', 'tulleyfish', '']]\n",
      "[['we', 'meanfield', '', 'sigma', '', '', '', 'holsteintj', ''], ['we', '', 'sigma', '', '', '', 'connect', ''], ['we', '', '', '', '2x', '', '', '', '', 'cuo', '', '', ''], ['we', 'mani', 'magneticlattic', 'polaron', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['philic', 'chattaraj', 'et', ''], ['', 'chattaraj', '', '', 'maiti', '', '', 'sarkar', '', 'phi', ''], ['chem', ''], [''], ['2003', '', '107', '', '4973', '', 'torolabb', 'cowork', '', 'morel', '', '', '', '', 'torolabb', '', 'phi', ''], ['chem', ''], [''], ['2005', '', '109', '', '205', '', '', 'multiphil', ''], ['nucleophil', '', 'wk', '', 'electrophil', '', 'wk', '', 'philic', ''], ['thi', 'nucleophil', 'electrophil', ''], [''], ['success', ''], [''], ['', 'intra', 'intermolecular', '', 'nucleophil', '', 'delw', '', 'nucleophil', '', 'electrophil', 'allmet', '']]\n",
      "[['we', '', '', 'rd', '', 'rdvalu', '', 'adl', '', 'rdvalu', '', '', ''], ['we', ''], ['', 'brownian', 'sde', 'lyapunovtyp', ''], ['', 'stochast', '']]\n",
      "[['we', 'phonon', 'dimension', 'electronphonon', '', 'ep', '', 'either', 'nitrid', '', 'subkelvin', ''], ['the', 'phonon', 'metalinsulatorsuperconductor', '', '', 'thermomet', ''], ['750', 'twodimension', '', '', 'phonon', ''], ['we', 'phonon', 'ep', '', '', 'sim', '', '05', '']]\n",
      "[['threedimension', 'uniformli', 'vortic', 'incompress', ''], ['the', 'parametr', ''], ['beltrami', 'nonlinear', ''], ['the', 'threedimension', '', ''], ['homoclin', '', 'homoclin', 'sobolev', 'enstrophi', '']]\n",
      "[['the', 'antiwear', '', 'rollingslid', 'dialkyldithiophosph', '', 'zdtp', '', 'andor', 'dialkyldithiocarbam', '', 'modtc', '', 'addit', '', 'nanoindent', ''], ['nanofrict', 'coeffici', ''], ['for', 'modtc', '', '', '', '05', '', 'coeffici', '', '', 'mu', '', '', '04', '', ''], ['for', 'tribofilm', 'modtc', 'zdtp', '', '', '', '001', '', '', 'mu', '', '', '005', '', '', 'tribofilm', ''], ['thi', 'coeffici', 'mos2', 'suffici', '', 'zdtp', '']]\n",
      "[['', '', '', ''], ['textit', '', '', '', '', 'nonasymptot', '', 'textit', '', '', '', ''], ['the', ''], [''], ['', 'arbitrari', 'nonequilibrium', '', '', ''], ['entrop', 'without', ''], ['asymptot', 'textit', '', '', ''], ['', 'asymptot', 'chorin', '']]\n",
      "[['we', 'phononmedi', 'translat', 'surfaceinduc', ''], ['we', 'translat', ''], ['deby', '', ''], ['silicainduc', ''], ['the', 'boundtobound', 'boundtofre', ''], ['', 'phonon', ''], ['we', ''], ['we', '', '', 'mu', '', '', 'mu', '', '', '', 'freetobound', '', '', 'freetofre', '', '', '', 'freetofre', '', '']]\n",
      "[[''], ['they', 'highenergi', 'kinemat', 'doublelogarithm', '']]\n",
      "[['cofibr', '', 'olich', 'enabl', 'homotopi', '', ''], ['we', 'cofibr', ''], ['the', '', 'olich', 'subspac', '', '', '', 'olich', '', '', '', '', '', '', 'ahookrightarrow', '', 'subclass', 'cofibr', ''], ['pupp', '']]\n",
      "[['confocalmicroscopi', 'colloid', 'q061', ''], ['', ''], ['thi', ''], ['', 'realspac', ''], ['we', ''], ['thi', 'montecarlo', '']]\n",
      "[['the', '', '', 'blazar', 'glast', ''], ['the', '', 'object', '', '', 'gammaray', '', '']]\n",
      "[['we', 'numer', 'scalefre', ''], ['the', 'monoton', '', 'between', 'central', '', ''], ['', ''], ['we', 'realworld', '']]\n",
      "[['hii', 'xray', ''], ['among', '', ''], ['the', 'mainsequ', '', ''], ['the', 'xray', ''], ['the', 'ccd', 'onboard', 'suzaku', '', ''], ['suzaku', '', 'card1', '', '2005', '2006', 'june', '', ''], ['card1', 'lshell', 'ion', 'kshell', 'ion', '', ''], ['thintherm', 'kt02', '', '06', 'kev', 'nh12e21', 'cm2', '', '', ''], ['the', 'supernova', '', 'supernova', '']]\n",
      "[['we', '', 'timeglob', 'spatiallyloc', ''], ['for', '']]\n",
      "[['photoion', 'pend', '']]\n",
      "[['the', 'colin', '', 'ere', '', 'mu', '', '', '', '', '', 'corank', 'colin', '', 'ere', '', '', '', '', 'schr', '', 'oding', '', '', '', ''], ['2001', '', 'lovasz', '3polytop', 'colin', '', 'ere', 'corank', '1skeleton', ''], ['we', 'lovasz', ''], ['', '', 'mu', '', '', '', '', '', '1skeleton', '', '', 'polytop', ''], ['inequ', 'bol', '']]\n",
      "[['we', 'esontt', ''], ['we', '', 'l5', 'l4', ''], ['these', 'alreadi', 'fornasi', 'et', ''], ['', '2004a', '', 'dotto', 'et', ''], ['', '2006', '', '', ''], ['the', '', 'anea', '', 'anchis', '', 'misenu', '', 'phereclo', '', 'sarpedon', '', 'panthoo', '', 'l5', 'l4', '', 'euryb', '', 'menelau', '', '1986', 'wd', '1986', 'ts6', '', ''], ['the', '', 'asteroid', '', 'euryb', 'l4', '', 'ptype', 'asteroid', ''], ['featureless', 'euryb', '', '', 'shortward', '5200', ''], ['ctype', 'asteroid', 'interval', ''], ['our', '', ''], ['the', 'versu', ''], ['we', 'statist', '', 'solar', ''], ['', 'euryb', '']]\n",
      "[['multifrequ', 'vlba', 'firstbas', '', '', ''], ['the', 'whether', 'could', 'radioloud', 'agn', 'intermitt', ''], [''], ['the', 'vlba', '', 'phasereferenc', ''], ['the', 'unpublish', '84ghz', 'vla', ''], ['', '', 'intermitt', ''], ['', '1045352', '', 'infraredlumin', '', 'bal', '', ''], ['whose', 'twosid', '', '', 'intermitt', ''], ['the', '1045352', 'bal', ''], ['submillimetr', '1045352', 'synchrotron', '']]\n",
      "[['abrikosov', 'superconductor', ''], ['with', 'hightemperatur', 'superconductor', ''], [''], ['the', 'hightemperatur', 'superconductor', 'hoba2cu3o7d', ''], ['the', ''], ['when', '', '', '', ''], ['these', 'abrikosov', 'hoba2cu3o7d', 'microsec', ''], ['superconductor', '']]\n",
      "[['we', 'pseudospin', 'spin12', 'spin0', ''], ['the', ''], ['when', '', 'isospectr', 'spinorbit', 'either', 'spinor', '', '', '', 'spin0', ''], ['', '', '', '', 'either', 'spin12', ''], ['we', '']]\n",
      "[['we', ''], ['when', '', 'quasiisotrop', 'asymptot', 'anisotrop', 'belinskii', '', 'khalatnikov', '', 'lifshitz', '', 'bkl', '', 'asymptot', ''], ['', '', 'anisotrop', '', 'quasiisotrop', ''], ['the', '', '', 'graviton', '']]\n",
      "[['the', 'et', ''], ['', '2001', '', 'intens', ''], ['', 'trigonometr', 'parallax', ''], ['kinemat', 'enabl', ''], ['we', 'trigonometr', 'parallax', '', 'wd', '', 'et', ''], ['', '2001', '', ''], ['we', 'eso', '156m', 'eso', '22m', '2001', 'juli', '2004', ''], ['parallax', '', '', 'sim5', '', '', '', '', 'sim12', '', '', '', '', 'sim20', '', '', ''], ['', '', 'parallax', ''], ['', 'wd', 'et', ''], ['', '2001', '', ''], ['kinemat', ''], ['trigonometr', 'parallax', 'parallax', ''], ['thi', '', 'subsequ', '']]\n",
      "[['dynam', 'barmod', '', 'rotat', '', '001', '', ''], ['thi', 'highfrequ', 'supernova', ''], ['highresolut', '', '', 'tw', 'barmod', ''], ['the', 'nonlinear', '', 'kelvinhelmholtzlik', 'corot', 'barmod', ''], ['', 'longterm', '', 'nonlinear', '', '']]\n",
      "[['', '', 'evolutionari', ''], ['these', '', '', ''], [''], ['we', ''], ['we', 'stochast', 'meanfield', ''], ['', ''], ['we', '', '', ''], ['counterintuit', ''], ['', 'rockpaperscissor', '', '', 'biodivers', '']]\n",
      "[['we', 'phenomenolog', 'mssm', '', '', '', ''], ['the', 'lepton', 'hadron', ''], ['', 'relev', '']]\n",
      "[[''], ['decompositon', 'mongeamper', 'measu', 'mongeamper', '']]\n",
      "[['we', 'torsion', 'alfven', 'solar', ''], ['torsion', 'analyt', 'inhomogen', ''], ['these', '', 'inhomogen', ''], ['torsion', '', ''], ['thi', 'alfven', 'footpoint', ''], ['the', 'torsion', ''], ['torsion', 'seismolog', '']]\n",
      "[['rate12', 'convolut', '', 'pccc', '', 'rate13', ''], ['', '', 'whilst', 'toward', 'rate12', 'pccc', ''], ['', 'rate12', 'pccc', '', 'pseudorandomli', ''], ['we', 'rate13', ''], ['', 'toward', '', ''], ['', 'pseudorandom', 'bandwidth', 'pccc', '']]\n",
      "[['the', 'sixvertex', '', ''], ['', '', ''], ['specif', '', 'freefermion', '', 'onematrix', 'logarithm', '', 'penner', ''], ['the', 'saddlepoint', '', '', '']]\n",
      "[[''], ['', '', ''], ['the', '', '', '', '', '', '', '', '', ''], ['nonintuit', '', '']]\n",
      "[['the', 'vectorvector', '', 'rho', '', '', '', '', 'rho', '', '', 'phi', 'charmless', ''], ['the', '05', 'penguindomin', 'treedomin', '']]\n",
      "[['migdaleliashberg', 'electronphonon', 'superconduct', ''], ['the', 'electronphonon', '', 'cuprat', 'superconductor', ''], ['the', '', 'superconduct', ''], ['', ''], ['these', 'hohenberg', '', 'bardeencooperschrieff', '']]\n",
      "[['geometri', 'yang', 'monopol', ''], ['', ''], ['thi', 'twohorizon', 'thermal', ''], ['the', 'thermal', ''], ['thi', ''], ['eventhough', '', ''], ['', 'geometri', 'nariai', ''], ['the', 'spacetim', ''], ['', 'geometri', 'whether', 'masstyp', '', '']]\n",
      "[['the', 'instanton', 'plebanski', 'hodg', 'selfdual', '', '', '', 'encod', ''], ['the', ''], ['we', '', 'lagrangian', 'themslev', ''], ['', 'ashtekar', '']]\n",
      "[['we', 'quasionedimension', '', 'tmtsf', '', '', 'so3', '', 'ea', '', '', '', '', ''], ['metalinsul', 'anion', 'drudelik', ''], ['1500', 'cm1', '', '185', 'mev', '', '', ''], ['the', 'infraredact', 'longrang', 'shortrang', ''], ['710', 'cm1', '', '', 'tmtsf', '', '2x', 'metalinsul', ''], ['tmtsf', 'fso3', 'anion', '', 'anomal', '']]\n",
      "[['neutrino', 'among', 'neutrino', ''], ['ref1', '', 'longbaselin', 'neutrino', 'fermilabnumi', 'highenergi', 'hyperkamiokand', 'would', '', 'sin2', '2theta', '', '', ''], ['', 'would', 'topcolor', 'technicolor', '']]\n",
      "[['the', 'spintron', ''], ['we', 'nanopillar', '', '', ''], ['we', 'currentinduc', '', ''], ['thi', 'nanopillar', 'oscil', 'sinc', 'without', ''], ['we', '']]\n",
      "[['', '', 'neutrino', '', ''], ['the', 'neutrino', 'interact', ''], ['the', 'obey', 'either', 'waal', 'chaplygin', ''], ['the', 'neutrino', 'nonrelativist', 'neutrino', 'nonmass', 'neutrino', ''], ['the', '']]\n",
      "[['the', 'constrainedsearch', 'lieb', '', 'hohenbergkohn', 'nrepresent', '', 'n1', '', ''], ['the', 'via', '']]\n",
      "[[''], [''], [''], ['we', '', '', ''], ['we', 'explicitli', '', ''], ['we', ''], ['', '']]\n",
      "[['thi', '']]\n",
      "[['the', 'premix', '', 'methan', 'methan', 'allen', 'propyn', '', ''], ['the', '209', '', '', '', 'methan', '334', '', '', 'methan', ''], ['', '249', '', 'c3h4', '', 'c3h4ch4', '', ''], ['the', 'kpa', '', '333', 'the', 'chromatographi', 'microprob', ''], ['monoxid', 'dioxid', '', 'methan', '', '', '', '', '', '', 'propyn', '', 'allen', '', '', 'propan', '', '12butadien', '', '13butadien', '', '1buten', '', 'isobuten', '', '1butyn', '', 'vinylacetylen', '', ''], ['the', 'ptrh', '', '', '', 'ptrh', '', '', '', '700', '1850', '', 'c3c4', 'hydrocarbon', ''], ['the', 'allen', 'propyn', 'c6', '']]\n",
      "[['we', 'holonom', '', '', 'dissip', 'oscil', ''], ['we', ''], ['for', '', 'albeit', '', '', '', ''], ['', 'holonom', 'socal', 'raman', 'adiabat', '', 'stirap', '', '']]\n",
      "[['we', 'electromagnet', '', '', 'electromagnet', ''], ['to', 'neutron', 'electroweak', ''], ['we', 'stronglydecay', '', '', '', '1232', '', ''], ['the', 'im', '', 'mu', '', 'gf2', 'm3768', 'pi3', '', '', '', '', '', '', '', '', 'gf', '', '', '', '', '', '3time', '', '', '', ''], ['for', 'neutron', ''], ['we', '']]\n",
      "[['we', '', 'ntime', '', 'toeplitz', '', 'nto', 'infti', '', ''], ['from', 'schmidtspitz', 'hirschman', '', 'ntoinfti', '', ''], ['', ''], ['the', 'minim', 'admiss', ''], ['', '']]\n",
      "[['thi']]\n",
      "[['we', '', 'ast', '', '', '', '236', '', '1996', '', '133', '', '154', '', '', ''], ['1729', '', '2000', '', '239', '', '256', '', '', ''], ['the', 'almostsur', 'longterm', '', '', 'asymptot', ''], ['our', 'twophas', 'suffici', '', '', '', 'kappa', 'sqrt', '', '', '', '', '', ''], ['the', '', '', '', ''], ['', ''], ['we', '', '']]\n",
      "[['we', '1e', '065756', 'cdm', 'mond', ''], ['', '', '4700km', '', 'mond', ''], ['cdm', '', '3800km', '', 'hydrodynam', '']]\n",
      "[['balandraud', 'subset', 'abelian', '', '', '', 'ts2', 'kneser', 'nonzero', ''], ['thi', 'kneser', 'poset', 'balandraud', ''], ['we', 'poset', 'nonabelian', '', '', ''], ['balandraud', 'abelian', '']]\n",
      "[['carlo', '', '', 'isopotenti', '', ''], ['we', 'coulombexchang', 'nodal', ''], ['nonrelativist', 'nondegener', ''], ['thi', '', '', 'li2', '', 'be2', '', 'b2', '', 'c2', '', 'n2', '', 'o2', '', 'f2', '', 'carlo', ''], ['the', 'nonrelativist', '']]\n",
      "[['gev', 'treack', 'overview', ''], ['the', '', '', '', '', ''], ['', '', 'sysytem', ''], ['', '', '', '', '', '', '', '', '', '', ''], ['the', '', '', '', '', '', '286', 'gevc', ''], ['the', '', '', '', '', '', '', '', '', 'to3alphax', '', '', '', ''], ['radioact', '', '', '', '', '', '']]\n",
      "[['we', 'ultracold', 'fermion', 'anharmon', ''], ['supershel', '', 'hartreefock', '', 'analyt', 'wkb', ''], ['for', '', 'supershel', '']]\n",
      "[['we', 'boseeinstein', '', 'fock', ''], ['', ''], ['', '', 'random', ''], ['', 'quasiclass', ''], ['if', '', '', '', '', 'inequ', ''], ['the', 'bchsh', 'inequ', '', '', '']]\n",
      "[['we', 'substellar', 'substellar', ''], ['we', 'propermot', 'via', 'multiepoch', ''], ['their', 'photometri', ''], ['comov', '', 'sigma', '', '178', '', '350', '', 'hd141272', '', '', ''], ['with', 'emmintt', 'm305v', ''], ['the', 'photometri', '026007', 'msol', 'hd141272', '', '', ''], ['photometri', 'premain', '', 'sinc', 'zam', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'cng', 'neutrino', '', 'mathcal', '', '', '', 'evq', '', '', 'masssquar', '', '', 'dmqsbl', '', ''], ['we', '', 'icaru', '', ''], ['we', 'neutrino', 'cng', '', 'numu', 'nutau', '', ''], ['the', '', '', 'activesteril', '', '', 'icaru', '', ''], ['', 'numu', 'nue', '', ''], ['we', 'cng', 'neutrino', '', 'neutrino', ''], ['', '', 'fourneutrino', ''], ['our', '', 'dmqsbl', 'gtrsim', '01', 'evq', '', '', 'textit', '', '', ''], ['masssquar', ''], ['we', '', 'theta', '', '', '', 'cng', 'neutrino', '']]\n",
      "[['we', 'axisymmetr', 'quadrupol', '', 'postnewtonian', '', ''], ['thi', '', '', '', ''], ['we', 'timeaverag', ''], ['for', '', 'ryan', '', ''], ['our', '', '', '', '', ''], ['the', 'quadrupol', '', '', 'toward', 'antialign', ''], ['multipol', 'multipol', ''], ['to', '', 'multipol', '', 'postnewtonian', '', '', 'quadrupol', '', ''], ['with', '', '', 'axisymmetr', 'spacetim', '']]\n",
      "[['we', 'fagnano', 'polygon', 'billiard', ''], ['we', '']]\n",
      "[['the', ''], ['hamiltonian', '', ''], ['the', ''], ['the', '', '', '']]\n",
      "[['mani', '', '', ''], [''], ['smallworld', '', 'random', '', '', 'scalefre', ''], ['they', 'connect', '', '', 'hodolog', '', '', ''], ['cortic', 'interar', 'connect', 'macaqu', ''], ['we', 'corticocort', 'rewir', '', 'smallworld', '', 'scalefre', 'random', '', '', 'cortic', ''], ['the', '', 'scalefre', ''], ['the', 'hubnod', ''], ['thi', '', 'connect', '']]\n",
      "[['we', 'nanoparticl', 'spheric', 'without', ''], ['we', '', ''], ['our', ''], ['thi', '']]\n",
      "[['thi', 'discretetim', ''], ['longrun', 'risksensit', ''], ['the', 'onestep', 'nonneg', ''], ['', 'optim', 'inequ', '']]\n",
      "[['', '', 'bd0', '', 'jpsi', '', '', '', '', '', 'jpsi', '', '', '', '', 'jpsi', '', '', 'perturb', '', 'pqcd', '', ''], ['the', 'pqcd', '', '', '', 'bd0', 'jpsi', '', '', '', '196', '', '', '968', '', '', '', '065', '', '', '', '', '', '', '', '', '', 'bd0', 'jpsi', '', '', '', '', '109', '', '', '376', '', '', '', '025', '', '', '', '', '', '', '', 'bd0', 'jpsi', '', 'lhc', ''], ['the', '', 'pqcd', '']]\n",
      "[['we', 'finitetemperatur', 'twodimension', 'boson', 'zeropoint', 'via', 'carlo', '', ''], ['thermal', ''], ['finites', 'superfluid', 'kosterlitzthouless', ''], ['the', '', '', '', '', '', 'propto', 'rho0x', '', '', 'x10', '', ''], ['anomal', '']]\n",
      "[['we', 'pathentangl', 'condit', 'parametr', 'oscil', ''], ['we', ''], ['the', '', 'onoff', ''], ['continuouswav', 'parametr', 'oscil', '']]\n",
      "[['we', '', '', 'distribut', '', 'ttoinfti', '', 'distribut', ''], ['thi', 'asymptot', 'random', 'bitcomparison', '', ''], ['our', '']]\n",
      "[['we', 'semiclass', 'nonasymptot', 'dilaton', '', 'socal', 'dilaton', ''], ['', ''], ['massless', '', '', 'although', '', '', 'massless', '']]\n",
      "[['we', 'smatrix', 'adscft', ''], ['we', 'algebra', 'yangian', 'central', 'su', '', '', 'superalgebra', '']]\n",
      "[['we', 'nearir', '', ''], ['supergi', '', 'rsg', '', ''], ['', 'rsg', 'nearir', '', 'rsgspecif', 'microturbul', ''], ['', '', 'm82', '05', ''], ['we', '']]\n",
      "[['leastenergi', 'singularli', 'quasilinear', ''], ['we', '', 'leastenergi', ''], ['we', 'leastenergi', '']]\n",
      "[['statist', 'photon', ''], ['either', 'photon', '', '', ''], ['singlephoton', ''], ['singlephoton', 'photon', ''], ['', '', 'ledlik', '']]\n",
      "[['the', '', 'fsi', '', 'rescatt', ''], ['', 'bdtopipi', '', '', 'bdtorhorho', '', ''], ['cp', '', 'bdtopipi', '', 'fsi', '']]\n",
      "[['semimartingal', 'brownian', '', 'srbm', '', 'piecewis', 'stochast', ''], ['', '', '', '', 'srbm', ''], ['thi', 'suffici', 'srbm', '', 'random', '', 'srbm', ''], ['inequ', 'skorokhod', ''], ['we', 'srbm', ''], ['we', '', 'srbm', '', 'suffici', '', '', 'srbm', 'polyhedron', 'polyhedron', '', '', '', 'srbm', 'piecewis', 'nonconst', '']]\n",
      "[['we', 'carlo', '', 'spinless', 'fermion', ''], ['we', '', '', 'superfluid', 'boson', 'fermion', ''], ['', '', 'interact', '', 'wherea', 'drude', 'gapless', '', '']]\n",
      "[['neutron', '', '', 'hadron', '', 'thomasfermi', ''], ['we', 'parametr', '']]\n",
      "[['we', 'conduct', 'singlemolecul', 'electromagnet', '', 'photoconduct', '', ''], ['', 'conduct', 'offreson', 'photoassist', ''], ['simplifi', '', '', 'photoconduct', ''], ['the', 'conduct', 'oligophenylen', 'electrod', '', 'whose', 'densityfunct', ''], ['conduct', 'lengthindepend', '']]\n",
      "[['we', '', 'overbarri', 'nonmonoton', ''], ['the', '', '', 'exponenti', '']]\n",
      "[['we', 'cyclotron', 'monolay', 'graphen', ''], ['cyclotron', 'photoconduct', ''], ['the', '', '', '', '', '', '', '', '', '', '', '', '1093', '', '', '', '', '', '', '', '', '', '', '', '', 'mev', '']]\n",
      "[['graphen', 'nanoribbon', ''], ['nonequilibrium', 'nanoribbon', 'graphen', 'metalsemiconductor', ''], ['monolay', 'graphen', '', '', 'twodimension', 'graphen', '', 'nanoelectron', '']]\n",
      "[['', 'mathbb', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['the', '', 'p2', '', 'brauer', '', 'suzuki', '', 'kimmerl', '']]\n",
      "[['we', 'pentaquark', '', 'theta', '', '', '', '', 'i0', '', 'j12', '', '', 'pentaquark', 'borel', ''], ['to', 'borel', '', 'correl', ''], ['our', ''], ['borel', '', 'chiraleven', '', 'theta', '', '', '', '168pm022', '', 'gev', '', ''], ['the', '', '', '']]\n",
      "[['lefthand', 'slab', 'either', 'slab', '', '', '', ''], ['', 'coeffici', 'lefthand', 'slab', 'righthand', 'slab', '', 'permitt', '', 'slab', ''], ['mani', '']]\n",
      "[['nanoscal', ''], ['steplik', 'singleelectron', ''], ['currentvoltag', 'nanoclust', 'nanowir', '']]\n",
      "[['', 'whose', 'veech', '', '', '', ''], ['we', 'origamissquaretil', ''], ['the', '', '', 'origami', '', 'veech', 'teichmuel', 'origami', 'veech', '', 'origami', 'whose', 'veech', ''], ['thi', '']]\n",
      "[['', '', '', ''], [''], ['these', ''], ['the', '']]\n",
      "[['the', 'twodimension', 'random', 'ise', 'renorm', ''], ['the', 'asymptot', 'per', '', '', ''], ['doublelogarithm', 'multipl', ''], ['thi', 'ise', '']]\n",
      "[['we', '', '', 'bphase', 'superfluid', '', '', '', 'aerogel', ''], ['the', ''], ['', 'drastic', '', 'gapless', '']]\n",
      "[['hourglass', ''], ['', 'hamiltonian', ''], ['the', 'hourglass', '', '']]\n",
      "[['', 'socal', 'sigmad', '', '', 'pne', '', '', '', 'sigmad', 'bremsstrahlung', '', '', 'supernova', '', 'snr', '', '', 'pne', '', 'malmquist', '', 'extragalact', 'snr', '', '', '', 'sigmad', 'pne', 'pne', '']]\n",
      "[['we', 'polarizationselect', ''], ['we', '', '', 'approx', '', '', '', 'microspher', ''], ['microspher', '']]\n",
      "[['the', '', 'kim', '', 'wimpnucleon', '3409', 'kgd', 'csi', '', '', 'yangyang', ''], ['the', 'proton', ''], ['the', 'gevc2ar', 'scintil', '']]\n",
      "[['', 'art10', '', 'tiptip', 'bodybodi', 'uu', '', '520', 'mevnucleon', ''], ['our', '', '', 'suffici', '', ''], ['the', 'nucleon', 'tiptip', 'bodybodi', '', '', '', '', '05', '', '', 'bodybodi', 'nucleon', '', '', '', '', '', 'tiptip', ''], ['observ', 'tiptip', 'bodybodi', 'eo', '', ''], ['the', '', 'csr', '', '', '', '', '', '520', 'mevnucleon', '', 'eo', '', '']]\n",
      "[['', 'spin12', 'kleingordon', 'spin0', '', 'could', 'nonloc', ''], ['the', '', ''], ['electromagnet', '', 'electromagnet', '', '', 'electrodynam', '', 'eg', ''], [''], ['thi', ''], ['these', 'kleingordon', ''], ['spin12', '']]\n",
      "[['dure', 'reioniz', '', 'photodissoci', ''], ['we', '', '', 'eg', ''], ['', 'miniquasar', '', ''], ['we', 'photodissoci', 'h2', '11000k', '', '', 'fesc', '', '', '', '', 'fesc', 'photon', '', 'overdens', ''], ['', 'photodissoci', 'h2', '', '', '', 'reioniz', '']]\n",
      "[['we', 'threedimension', '', '', 'ise', '', 'randomexchang', '', '', '', 'xy', '', '', '', '', '', 'xy', '', '', '', '', '', '1p', '', '', '', 'xy', '', '', '', '', '', 'paramagnet', 'ferromagnet', '', '', 'p1', '', 'multicrit', '', 'nishimori', '', '', 'ppnapprox', '0767', '', ''], ['finites', 'carlo', '', '', '', 'pn', '', '', '', '', 'ferromagnet', 'threedimension', 'randomlydilut', 'ise', ''], ['we', '', 'nu0682', '', '', '', '', 'eta0036', '', '', '', '', '', 'nu0683', '', '', '', '', 'eta0036', '', '', '', 'randomlydilut', 'ise', '']]\n",
      "[['we', 'midinfrar', '', '104', '', '117', '', '183', '', 'protostellar', 'bok', 'globul', 'cb54', ''], ['we', 'protostellar', 'nearinfrar', 'cb54yc1ii', ''], ['the', 'midinfrar', 'cb54yc1ii', '', '', 'midir', '', 'approx', 'lsun', '', '', '', '', 'approx', '08', 'msun', '', '', '', '', '', '', '', 'msun', '', '', '', '', ''], ['cb54', 'nearinfrar', '', 'cb54yc1i', '', '', ''], ['the', 'nondetect', 'cb54yc1i', ''], ['cb54yc1i', 'protostar', '', 'nearinfrar', 'protostar', '', ''], ['', 'midinfrar', '', 'spatial', 'cb54', ''], ['the', '', '', 'sim100', '', '', 'midinfrar', 'midinfrar', 'protostar', '']]\n",
      "[[''], ['specif', '', ''], ['alreadi', 'mani', ''], ['the', 'missionposs', ''], ['duesberg', ''], ['without', '', 'genebas', ''], ['they', '', '', ''], ['', 'vivo', '', 'explicitli', '']]\n",
      "[['coordinat', 'delzant', '', 'symplect', 'geometri', '', ''], ['for', 'delzant', 'polytop', '', 'coordinat', 'delzant', ''], ['thi', 'coordinat', 'delzant', 'toric', '', 'geometri', '', '', 'toric', ''], ['we', 'delzant', '', '', 'toric', ''], ['these', 'coordinat', '', 'selfcontain', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'rotat', ''], ['', 'axial', '', '', 'tw', '', 'offcent', 'differenti', ''], ['thi', 'smbh', 'supermass', '']]\n",
      "[['these', '', '', 'via', 'hpt', '', 'huebschmann', 'stasheff', '', 'kosmannschwarzbach', 'voronov', '', '', '', '']]\n",
      "[['we', 'variat', 'electrodynam', 'rham', ''], ['our', 'variat', ''], ['we', 'spacetim', 'rham', '4current', ''], ['thi', ''], ['']]\n",
      "[['we', '', 'specif', 'lauryl', ''], ['we', 'dispar', '', 'proteinladen', '', '', 'surfactantladen', 'autoprecursor', '']]\n",
      "[['we', 'spacetim', 'weyl', '', '', ''], ['thi', 'spacetim', '', 'holer', ''], ['', 'the', '', '', ''], ['weyl', 'spacetim', 'onedimension', 'lorentzian', '', 'timelik', '', '', 'wherea', 'spacetim', 'twodimension', 'lorentzian', ''], ['bianchi', '', 'nontrivi', '', 'spacetim', '', '', '', '', 'spacetim', '', ''], ['', '', 'spacetim', '', 'spacetim', '', ''], ['for', '', '', '', 'spacetim', 'nongeodet', '', ''], ['', 'weyl', '3x3', 'phi', '', 'ij', '', ''], ['', 'twistfre', '', '', '', 'ij', '', '', '', '', 'phi', '', 'ij', '', 'eigenvector', 'phi', '', 'ij', '', '', 'ij', '', '', 'spacelik', 'spacetim', ''], ['twistfre', 'phi', '', 'ij', '', ''], ['the', 'n5', 'myersperri', 'kerrnutad', 'arbitrari', 'spacetim', '']]\n",
      "[['how', 'nonlinear', 'spinor', ''], ['', 'nonlinear', 'spinor', '', ''], ['thi', '', '']]\n",
      "[['we', '', '', '', '', '', '', '4170', 'mev', 'cleoc', 'fd', ''], ['we', '', '', 'nu', '', 'either', 'mu', 'tau', '', 'tau', '', '', 'nu', ''], ['', '', '', '', 'mu', 'nu', '', '', '', '0594', '', '0066', '', '0031', '', '', '', '', '', '', 'tau', 'nu', '', '', '', '', '', '04', '', '', ''], ['we', '', '', '', '', '', 'mu', 'nu', '', '', '', '0638', '', '0059', '', '0033', '', '', 'fd', '', '', '274', '', '', '', 'mev', ''], ['', '', '', 'mu', 'nu', '', '', 'fdsfd', '', '123', '', '011', '', '004', ''], ['we', ''], ['', '', '', '', 'nu', '', '', 'x10', '', '', '', '']]\n",
      "[['the', 'tev', 'higherdimens', 'higg', 'boson', 'righthand', 'neutrino', ''], ['these', 'higg', 'boson', ''], ['for', 'higg', 'boson', '', 'mw', '', 'subdomin', ''], ['the', 'righthand', 'neutrino', ''], ['collid', ''], [''], ['whether', 'crucial', 'righthand', 'neutrino', '']]\n",
      "[['anyon', 'quasiparticl', '', 'nu', '', '2m1', '', '', 'anyon', ''], ['we', 'quasiparticl', 'antidot', 'wignerjordan', '1d', 'abelian', 'anyon', ''], ['we', 'anyon', 'conduct', '', '', 'quasiparticl', ''], ['', 'nonvanish', 'quasiparticl', 'antidot', '']]\n",
      "[['we', 'spin1', 'boseeinstein', ''], ['we', 'analyt', '']]\n",
      "[['we', 'hd', '70573', ''], ['the', 'myr', ''], ['we', 'fero', 'mpgeso', 'silla', ''], ['our', 'g115v', 'myr', ''], ['hd', '70573', 'sinc', '2003', '2007', ''], ['the', 'fero', ''], ['hd', '70573', '852', '', 'semiamplitud', '149', '', ''], ['the', 'rotat', '', ''], ['', 'halpha', 'bisector', '', 'rotat', 'nonradi', 'longperiod', ''], ['', 'lowmass', ''], ['m110', '', '01', 'msun', '', 'm2sini', 'mjup', '', '', 'semimajor', '176', ''], ['the', 'e04', ''], ['the', 'hd', '70573', '']]\n",
      "[['we', 'electromagnet', 'propagationinvari', ''], ['the', 'sinc', 'intern', '', 'nonlinear', ''], ['schr', '', 'odingercat', 'xwave', '']]\n",
      "[['we', 'neutronneutron', '', 'nn', '', '', '', 'nn', ''], ['the', 'chiral', ''], ['we', 'kinemat', '', '01', '']]\n",
      "[['katz', 'vafa', 'adetyp', 'orbifold', 'iia', '', 'mtheori', '', 'ftheori', 'compactif', ''], ['', '', 'compactif', 'mani', ''], ['we', 'explicitli', '', 'su5', '', ''], ['', '', 'greatli', '']]\n",
      "[['thi', 'upon', '', 'geometricallyengin', ''], ['thi', 'topdown', 'mani', '', '', 'geometri', ''], ['and', 'superpotenti', '', '', 'greatli', ''], ['', 'su', '', '', ''], ['', '', '', '', 'e8', '']]\n",
      "[['project', 'isogen', '', 'freeli', '', '', ''], ['pgq1', 'isogen', '']]\n",
      "[['', 'twocompon', 'boseeinstein', '', 'interatom', ''], ['', ''], ['', '']]\n",
      "[['mani', 'extrasolar', ''], ['', '', 'situ', '', 'nascent', ''], ['', ''], ['we', ''], ['thi', ''], ['', ''], ['we', '', '', '']]\n",
      "[['we', 'holomorph', 'calabiyau', 'z3', 'z3', ''], ['', 'hepth0703182', '', '', 'homolog', 'h2', '', '', '', 'z3', '', 'z3', '', 'z3', ''], ['bmodel', '', 'instanton', ''], ['we', 'selfmirror', ''], ['selfmirror', '', 'prepotenti', '', ''], ['', 'instanton', 'homolog', ''], ['nontor', '']]\n",
      "[['correlationdriven', 'typicalmedium', 'meanfield', '', 'tmtdmft', '', 'mottanderson', ''], ['', 'epsilonri', 'kondo', ''], ['thi', '', '', '', '', '']]\n",
      "[['singlemolecul', '', '', '', ''], ['surfaceenhanc', 'enabl', '', ''], ['we', '', 'scaleabl', 'surfaceenhanc', 'raman', '', 'ser', '', 'nanometerscal', 'electromigr', 'electrod', ''], ['nanogap', 'raman', '', ''], ['electrodynam', 'plasmon', '', 'electromagnet', 'singlemolecul', 'ser', '']]\n",
      "[['we', 'x1', '', 'hetg', '', '', 'chandra', 'xray', '', ''], ['hetg', ''], ['the', '', '', '', '', '', '', '', 'hetg', ''], ['', '', ''], ['for', '', '1214', '', '', '', '', 'photon', '', '', '', '', '', '', '', '', '', '', '', '', '', '006', '', '', '', 'photon', '', '', '', '', '', '', '', '', '', '', ''], ['thi', 'timescal', ''], ['the', 'xray', '', '', ''], ['for', 'cyg', 'x1', '', 'xray', ''], ['', ''], ['we', '']]\n",
      "[['we', 'angleresolv', 'photoemiss', 'asgrown', 'oxygenreduc', '', '', '', '2x', '', '', '', '', 'cuo', '', '', '', '', '', '1x', '', '', '', '', '', '', '', 'cuo', '', '', 'electrondop', 'cuprat', ''], ['', 'neither', ''], ['', 'anisotrop', ''], ['nodal', 'longrang', 'antiferomagnet', '', 'antinod', '']]\n",
      "[['spacebas', 'microlens', 'exoplanet', 'statist', 'exoplanet', '01', 'earthmass', '05au', ''], ['thi', 'solar', '', ''], [''], ['closein', '', '05', 'spacebas', 'microlens', '', ''], ['', 'groundbas', 'microlens', '', 'semimajor', 'extrasolar', 'spacebas', 'microlens', ''], ['the', 'groundbas', 'microlens', '', 'spacebas', 'microlens', ''], ['', 'spacebas', 'microlens', '', ''], ['the', 'microlens', '', 'mpf', '', 'spacebas', 'microlens', '']]\n",
      "[['we', '', 'astrometr', '', 'usco1606119193532', '', 'ultrawid', '', '1600', '', '', 'lowmass', '', 'mtot04', 'msun', '', ''], ['we', '', 'comov', '', 'highresolut', ''], ['if', 'aab', 'gravit', '', 'would', ''], ['', ''], ['twopoint', '', '', '', 'lowmass', '', '', '', 'sco', '', 'would', '', '']]\n",
      "[['we', '', 'doublet', '', ''], ['we', 'dissip', ''], ['', ''], ['', ''], ['thi', ''], ['', 'transplanckian', '']]\n",
      "[['we', 'subcrit', 'josephson', ''], ['transduc', 'induct', ''], ['', ''], ['we', '']]\n",
      "[['we', '', 'rm', '', '148', 'extragalact', '', '253o', '', '', '356o', '', '', '15o', '', '', 'largescal', ''], ['we', 'rm', 'longitud', ''], ['the', 'rm', 'requri', 'largescal', '', 'scutumcrux', ''], ['to', 'quantit', '', 'extragalact', 'pulsar', 'rm', '', 'largescal', ''], ['bestfit', '', 'sagittariuscarina', '', '', '', 'scutumcrux', ''], ['thi', 'pulsar', 'rm', '', 'fourthquadr', ''], ['pulsar', 'rm', '', 'pulsar', 'extragalact', 'rm', 'largescal', '']]\n",
      "[['', '', '', '', '', '', 'pointsymmetr', '', 'vin', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'automorph', '', ''], ['', 'jin', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['our', '', '', '', '', '', '', '', '', '', '', 'j1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'the', 'vertexsymmetr', ''], ['caccettah', '', 'aggkvist', 'vertexsymmetr', 'shepherdson', '']]\n",
      "[['the', 'kilodegre', '', '', ''], ['smallapertur', '', 'widefield', 'winer', 'sonoita', '', ''], ['the', '', '', '', '', '', '', 'closein', ''], ['thi', ''], ['we', 'solartyp', '']]\n",
      "[['qubit', ''], ['qubit', 'interact', 'qubit', '', '', 'either', 'qubit', '', '', 'qubit', ''], ['the', 'qubit', 'interact', '', 'maxim', 'maxim', ''], ['qubit', 'qubit', '', ''], ['when', '', 'qubit', ''], ['exponenti', '', '', '']]\n",
      "[['the', 'gammaray', '', 'inversecompton', 'cosmicray', 'solar', ''], ['the', 'extragalact', ''], ['glast', '', 'egret', ''], ['we', 'egret', 'databas', '', '', '3c', '279', '', '', '', 'solar', ''], ['the', '', ''], ['we', ''], ['the', '']]\n",
      "[['we', '850', '450', 'premain', 'm1', 'twa', ''], ['these', 'twa', '', 'tw', ''], ['850', '', 'lunar', '', '02', '', 'cm2g', 'thi', 'twa', '', 'd55', '', 'microscopii', '', 'gl', '803', '', '', '', '', ''], ['thi', 'twa', 'mic', ''], ['we', 'midir', 'submillimet', ''], ['', '', '', ''], ['we', 'tw', 'lowmass', '', 'twa', 'evolutionari', '', 'gasrich', '', '']]\n",
      "[['nonequilibrium', ''], ['the', '', '', 'adiabat', '', ''], ['50atom', 'dileucin', 'peptid', '', ''], ['for', '', 'naiv', '', 'modestli', ''], ['', 'whenev', '', '', '', '', ''], ['', '']]\n",
      "[['nonlinear', 'fokkerplanck', '', '', 'phenomenolog', '', 'anomal', '', ''], ['nonlinear', '', '', ''], ['herein', '', 'stationaryst', '', 'htheorem', ''], ['', 'masterequ', '', 'obey', ''], ['']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'spinlattic', '', '', '', '', '', '', 'mgb', '', '', ''], ['the', '', '', ''], ['', '', '', '', '', '', '032', 'mgb', '', '', '', '', '', '', '', '']]\n",
      "[['we', 'critic', 'xray', 'xray', 'continuum', ''], ['we', 'xmmnewton', 'gx', '3394', '', 'highqual', '', 'kev', '', ''], ['socal', '', '', '', '', '', ''], ['thi', '', 'eg', '', '', 'among', ''], ['we', 'observ', ''], ['we', ''], ['for', '', ''], ['we', 'highsoftst', 'continuum', '', '', 'satisfactorili', 'stateoftheart', ''], ['we', '']]\n",
      "[['', '', '', 'v1', '', 'v2', '', '', '', '', '', '', 'mathcal', '', '', '', '', '', 'bicliqu', '', '', '', 'mathcal', '', '', '', 'mweb', '', 'subgraph', 'whose', ''], ['thi', 'bioinformat', '', 'databas', '', '', 'approxim', ''], ['', '', 'mathcal', '', '', '', '', 'specif', '', '', 'frac', '', 'minmathc', '', '', '', '', 'mathcal', '', '', '', '', '', '', 'delta12', '', '', '', '', '12delta', '', '', '', '', '', '', '', 'v1', '', 'v2', '', '', '', '', '', '012', '', '', '', '', '', 'mathcal', '', '', '', 'mweb', '', '', 'epsilon', '', '', '', 'epsilon', '', '', 'unless', '', 'mathsf', '', 'rp', '', '', '', ''], ['thi', '', ''], ['specif', '', '', '', 'statist', 'biclust', '', '', 'tan02', '', 'microarray', '', '', '', 'epsilon', '', '', 'inapproxim', '', '', '', 'bu05', '', 'unless', '', 'mathsf', '', 'rpnp', '', '', '']]\n",
      "[['we', 'onetoon', 'project', '', '', 'd2', '', ''], ['we', '', '', '', '', ''], ['when', 'q6', '', '', ''], ['thi', '3net', '', '', '', 'etc', ''], ['we', '', '', '']]\n",
      "[['we', 'centimetr', 'midinfrar', 'vlt', 'kolmogorov', ''], ['the', 'von', 'karman', '8m', 'vlt', ''], ['the', '', '', 'diffractionlimit', '30m', 'without', '']]\n",
      "[['the', 'isospin', 'neutronrich', 'neutron', ''], ['statist', 'multifragment', '', 'isosc', '', ''], ['statist', ''], [''], ['the', '', '', '', '', 'astrophys', '']]\n",
      "[['we', 'nearestneighbor', 'metast', '', 'explicitli', ''], ['with', '', '', 'metast', ''], ['we', 'competit', ''], ['for', '', 'nucleat', 'nucleat', ''], ['the', '', '', 'probabilist', ''], ['', 'nucleat', '', 'among', '', '']]\n",
      "[['transformationbas', 'extrem', ''], ['variationbas', '', 'transformationbas', 'carlson', 'leitmann', 'torr', '']]\n",
      "[['we', '', '', '', '', 'interfaci', 'lennardjon', 'spce', ''], ['for', 'lennardjon', '', 'longrang', '', '', '', '', ''], ['spce', 'longrang', 'coulomb', ''], ['', '', '', '', '', '', '', 'rm', '', '', '', 'mathbf', '', '', 'longrang', '', 'although', 'coulomb', '']]\n",
      "[['we', 'suzaku', 'archiv', 'xmmnewton', 'sersic', '15903', '', 'xray', ''], ['the', 'suzaku', '', 'redshift', 'ovii', ''], ['xmmnewton', 'azimuth', ''], ['although', 'nontherm', '', 'neither', 'interclust', 'warmhot', '', 'clumpi', 'intraclust', 'infal', ''], ['xmmnewton', ''], ['the', 'nontherm', ''], ['', '']]\n",
      "[['we', 'adiabat', '', '', '', 'bfield', '', ''], ['the', '', '', 'adiabat', 'hyperfin', 'bfield', ''], ['thi', 'bfield', 'semiclass', '', '', 'bfield', '', ''], ['interferometri', 'adiabat', '']]\n",
      "[['we', '', 'highmass', '', 'lowmass', '', '', 'metal', '103', 'zsolar', ''], ['we', 'radi', 'meshrefin', 'hydrodynam', ''], ['our', '', '', 'highmass', '', 'lowmass', ''], ['we', 'hydrodynam', 'lambdacdm', '', 'metal', '', '102', 'zsolar', '', 'beginn', '', '', ''], ['the', 'msolar', '', '', ''], ['msolar', 'metal', '', '', '104', 'zsolar', '', '', '', 'metal', '', '', '103', '102', 'zsolar', '', ''], ['the', '', '103', 'zsolar', 'lowmass', 'protostellar', '102', 'msolar', ''], ['', '', '103', 'zsolar', '', ''], ['thi', '', '']]\n",
      "[['we', 'highresolut', 'nearinfrar', 'keck', '', 'ssc', '', 'starburst', 'm82', ''], ['the', 'myr', '', 'mani', ''], ['we', 'virial', 'kinemat', 'ssc', ''], ['the', 'ssc', '106', 'solar', '', '107', 'solar', ''], ['m82', 'ssc', 'versu', 'ssc', ''], ['we', 'ssc', '', '', '191', '', '006', ''], ['thi', 'ssc', '']]\n",
      "[['we', 'unipot', 'picard', '']]\n",
      "[['eigenfunct']]\n",
      "[['the', 'wellknown', 'lowenergi', 'fournucleon', 'observ', 'threenucleon', '', 'eg', '', 'tjon', '', ''], [''], ['we', ''], ['the', '']]\n",
      "[['we', 'atomfield', '', 'fourlevel', ''], ['', ''], ['', 'twoqubit', 'cphase', 'adiabat', ''], ['thi', 'decoherencefre', '', 'cphase', 'arbitrari', '']]\n",
      "[['we', 'fuldeferrelllarkinovchinnikov', '', 'fflo', '', 'cecoin5', ''], ['quasiclass', 'eilenberg', '', '', '', 'paramagnet', '', '', 'swave', 'dwave', ''], ['the', 'piphas', 'fflo', 'nodal', '', 'paramagnet', ''], ['we', 'neutron', 'fflo', '']]\n",
      "[['we', ''], ['we', 'random', ''], ['thi', '']]\n",
      "[['thi', 'incompress', 'stoke', 'nonhomogen', ''], ['the', 'differenti', 'minimax', 'lagrangian', 'parametr', ''], ['we', ''], ['']]\n",
      "[['', '', '', 'horizontalbranch', '', '', ''], ['thi', 'subpopul', '', ''], ['kinemat', ''], ['the', '', 'random', 'kinemat', 'metal', ''], ['', '', '', 'dissip', ''], ['kinemat', '', ''], ['our', '', '', '', '', '']]\n",
      "[['becaus', '', 'gr', '', '', '', 'spm', '', ''], ['the', 'spm', '', '', 'intergalact', 'without', '', '', '', 'rc', '', 'without', '', 'rc', '', '', '', ''], ['', 'spm', '', '', ''], ['gr', 'spm', 'solar', '', '']]\n",
      "[['thi', 'teleparallel', 'axisymmetr', ''], ['we', ''], ['the', '', 'axialvector', ''], ['axialvector', '', 'rho', '', '', '', ''], ['the', '', '', ''], ['the', 'hamiltonian', ''], ['', 'teleparallel', '', 'ddot', '', '', '', 'ller', 'energymomentum', ''], ['', '', 'lambda1', '', '', 'teleparallel', 'gr', '', ''], ['', 'axisymmetr', '']]\n",
      "[['the', 'kleingordon', 'ddimens', 'kratzer', 'ringshap', 'analyt', 'nikiforovuvarov', ''], ['the', 'boundstat', 'kleingordon', 'noncentr', ''], ['the', 'threedimens', '']]\n",
      "[['the', 'axionlik', 'could', ''], ['', 'friislik', 'longdist', ''], ['', '', '', '', '', 'mev', '', '', 'agamma', '', '', '', '', '', '', '', 'gev', '', '', '', '', '', '', '', '']]\n",
      "[['we', ''], ['', '', '', '', '', '', '', '', '', '', 'ij', '', '', '1pi', '', '', '', '', '', ''], ['the', '', 'applic', ''], ['we', '']]\n",
      "[['we', '', '', 'dissatisfi', '', '', '', '', 'zm', '', 'lak', '', '', 'ak2', '', 'suffici', '', '', '', '', '', '', '', '', ''], ['ex3', '', '', '', ''], ['ex4', 'qu1', '', 'qu', '', 'suffici', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'alg1', 'alg2', ''], ['', 'ex5', '', '', '', ''], ['we', '', '', 'wf', '', '', '', '', '', '', '', '', 'wf', '', '', '', '', '', '', 'reesse1', 'v21', ''], ['to', '', '', '', 't1', 'q1', '', '', 'm1', '', '', '', '', '', 'reesse1', '', '', '', 'reesse1', '', '', '', 'reesse1', '', '', 'wf', '', '', '', '', '', '']]\n",
      "[['we', '', '', '', '', ''], [''], ['the', 'carlo', ''], ['the', '', 'twodimension', 'hamiltonian', ''], ['the', 'linearchain', '', 'freeli', ''], ['', '', ''], ['', 'rotat', '', ''], ['', ''], ['the', '']]\n",
      "[['the', 'fractal', 'normalphas', 'percol', 'superconductor', ''], ['the', 'superconductor', 'percol', 'superconduct', '', ''], ['ybco', '', '', 'bsccoag', '', ''], ['superconductor', ''], ['the', 'fractal', ''], ['superconduct', ''], ['the', 'currentvoltag', 'superconductor', 'fractal', '']]\n",
      "[['twoqubit', '', '', '', '', 'subset', 'fourdimension', 'project', '', 'socal', 'veldkamp', '', '', ''], ['', 'uni', 'tricentr', '', '', '', 'subset', 'hyperplan', '', '', '']]\n",
      "[['the', 'equilibr', '', '', 'timedepend', 'hartreefock', ''], ['the', 'preequilibrium', '', 'gdr', '', ''], ['isovector', 'nz', ''], ['the', 'gdr', 'preequilibrium', '', '', ''], ['', 'preequilibrium', 'gdr', 'statist', ''], ['revisit', '', ''], ['we', 'fusionevapor', 'gammaray', 'preequilibrium', 'gdr', ''], ['thi', 'radioact', 'nz', '']]\n",
      "[['', '', 'coeffici', 'lopatinski', 'via', '']]\n",
      "[['we', 'lepton', 'theta13', 'neutrino', ''], ['we', 'chooz', '', '', '', '', 'daya', '', '', '', 'reno', ''], ['we', '', 'systemat', '', ''], ['chooz', ''], ['', 'sin2', '', 'theta13', '', 'systemat', ''], ['statist', 'drawback', '']]\n",
      "[['we', ''], ['we', 'singlesourc', 'singledestin', 'mani', ''], ['', '', '', ''], ['we', '', 'decodeandforward', '', '', 'multihop', '', 'pointtopoint', 'noncoop', ''], ['we', '', '', 'decodeandforward', ''], ['sinc', '', ''], ['the', 'codeword', ''], ['we', '']]\n",
      "[['we', 'nilpot', '', 'resp', ''], ['metabelian', '', '', 'automorph', 'automorph', '']]\n",
      "[['we', '', '', 'cauchi', 'nonlinear', 'schr', '', 'oding', '', 'iepsilon', 'psit', 'frac', '', 'epsilon2', '', '2psi', '', '', '', 'psi2', '', '', '', 'x0', '', 'epsilon', '', '', '', '', 'frac', '', '', '', 'epsilon', '', '', '', '', '', 'painlev', '', 'ei', '']]\n",
      "[['', 'functor', 'fquad', '', 'f2vector', 'nondegener', '', ''], ['we', 'project', 'fquad', '', 'indecompos', 'project', 'fquad', ''], ['', 'functor', 'fquad', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'suffici', '7manifold', '', 'tild', 'g2', '', ''], ['suffici', '7manifold', '3form', '', 'tild', 'g2', '', '']]\n",
      "[['we', 'baryonbaryon', 'neutron', ''], ['we', '', 'hyperon', 'neutron', '', 'neutron', '', 'sim', 'modot', '', '']]\n",
      "[['we', 'einsteinyangmil', 'yangmil', ''], ['the', 'compactif', 'cremmer', 'scherk', '', 'tendimension', 'spacetim', 'compactifi', 'fourdimension', 'sixdimension', 's6', 'instanton', ''], ['the', 'fourderiv', ''], ['we', 'tendimension', 'without', 'compactifi', 'ads4', 's6', '']]\n",
      "[['the', 'cecoin', '', '', 'lowtemperatur', '', '', '', '', ''], ['fieldinduc', 'h5', '', 'tstarapprox', '03', '', '', '', '', '', 'tpropto', '', '', '', '', '', '', '', ''], ['we', 'dimension', ''], ['', 'whose', 'cecoin', '', '', '', '5x', '', '', '', '', '', '', '0leq', 'xleq', '018', '', '', '', '', 'tstar', '', 'toward', '']]\n",
      "[['fourdimension', 'supersymmetr', ''], ['', '', '', 'n2', 'stu', 'qubit', '', '2state', '', '', '', '', '', '', '', '', 'n8', 'qubit', 'e7', '', '', '', '', ''], ['', 'n8', '', '', 'qutrit', '', '3state', '', '', 'e6', '', '', '', '', ''], ['both', '', '', 'cartan', 'e6', ''], ['', '', 'n2', 'supergrav', '']]\n",
      "[['we', 'function', '', 'phin', '', '', '', 'xn', '', ''], ['we', 'suffici', '', 'function', '', 'dynkin', 'wfunction', ''], ['', 'suffici', 'function', 'xn', '']]\n",
      "[['stochast', '', 'bsde', '', '', '', '', 'ay', '', '', 'dt', 'f0', '', '', '', '', '', 'dt', 'f1', '', '', '', '', '', '', '', '', 'dt', '', '', '', 'dw', '', '', '', '', '', '', '', 'the', 'sectori', 'dissip', 'nonlinear', 'f0', '', '', '', 'dissip', 'subspac', 'socal', 'nonlinear', ''], ['stochast', '']]\n",
      "[['we', 'axino', '', 'dominantli', 'nexttolightest', 'supersymmetr', 'lepton', '', '', '', '', '', '', '', ''], ['', '', 'omegab', '', '', '', '', '']]\n",
      "[['', 'inform', '', ''], ['the', 'algebra', 'su', '', '', ''], ['sicpovm', 'mub', '']]\n",
      "[['we', 'coexist', 'predatorprey', ''], ['the', 'stochast', 'lotkavolterra', ''], ['meanfield', ''], ['the', '', 'metapopul', '', ''], ['thi', ''], ['the', 'coexist', '', 'selfsustain', 'timeoscil', ''], ['the', 'hopf', ''], ['they', '', '', 'lotkavolterra', ''], ['', 'biolog', 'lotkavolterra', '']]\n",
      "[['polar', '', '', 'rotat', ''], ['evolutionari', '', ''], ['whilst', 'longperiod', '', ''], ['we', 'phaseresolv', 'photometri', 'j233325921522221', '', '8312', '', '009', '', '', '', '4166', '', '013', '', ''], ['we', 'mu', '', 'wd', '', 'approx', '1033', 'cm3', '', 'shortperiod', 'mani', 'longperiod', ''], ['we', 'longperiod', 'toward', ''], ['longperiod', '', '', 'shortperiod', 'j2333', '', '']]\n",
      "[['thi', 'boolean', 'algebra', 'goedel', ''], ['if', '', 'etc', ''], [''], ['if', '', '', ''], ['if', 'deduc', 'deduc', ''], ['if', '', '', '', ''], ['ndtm', '', '', '', '', '', 'neq', ''], ['relativis', 'pnp', 'bakergillsolovay', 'determinist', 'nondeterminist', ''], ['if', 'panpa', '', 'dtm', '', '', 'ndtm', '']]\n",
      "[['we', 'finitelength', 'tomonagaluttingerliquid', 'backscatt', ''], ['the', '', 'plasmon', 'interact', ''], ['', ''], ['thi', 'nonfermiliquid', '']]\n",
      "[['the', 'shor', ''], ['the', '', '', 'random', '', ''], ['shor', 'random', ''], ['', '', '']]\n",
      "[['toxic', ''], ['thi', 'pharmacokinet', ''], ['the', '', 'kdem', '', '', '', 'secodip', ''], ['parametr', 'kdem', ''], ['', 'seafood', 'revisit', '']]\n",
      "[['highmass', '', 'g2996002', '862mu', 'submillimet', '', 'sma', '', 'subarcsecond', ''], ['the', 'submm', 'continuum', '036', '', 'x025', '', '', '1800au', '', ''], ['7800', '', '', 'prototrapezium', 'protostellar', '14x05', 'protostarspc3', ''], ['the', '', '', '', 'kinemat', '', ''], ['the', '300k', ''], ['we', '', 'eg', '', 'c34', 'toward', 'uchiihot', '', 'desorpt', ''], ['the', 'sio', '', '', ''], ['central', 'submm', ''], [''], ['submm', 'continuum', '', 'largescal', ''], ['sinc', 'protostellar', '', 'keplerian', ''], ['andor', '', '', '', 'andor', 'uchii', '']]\n",
      "[['rabei', 'et', ''], ['', '', '', 'applic', 'fraction', ''], ['the', ''], [''], ['the', 'agraw', '']]\n",
      "[['interact', '', 'qubit', '', ''], ['the', '', '', '', '', 'von', 'interact', ''], ['mani', 'examin', '', '', ''], ['we', 'huang', 'kai', ''], ['', 'controversi', '']]\n",
      "[['fermion', 'fraction', '', 'e2', '', ''], ['we', '', '', ''], ['the', 'thorough', '', '', '', ''], ['fraction', '', ''], ['', 'quasiparticl', '', 'fraction', ''], ['', '', 'fraction', 'deconfin', '', '', 'rokhsar', '', 'kivelson', ''], ['for', '', '', '']]\n",
      "[['we', 'threedimension', '', 'bto', '', '', '', '', '', 'bto', '', 'c1', '', '', '', '', 'bto', 'jpsi', '', '', ''], ['we', 'babar', 'pep2', '', '232', '', 'bbar', '', ''], ['the', '', '', '', '', '', '', '', '', '', 'c1', '', '', '', '', '', '', '', '', 'jpsi', '', '', '', '', '', ''], ['', 'cp', '', '']]\n",
      "[['we', ''], ['we', 'thermalst', 'qubit', 'thermalbel', '', 'purest', 'qubit', ''], ['thermalbel', 'without', 'photon', 'kerr', 'nonlinear', 'singlephoton', ''], ['thi', 'enabl', 'teleport', 'thermalst', 'qubit', '']]\n",
      "[['stochast', 'cauchi', ''], ['the', '', ''], ['', '', 'stochast', '']]\n",
      "[['thi', 'arxiv', 'grqc0410004', '', 'grqc0603075', '', 'other', ''], ['thi', '', 'grqc0608111', '', 'other', '']]\n",
      "[['wentzel', '', 'kramer', '', 'brillouin', '', 'wkb', '', 'fraction', 'fraction', ''], ['fraction', '', '', ''], ['to', '']]\n",
      "[['we', 'einsteinskyrm', ''], ['skyrmion', 'soliton', ''], ['', 'skyrmion', '', 'multibaryon', 'whilst', '']]\n",
      "[['thi', 'manytoon', 'throughput', '', '', 'onetomani', 'throughput', '', 'ieee', '80211', 'multihop', ''], ['manytoon', 'throughput', 'upperbound', 'throughput', '80211', ''], ['thi', '', '', '', 'regularlystructur', 'whose', ''], ['we', 'throughput', '80211', '3l4', '', 'throughput', '0690l', '', '0740l', '', 'mani', ''], ['we', '3l4', ''], ['when', '', '2l3', ''], ['our', '80211', 'random', 'aodv', 'throughput', ''], ['', 'gateway', '', 'gateway', '', '', 'throughput', '', ''], ['', '', 'worthwhil', 'judici', '']]\n",
      "[['we', 'pyrochlor', 'superconductor', 'kos2o6', '', '', '', '195', 'thi', 'atom', '', 'spatial', 'fullygap', 'superconduct', 'anisotropi', '', ''], ['abrikosov', ''], ['from', '', '3140', '', '', '', 'hc2', ''], ['we', '', '', '']]\n",
      "[['we', 'supersymmetr', 'bogomolnytyp', 'twistor', ''], ['', '', 'chiral', '', 'supersymmetri', ''], ['moyaltyp', '', 'explicitli', 'multisoliton', 'noncommut', '', '', '']]\n",
      "[['we', 'electricmagnet', 'fourdimension', '', '', 'ds4', ''], ['hamiltonian', '', ''], ['we', 'holographi', '']]\n",
      "[['', 'transitionmet', 'quasicryst', ''], ['fujiwara', '']]\n",
      "[['xray', '', '', 'medg', '', 'tbmn2o5', ''], ['xray', 'ferroelectr', '', ''], ['striction', 'ferroelectr', ''], ['xray', ''], ['the', 'commensuratetoincommensur', 'discommensur', 'geometri', ''], ['we', 'incommensur', 'commensur', 'antiphas', '']]\n",
      "[['', '', 'al80ni20', ''], ['', 'selfdiffus', 'coeffici', 'longcapillari', '', 'lc', '', 'quasielast', 'neutron', ''], ['the', 'lc', 'interdiffus', 'coeffici', ''], ['wherea', '', 'selfdiffus', 'interdiffus', 'undercool', ''], ['the', ''], ['3000', '', '', '', '', '715', '', 'interdiffus', 'coeffici', 'selfdiffus', ''], ['undercool', ''], ['thi', 'phi', '', 'interdiffus', ''], ['the', '', 'undercool', ''], ['thi', '']]\n",
      "[['the', 'multimod', ''], ['subpopul', ''], ['pipino', '', 'matteucci', '', '2004', '', 'multizon', 'photochem', '', 'galactocentr', ''], ['we', 'earlytyp', 'puzia', 'et', ''], ['', '2006', '', 'multimod', 'ellipt', '', '', ''], ['our', 'supermetalrich', '', ''], ['', 'nonlinear', 'metal', '', 'mergerinduc', 'nonlinear', 'colormetal', '', '', '']]\n",
      "[['xray', 'microquasar', ''], ['nontherm', ''], ['', 'emitt', '', '', 'mev', '', 'andor', '', '', '100gev', '', 'gammaray', ''], ['highenergi', 'microquasar', '', 'accretionpow', '', 'pulsar', '', 'rotationpow', '', ''], ['glast', ''], ['glast', 'microquasar', 'enabl', 'pulsar', 'rotationpow', '']]\n",
      "[['thi', '', 'blanc', '', 'abelian', 'cremona', '', ''], ['acad', ''], ['sci', ''], ['', 'ser', ''], ['344', '', '2007', '', '', '2126', '', ''], ['automorph', ''], ['abelian', 'cremona', '', 'whether', 'birat', 'automorph', ''], ['', 'birat', 'linearis', 'nontrivi', ''], ['for', 'abelian', '', '', 'z2zxz4z', '', 'whose', 'nontrivi', 'automorph', ''], ['we', 'automorph', '', '', 'del', 'pezzo', '']]\n",
      "[['we', 'ptfe', '', '', '', ''], ['pentacen', '', 'pnc', '', 'ptfe', 'ptfe', ''], ['the', 'ptfe', ''], ['ellipsometri', '', '133', '136', 'ptfe', ''], ['ptfe', 'unidirect', ''], ['ptfe', 'pnc', ''], ['the', 'ptfe', 'pnc', '']]\n",
      "[['noncentr', 'pvariat', 'pcube', 'cp', '', '', '', '', '', '', '', '', ''], ['', 'xax', '', ''], ['for', 'pvariat', '', 'p1', '', 'integr', 'cp1', ''], ['the', 'integr', 'numer', 'integr', '']]\n",
      "[['the', '', 'icdm', '', '', 'priori', '', '', ''], ['', 'collabor', '', '', ''], ['with', '', 'icdm', 'memoryless', 'gaussian', '', '', '', ''], ['gaussian', 'highinterferencegain', '', 'consider', '']]\n",
      "[['subset', '', '', 'abelian', '', '', '', '', '', '', 'nonempti', '', '', ''], ['', 'asubset', '', '', '', 'coprim', '', '', ''], ['erdh', '', '', 'heilbronn', '', 'olson', '', '', '', '', '', '', '2sqrt', '', '', '', '', 'vu', '', '', '', 'arbitrari', '', '', '', '', '', '', 'csqrt', '', '', '', '', '', '', ''], ['we', '', '', '', '', '12sqrt', '', 'n4', '', '', '', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', '', '', 'grassmannian', ''], ['monomi', 'geometri', 'combinator', ''], ['the', ''], ['thi', 'grassmannian', 'symplect', 'grassmannian', ''], ['', ''], ['', 'coset', '', '', 'pfaffian', ''], ['', '', '']]\n",
      "[['igr', 'j112155952', 'xray', '2005', 'xray', '', 'supergi', 'xray', '', 'sfxt', '', ''], ['archiv', 'rxte', '330', ''], ['', 'igr', 'j112155952', 'sfxt', '', ''], ['we', '', '2007', ''], ['the', '', '2ksday', '', '', '2007', '', '', '', 'onsourc', ''], ['thi', 'sfxt', ''], ['the', 'photon', 'nh1', '1022', 'cm2', ''], ['kev', '1036', 'erg', 's1', '', 'kpc', '', '', ''], ['these', 'dataset', 'sfxt', '', '', 'igr', 'j112155952', ''], ['we', ''], ['the', 'phenomenolog', 'periastron', 'mani', '', '']]\n",
      "[['', 'ginzburg', '', '', '', '', '', 'schr', '', 'oer', '', 'weig', '', '', '', 'rtner', '2004', '', 'appl', ''], ['chem', '', ''], ['', 'bf', '', '', ''], ['interplay', '', '', '', '', ''], ['we', 'chargeasymmetr', 'shortrang', '', 'without', 'ise', '', ''], ['the', 'landauginzburg', 'hamiltonian', 'gasliquid', 'ginzburg', 'ionic', ''], ['the', '', '', '', '', 'suffici', '']]\n",
      "[['kenzelmann', 'continuum', 'multiferro', 'magneticallyinduc', 'ferroelectr', ''], ['thi', 'success', 'thermodynam', 'magnetoelectr', 'mani', 'multiferro', '']]\n",
      "[['twojunct', '', '', ''], ['hamiltonian', '', ''], ['the', 'overdamp', 'twojunct', 'supercurr', 'qubit', '']]\n",
      "[['we', '', 'nev', '', '', '14um24um', '', '', 'siii', '', '', '18um33um', '', '', 'tradit', '', '', 'agn', '', 'spitzer', ''], ['the', '', 'nev', '', '', 'nev', '', '', ''], ['we', 'agn', 'agn', 'agn', ''], ['we', '', 'nev', '', ''], ['becaus', '', '', '', '', 'nev', '', ''], ['we', '', 'siii', '', ''], ['sinc', 'lowion', '', '']]\n",
      "[['', 'neutrino', 'physicist', 'chooz', 'neutrino', ''], ['neutrino', '235u', '239pu', '']]\n",
      "[['semiclass', ''], ['we', '', 'nonintegr', '', '', 'sinc', 'exit', '', '']]\n",
      "[['we', 'ccd', 'bvi', ''], ['colourmagnitud', 'metal', '', 'without', '', '', '', '', 'metal', '', ''], ['the', '', 'subsolar', 'metal', '', 'z0008', '', 'z0006', '001', 'margin', '', '', '', '5055', 'gyr', '', '', 'without', '4244', 'gyr', '', '', '', '', '0124126', '', '', 'bv', '', '012018', '', 'metal', '', '', 'rgc', '', '10711', 'kpc', '', '', '231254', ''], ['the', '', 'z001', '', 'age35475', 'gyr', '', '', '', '011671175', '', '', 'bv', '', '103106', '', 'rgc', '', '9210', 'kpc', '', '', '253387', '']]\n",
      "[['databas', ''], ['the', 'bibliographi', '', ''], ['', 'coeditor', ''], ['we', 'whose', 'collabor', ''], [''], ['the', 'mani', 'coauthorship', '']]\n",
      "[['wellobserv', 'iip', 'sne', 'photospher', '', 'epm', '', '', ''], ['the', 'epm', 'without', '', ''], ['the', 'sne', '']]\n",
      "[['we', 'nonabelian', 'pseudogoldston', 'boson', '', 'sliv', '', ''], ['to', '', 'sliv', 'yangmil', 'nonlinear', '', 'tr', '', '', 'boldsymbol', '', '', '', '', 'mu', '', 'boldsymbol', '', '', '', '', 'mu', '', '', '', '', '', '', '', '', 'sliv', '', ''], ['with', '', '', '', '', '', '', '', '', '', 'd3d', '', '', 'sliv', ''], ['', 'goldston', 'boson', '', 'pseudogoldston', 'boson', '', '', 'd3d', '', '', 'goldston', 'multiplet', ''], ['', 'massless', '', 'yangmil', ''], ['we', '', 'although', '', 'cpt', '', '', 'sliv', ''], ['', 'could', ''], ['for', 'sliv', 'could', '']]\n",
      "[['the', 'inmedium', 'nucleonnucleon', '', '', 'nn', '', '', 'ion', '', '', 'hic', '', '', ''], ['', 'covari', '', '', 'inelast', '', 'appreci', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'inmedium', 'inelast', ''], ['thi', '', 'sinc', 'uniformli', ''], ['', 'chiral', 'perturb', 'mesonquark', '', '', '', '', '', '', '', '', '', '', ''], [''], ['we', 'observ', '', '', 'eo', '', '', '', '', 'isovector', '']]\n",
      "[['erd', '', '', '', 'tur', '', '', '', '', 'asubsetmathbb', '', '', '', '', '', '', '', '', '', '', '', 'infti', '', 'mani', 'arbitrari', '', 'kgeq3', '', ''], ['for', 'twodimension', '', 'bsubset', 'mathbb', '', '', 'timesmathbb', '', '', '', '', '', 'sumlimit', '', '', '', '', '', 'frac', '', '', '', 'x2y2', '', 'infti', '', '', '', '', 'sgeq2', '', '', '', '', '', 'stime', '', 'axesparallel', ''], ['', 'sgeq2', '', '', 'erd', '', '', '', 'stur', '', '', '', '', 'k2s1', '', '']]\n",
      "[['dure', 'via', '2bodi', '', '', '', 'would', 'unbond', '', 'eg', ''], ['verlet', '', ''], ['thi', '', ''], ['the', 'hysteresi', 'without', ''], ['the', '', '', ''], ['the', ''], ['']]\n",
      "[['we', 'cbase', 'evolutionari', ''], ['we', 'silic', ''], ['we', 'cstar', '', '', 'wr', '', '']]\n",
      "[['', '', '', 'theta', '', '', 'abelian', '', 'subvarieti', ''], ['pareschi', 'popa', 'cohomolog', 'mregular', ''], [''], ['', 'jacobian', '', '', 'abelian', '', 'fano', '', '', 'cohomolog', ''], ['mregular', '']]\n",
      "[['we', '', '', '', '', 'noncommut', ''], ['we', '', '', 'widthin', 'renormaliz', 'noncommut', ''], ['the', 'oneloop', 'renormaliz', ''], ['', 'noncommut', '', 'noncommut', ''], ['would', ''], ['', '', 'noncommut', 'tev', '']]\n",
      "[['overview', '', '', 'highlycharg', 'ion', '', 'hitrap', 'gsi', 'darmstadt', '', '', ''], ['these', 'highresolut', 'hyperfin', 'split', ''], ['', 'hyperfin', 'split', 'lithiumlik', 'ion', 'isotop', '', 'electromagnet', ''], ['ion', '']]\n",
      "[['we', 'josephson', ''], ['for', '', 'without', '', ''], ['the', '', 'allometr', ''], ['for', '', ''], ['for', '', ''], ['our', '']]\n",
      "[['', 'fmft', '', ''], [''], ['c2h2', '', 'mu', '', '']]\n",
      "[['', '', ''], ['the', 'extent', 'univoc', 'poincar', '', 'hartlehawk', '']]\n",
      "[['the', 'noncommut', '', 'chamseddin', '', 'conn', 'via', 'zeta', ''], ['the', 'diophantin', ''], ['holomorph', 'holomorph', '']]\n",
      "[['we', 'lifshitzslyozovwagn', 'stefantyp', 'reactioncontrol', ''], ['', 'meanfield', 'surfacearea', '']]\n",
      "[['we', 'azd', '', 'supercanon', 'azd', '', 'project', 'pseudoeffect', ''], ['we', 'supercanon', 'azd', '', '', '', '', '', '', '', 'project', 'plurigenera', '']]\n",
      "[['we', '', 'timehomogen', '', 'onedimension', 'duffi', '', 'filipov', 'schachermay', ''], ['we', '', '', ''], ['', ''], [''], ['we', 'cumul', ''], ['we', 'vasicek', '', 'cir', '', 'cir', 'ornsteinuhlenbeck', '']]\n",
      "[['the', 'lightemit', ''], ['polym', '', '', 'oxadiazol', 'quinoxalin', ''], ['both', '']]\n",
      "[['thi', 'microfluid', ''], ['', 'nanolitervolum', 'droplet', 'solut', ''], ['', 'enabl', 'quantit', '', ''], ['we', '', 'adip', '', '250', '', 'mu', '', '']]\n",
      "[['subset', 'fraction', 'conform', '', 'cft', '', 'correl', '', 'notabl', 'laughlin', '', 'nu1m', '', '', '', '', '', 'quasihol', '', 'pfaffian', '', 'nu12', '', 'quasihol', ''], ['we', 'compositefermion', '', '', 'conform', ''], ['quasiparticl', '', 'nu1m', '', 'anyon', '', '', '', 'frac', '', '', '', '', '', '', '', '', '', 'subset', 'correl', ''], ['the', 'onequasiparticl', '', 'twoquasiparticl', 'fraction', 'numer', ''], ['we', 'wavefunct', '', 'nu', '', '', '2sp1', '', '', 'cft', 'correl', 'fermion', '', '', '', '', '', '', '', '', '', '', '', 'compactifi', 'boson', '', 'cft', 'fermion', '', '2p', '', '', '', 'rm', '', '', ''], ['we', 'quasiparticl', 'quasihol', 'fraction', ''], ['for', 'chiral', 'cft', '', '', '', '', '', '', '', '', ''], ['our', 'quasiparticl', 'fraction', '', '']]\n",
      "[['timedepend', 'dalitz', '', '', '', 'pippimpiz', '', 'dataset', '346', '', '', '', 'upsilon', '', '', '', 'babar', 'slac', 'pepii', '', '', ''], ['cp', '', '', '', '', '', '', '152', '', '', '']]\n",
      "[['thermal', 'polym', '', 'optoelectron', '', 'lightemit', '', 'electrochem', '', 'photodiod', '', 'photovolta', '', '', 'optocoupl', 'optic', 'statew', 'poli', '', 'pphenylen', 'vinylen', '', '', 'ppv', '', '', '', ''], ['', '', 'microscop', '', 'afm', '', 'dektak', '', 'ellipsometri', 'uvvi', '']]\n",
      "[['the', 'kleingordon', 'ddimens', 'kratzer', 'ringshap', 'analyt', 'nikiforovuvarov', ''], ['the', 'boundstat', 'kleingordon', 'noncentr', ''], ['the', 'threedimens', '']]\n",
      "[['we', '', '', 'timescal', 'detect', '', ''], ['timescal', 'leastsquar', 'statist', 'boxshap', '', ''], ['', '', ''], ['', 'smallapertur', '', 'whose', 'presentday', '', '', '', '']]\n",
      "[['we', 'nonperturb', 'bertrand', 'concis', '', 'oscil', '']]\n",
      "[['the', '13050007', 'metalpoor', 'doubleenhanc', 'metal', '', 'feh', '', '', '', '', 'metal', 'doubleenhanc', ''], ['parametr', '', 'selement', 'neutron', ''], ['thi', 'postcommonenvelop', ''], ['sprocess', 'neutron', 'nucleosynthesi', 'dredgedup', '', 'agb', 'commonenvelop', ''], ['radialveloc', '13050007', '', 'could', '', 'aic', 'rprocess', '']]\n",
      "[['', 'm5brane', ''], ['', '']]\n",
      "[['we', 'supergranular', '', '', '', ''], ['the', '', 'caii', '', '', 'twolevel', '', 'tst', '', '', 'ibi', ''], ['the', 'photospher', ''], ['', ''], ['we', 'cospati', 'caii', 'photospher', ''], ['the', ''], ['the', 'upflow', ''], ['', 'converg', 'cospati', 'caii', '']]\n",
      "[['we', 'ccd', 'widefield', 'galaxyclust', '', '', ''], ['thi', 'xray', '004', '', '', '007', ''], ['we', 'dedica', '', 'adaptivekernel', ''], ['we', 'montecarlo', ''], ['dedica', ''], ['', 'colormagnitud', '', ''], ['the', 'subclust', '', '', '', ''], ['the', 'subclust', '', 'bcg', '', ''], ['', '10112', 'lsun', '', 'subclust', '']]\n",
      "[['we', 'montecarlo', 'occur', 'spinglass', 'singledomain', 'ferromagnet', 'nanoparticl', 'dipolar', 'anisotropi', '', 'posit', 'orient', ''], ['we', 'orient', 'anisotropi', '', 'ise', ''], ['sinc', 'dipolar', 'favor', 'antiparallel', '', 'antiparallel', '', 'spinglass', ''], ['', '']]\n",
      "[['', '', '', '', '', '', '', ''], ['we', 'cardin', 'subset', '', 'irr', '', 'gv', '', '', '', '', 'chiinirr', '', 'gv', '', '', '', '', 'vin', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['these', '', 'coprim', '', '', 'gv', '', '', '', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'statist', 'deltapin', ''], ['depin', 'without', ''], ['wrt', ''], ['uniformli', ''], ['how', 'hamiltonian', ''], ['we', 'arbitarili', 'random', 'deltapin', 'deloc', ''], ['the', 'random', ''], [''], ['we', 'inequ', '']]\n",
      "[['', 'dh', '', '', '', 'unit', '', '', '', '', '', 'algebra', '', '', 'dh', '', 'selfabsorb', ''], ['unit', '', '', '', '', '', 'dh', '', '', 'otim', 'dh', '', 'unitarili', ''], ['we', '', '', 'dh', '', '', '', '', '', 'inject', '', 'asymptot', 'unitarili', ''], ['thi', 'unit', 'endomorph', '', 'dh', '', 'asymptot', ''], ['', 'automorph', '', 'dh', '', 'compactlycontract', '', 'pointnorm', '', 'hausdorff', '', '', '', 'homotopi', '', '', '', 'aut', '', 'dh', '', '', '', ''], ['the', 'unit', 'endomorph', '', 'dh', '', ''], ['', '', 'kk', '', 'dh', '', 'aot', 'dh', '', '', '', '', '', '', 'asymptot', ''], ['', '', 'kk', '', 'dh', '', 'aot', 'dh', '', '', '', 'k0', '', 'aot', 'dh', '', '', '']]\n",
      "[['from', '', 'njl', ''], ['the', 'noninteract', 'interact', 'via', 'njl', '']]\n",
      "[['the', 'interlandau', 'farinfrar', 'fewlay', 'graphen', 'graphen', ''], ['thi', '', 'qualit', '']]\n",
      "[['the', 'ejecta', '', ''], ['', 'sne', ''], ['', '', '', 'revisit', 'todini', '', 'ferrara', '', '2001', '', 'ejecta', 'sne', '', '', '', '', '', '', ''], ['we', '01', '', '06', 'msun', 'ejecta', '', 'msun', ''], ['', '220', '', '', 'timescal', '104', ''], ['toward', ''], ['the', 'qso', ''], ['stochast', ''], ['thi', '', '', '01', 'msun', '', '', '', '40k', '', '', 'without', '']]\n",
      "[['the', 'thermodynam', 'nucleic', 'doublelay', 'microion', 'polyion', ''], ['we', 'coulomb', 'saltpolyelectrolyt', '', 'donnan', '', 'coeffici', '', 'polyion', 'deby', '', ''], ['the', 'poissonboltzmann', '', 'geometri', '', 'polyion', '', '', 'counterion', '', '', ''], ['the', 'electrolyt', '', '', '', '', '', ''], ['we', 'polyion', '']]\n",
      "[['asymptot', 'via', '', 'microst', '', 'random', '']]\n",
      "[['we', 'jun', ''], ['1983', ''], ['2005', '', ''], ['these', 'realest', '', '', '2003', 'mid2004', 'prebubbl', '2005', ''], ['2002', 'mediums', '1990', ''], ['', 'finetun', ''], ['could', '', 'intrayear', '', '', '', ''], ['we', '', '2006', ''], ['the', '', '', 'mid', '2004', 'mid2006', '', '']]\n",
      "[['we', 'hermitian', ''], ['for', 'hermitian', 'gf', '', 'q2', '', '', '', 'q2', '', 'vlsi', ''], ['the', 'encod', 'varyingr', 'reedsolomon', 'encod', '', 'q2', '', '']]\n",
      "[['', 'qcp', '', 'antiferromagnet', 'paramagnet', 'hydrostat', '', '', '', '', 'rho', '', '', '', '05', 'muomegacm', ''], ['we', '', 'rho', '', '', '', '2x', '', '', '', 'solidsolut', '', 'drastic', ''], ['paramagnet', '', '', '', '', '', 'rho', '', '', 'sim', '', '', 'rho', '', '', '', '', 'robustli', '']]\n",
      "[['the', 'pdope', 'gaa', '', '', '', 'picosecond', 'pumpprob', 'kerr', 'inplan', ''], ['for', 'exciton', ''], ['radi', 'exciton', ''], ['dephas', '650', ''], ['the', 'dephas', 'inplan', '', 'cryogen', '']]\n",
      "[['we', 'clausiusmossotti', 'magnetodielectr', 'radi', 'oscil', ''], ['to', 'electromagnet', 'bicub', '', '', ''], ['linewidth', 'oscil', 'selfconsist', 'selfinteract', ''], ['we', 'radi', 'suffici', 'freespac', '', 'rho', 'lambda3', 'gg', '', '', '', 'rho', '', 'scatter', ''], ['sinc', '', '1rho', '', 'lowloss', '']]\n",
      "[['bquark', 'delphi', 'lepii', ''], ['the', 'centreofmass', '196', '209', 'gev', '', '420', '', '', ''], [''], ['', '', '', '', 'bz', '', '', '', '', '', 'cw', '', '', '103', 'gevc2', ''], ['these', '', '', '', 'ckm', '', '', 'cb', '', '', '', '', '', '', '', '', '', '', 'cb', '', '', '', '', '', '', '', '', 'ckm', '']]\n",
      "[['we', 'pseduoriemannian', '', '', '', '', '', '', '', '', 'gf', '', '', '', '', '', 'oplu', 'w2', 'gf', '', '', '', '', '', 'mu', '', 'oplu', 'w2', 'gf', '', '', '', '', '', '', 'infti', '', '', '', 'mu', '', ''], ['we', 'ricci', ''], ['if', '', '', '', '', '', 'riemannian', '', 'nonlinear', 'concaveconvex', 'nonlinear', 'lichnerowiczyork', 'among', 'other', '']]\n",
      "[['thi', 'pseudoriemannian', 'weyl', 'conform', '']]\n",
      "[['', '', 'ww', '', '', '', 'q1', 'qbar2', '', '', 'q3', 'qbar4', '', 'hadron', 'q1', 'qbar2', 'q3', 'qbar4', 'boson', ''], ['', 'sinc', 'parton', '', 'hadron', 'gluon', ''], ['thi', 'reconnect', ''], ['reconnect', 'hadron', 'delphi', 'lep', ''], ['', '', '', ''], ['', 'kappa', '', 'kappa', '', '', '', '', '', '', '', '', 'reconnect', '', 'reco', '', '031', '', '', 'reco', '', '', '068', '', '052', '']]\n",
      "[['', ''], ['determinist', '', ''], [''], ['which', ''], ['evolutionari', '', 'eng', '', '', ''], ['the', 'ecosystem', ''], ['those', '', ''], ['the', 'eng', 'scalefre', '', '']]\n",
      "[['xray', 'cuprat', 'superconductor', 'bi2sr2cacu2o8', '', '', '', 'pseudogap', 'photoemiss', ''], ['we', 'critic', 'xray', '', 'paritybreak', ''], ['dichroism', ''], ['we', 'xray', 'whether', '']]\n",
      "[['we', '', 'random', '', 'subset', '', 'wm', ''], ['thi', '', 'whose', '', ''], ['we', 'suffici', 'wm', ''], ['we', 'partitionregular', 'coeffici', 'wm', '']]\n",
      "[['we', '', 'dbar', '', 'higg', ''], ['topquark', '', '', '3time', '', 'cabibbokobayashimaskawa', 'nonunitari', '', '4time', '', 'zmediat', ''], ['', '', 'dbar', '', '', '', '', 'dto', 'xu', '', 'cp', 'could', '', '', '', '', '', ''], ['', '', 'dto', 'xu', 'ell', '', '', '', 'ell', '', '', '', '', '', '', 'dto', 'xunu', 'nu', '', '', 'dto', 'mu', '', '', '', 'mu', '', '', '', '', 'could', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']]\n",
      "[['we', ''], ['these', 'chiral', 'gev', ''], ['thi', 'technicolor', '']]\n",
      "[['we', 'coeffici', 'lineofsight', 'solar', 'photospher', 'nonmagnet', 'photospher', ''], ['the', 'anticorrel', '06', 'lineofsight', 'nonmagnet', 'photospher', 'tau5', '', '04', ''], ['the', 'decorrel', '5min', '']]\n",
      "[['we', 'muonspin', 'hightc', 'cs2agf4', ''], ['we', '', '', 'tc1395', '', '', 'the', 'intraplan', 'jj19', '102', '', 'beta0292', '', '', '', ''], ['dipolar', 'fmuf', '', '']]\n",
      "[['we', 'd0bar', '', '', '0pi0', 'm38752pm', '07', '', '03', '', '', '', '', '08', 'mev', 'bell', 'bto', 'd0bar', '', '', '0pi0', 'wellestablish', '', '3872', '', ''], ['we', 'flatt', 'd0bar', '', '', '0pi0', '', 'pipi', 'jpsi', '', '3872', '', ''], ['', '3872', '', 'd0bar', '', '', '', '', '', '', '', '', '3872', '', ''], ['', 'd0bar', '', '', '', '', '', '', 'mev', 'd0bar', '', '', '', '', '', '', '', 'nonbreitwign', '']]\n",
      "[['the', '', '', ''], ['we', 'threedimension', 'arbitrari', ''], ['diodic', 'detun', '']]\n",
      "[['we', 'plasmon', 'twodimension', 'graphen', ''], ['the', 'plasmon', 'interband', 'electronhol', 'graphen', 'plasmon', ''], ['we', 'plasmon', 'electronhol', '', '', '', '', '', '', '', '', '', '', 'electronhol', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'plasmon', 'intraband', ''], ['plasmon', 'intraband', ''], ['could', 'amplifi', 'oscil', '', 'mu', '', '']]\n",
      "[['we', 'birat', ''], ['biration', 'chern', ''], ['we', 'coeffici', ''], ['irreduc', 'sylvest', 'via', 'computerassist', ''], ['for', ''], ['the', 'affirm', '']]\n",
      "[['enabl', 'eavesdropp', ''], ['we', '', '', 'versu', ''], ['we', '', '', '']]\n",
      "[['we', 'collisionless', 'gaussian', 'nonloc', 'nonlinear', ''], ['for', 'defocus', 'nonlinear', 'nonloc', '', 'though', 'qualit', '', 'wherea', 'nonlinear', 'filament', ''], ['the', 'defocus', '']]\n",
      "[[''], ['statist', '', 'rbfnn', '', 'success', ''], ['rbfnn', ''], ['', '']]\n",
      "[['we', 'nonlinear', '', 'hepph0609105', '', 'hepph0609090', '', ''], ['', 'hepph0408216', '', ''], ['the', 'consider', 'anomal', ''], ['the', '', '', ''], ['these', ''], ['we', 'numer', '', ''], ['we', 'nonlinear', ''], ['']]\n",
      "[['anisotrop', 'singleparticl', ''], ['', '', 'inelast', '', 'eftaugg', '', ''], ['phononassist', 'via', 'nonmonoton', 'caxi', '']]\n",
      "[['we', '', 'omegan', '', 'nontrivi', 'holomorph', '', 'omegan', '', '', '', 'ngeq', '', '']]\n",
      "[['the', 'onto', ''], ['we', '', 'rearrang', 'onto', ''], ['we', 'consensu', '', 'incongru', '']]\n",
      "[['we', 'multiwavelength', 'interferometr', 'herbig', 'ae', 'hd', '163296', 'irampbi', '', 'sma', 'vla', 'continuum', '12co', '', '13co', 'c18o', ''], ['selfconsist', ''], ['the', 'circumstellar', 'continuum', 'we', 'circumstellar', 'keplerian', 'msun', ''], ['the', '464', 'deg', '1284', 'deg', ''], ['the', '087', '', 'beta1', '', 'mmcmsize', ''], ['the', 'continuum', '540', ''], ['the', ''], ['', 'isotopom', '12co', '13co', 'c18o', ''], ['we', 'hd', '163296', ''], ['', '', '']]\n",
      "[['the', 'chromospher', 'groundbas', ''], ['we', 'spectropolarimetr', '8498', '8542', 'plasmabeta', ''], ['stoke', '', 'arguabl', '', ''], ['', 'stoke', '', ''], ['we', 'stoke', '', 'histogram', ''], ['both', 'internetwork', ''], ['', '', 'highbeta', '', 'selfrevers', '']]\n",
      "[['irreduc', ''], ['irreduc', 'we', '', 'n1', '', '', 'n2', '', '2dk', 'we', '', '', ''], ['if', '3ng1k', '', '', '3g3', '', '3g3rhok', '', '', 'rho', 'brillneoth', 'we', ''], ['irreduc', 'nonposit', 'brillnoeth', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'mssm', 'higg', 'boson', 'lhc', ''], ['we', 'mssm', 'higg', 'boson', 'fb1', ''], ['thi', 'stateoftheart', 'mssm', 'higgsboson', ''], ['the', 'mssm', 'tanbeta', 'higgsboson', '', ''], ['we', 'sigma', 'matanbeta', 'supersymmetr', ''], ['the', 'higgsino', 'mu', '', 'via', 'higherord', 'radi', 'via', 'kinemat', 'higg', 'supersymmetr', ''], ['', 'mu', '', 'prospect', '', 'correspondingli', '', 'lhc', '', '', 'tanbeta', '', '', 'supersymmetr', ''], ['higg', 'boson', ''], ['we', '', '', 'could', 'mssm', 'mssm', 'higg', 'boson', 'lhc', '']]\n",
      "[['we', '', 'cspn', '', '', '', 'wd', '', ''], ['we', '002', '', 'odot', '', ''], ['the', 'cspn', '', '061', 'rm', 'modot', '', ''], ['the', 'wd', '', '', '058', 'rm', 'modot', '', '', ''], ['postagb', 'bl', '', 'ocker', ''], ['per', 'wd', 'pn', ''], ['', 'wd', '']]\n",
      "[['if', '', 'mu', '', '', '', '', 'cmu', '', 'cauchi', ''], ['the', '', 'mu', '', 'reflectionless', '', '', '', 'cmu0', '', '', 'mu', '', ''], ['we', '', 'mu', '', 'reflectionless', 'cauchi', '', 'cmu', '', '', 'summabl', '', 'mu', '', '', 'mu', '', ''], ['reflectionless', 'whose', '', '', '', 'l1', '', '', ''], ['we', 'reflectionless', 'giorgi', '']]\n",
      "[['irreduc', 'sextic', ''], ['irreduc', 'm4', '', 'm4', '', '', 'm4', 'parametr', 'the', '', ''], ['we', ''], ['irreduc', '']]\n",
      "[['anisotrop', ''], ['the', 'proton', ''], ['the', ''], ['', '']]\n",
      "[['the', 'stepedg', 'electromigr', 'continuum', 'langevin', ''], ['if', 'electromigr', 'updown', '', 'stepedg', 'masstransport', '', '', '', '', '', 'terracewidth', '', 'tau', '', 'upon', '', '', '', '', '', '', '', '', '', '', 'adatom', 'electromigr', '', '', '', ''], ['for', '', '', '', 'tau', '', '', '', '', '', '', '', '', '', '', '', ''], ['for', '', 'tau', '', ''], ['thi', 'montecarlo', ''], ['electromigr', 'upon', 'stepedg', 'statist', 'stepedg', 'timescal', '']]\n",
      "[['we', 'renorm', 'susi', 'su', '', '', ''], ['the', 'higgsino', 'scanrio', 'susi', ''], ['']]\n",
      "[['', 'threeyear', 'wmap', 'sachswolf', '', 'isw', '', ''], ['the', 'gaussian', '', 'signedintens', '', ''], ['wmap', ''], ['the', 'signedintens', '999', '', ''], ['signedintens', '', 'wmap', ''], ['systemat', 'wmap', ''], ['our', 'isw', ''], ['', 'isw', ''], ['', '']]\n",
      "[['the', 'electromagnet', '', '', 'lightfront', ''], ['', 'quarkantiquark', 'covari', ''], ['', '', '', '']]\n",
      "[['we', 'postnewtonianinspir', 'nonspin', 'blackhol', '', ''], ['we', 'revisit', 'tichi', 'et', ''], ['', 'tichi', '', 'bruegmann', '', 'campanelli', '', 'diener', '', 'phi', ''], [''], ['', '064008', '', '2003', '', '', '', 'explicitli', ''], ['these', '', '', ''], ['we', '', 'transversetraceless', 'quadrupoleapproxim', ''], ['these', '', 'postnewtonian', 'inspir', '']]\n",
      "[['we', 'fd', '', '', 'nu', '', 'either', 'mu', 'tau', '', 'tau', '', '', 'nu', ''], ['fd', '', '274', '', 'mev', ''], ['fd', '', 'fdsfd', '', '123', '', '011', '', '004', ''], ['we', '']]\n",
      "[['we', '', 'eto', 'pipigamma', '', '', '', 'kkpi0pi0gamma', '', '', 'kgamma', '', '', 'photon', ''], ['34600', '', '4400', '2300', '', '', '232', 'invfb', 'babar', ''], ['the', 'hadron', 'epem', 'centerofmass', '', '', 'pipigamma', '', '', 'eto', 'kk', 'pipi', '', '', '', 'eto', 'pi0pi0', '', '', 'epemto', '', ''], ['', '', ''], ['', '', 'etophi', '', '1020', '', '', '', '', '980', '', '', ''], ['charmonium', '', '', 'jpsi', '', '', '', '', '', '', '', ''], ['we', '', '4260', '', '', '', '', '4260', '', 'tophipipi', '', 'cdotgamma', '', '', '', '', '', '', '04', '', '', '']]\n",
      "[['anomal', 'boundstat', '', 'hydrino', '', 'bona', 'fide', 'schr', '', '', '', 'dinger', '', 'kleingordon', '']]\n",
      "[['', 'extrasolar', '', '', 'lowmass', '', '', ''], ['we', 'toward', ''], ['', ''], ['these', ''], ['thi', 'meanmot', '', '', ''], ['groundbas', 'alreadi', 'subearth', ''], ['', 'ttv', 'highprecis', ''], ['these', 'ttv', ''], ['groundbas', '', '', 'sim', '05', '', 'rm', '', '', 'could', '']]\n",
      "[['electronphonon', 'superconduct', 'phonon', 'quasi2d', ''], ['migdaleliashberg', ''], ['dwave', 'superconduct', 'halffil', ''], ['the', 'undergo', 'swave', 'superconduct', ''], ['dwave', ''], ['pseudopotenti', 'superconduct', '', 'superconduct', 'cuprat', '', '', 'swave', '', 'dwave', 'unmodifi', '']]\n",
      "[['coarsegrain', 'comput', 'protein', 'supramolecular', ''], ['', 'protein', 'solventexclud', ''], ['the', 'discret', 'arbitrari', ''], ['the', 't4', 'actin', '', ''], ['allatom', '', '', ''], ['the', 'comput', 'protein', 'atomiclevel', '', 'aqueouselectrolytemedi', ''], ['the', 'applic', 'protein', 'protein', '', 'protein', '', 'supramolecular', '']]\n",
      "[['thi', 'astroph0604264', ''], ['we', 'astroph0507439', ''], ['astroph0604264', ''], ['nucleosynthesi', 'without', '']]\n",
      "[['twodimension', '', '2dc', '', 'nonlinear', 'exciton', 'ultrafast', '', ''], ['the', '2dc', '', '', 'sumoverst', 'manybodi', 'eigenst', ''], ['', '', 'quasiparticl', ''], ['phasematch', ''], ['the', 'frenkel', 'exciton', '', 'boson', '', 'vibrat', 'exciton', '', 'softcor', 'boson', '', '']]\n",
      "[['we', 'euv', '', '', 'lopez', '', 'klimchuk', '', 'demoulin', '2006', '', ''], ['for', '', 'textit', '', '', '', ''], ['we', '', ''], ['we', 'appreci', '', 'forcefre', ''], ['thi', ''], ['the', ''], ['we', 'smallscal', ''], ['the', ''], ['we', '', '', 'largescal', ''], ['the', '']]\n",
      "[['we', '', 'jpsi', '', '', 'psiprim', '', '', '', '', '', '06', '', '', 'geq', 'pgev', '', ''], ['the', '', '800', 'ipb', '', 'cdf', ''], ['for', '', '', '', '', 'pgev', '', ''], ['these', 'nonrelativist', 'chromodynam', ''], ['the', '', 'jpsi', '', '', 'psiprim', '', '', '', 'hadron', '']]\n",
      "[['we', 'nongaussian', 'boson', 'nongaussian', 'hilbertschmidt', 'gaussian', ''], ['we', 'nongaussian', 'relev', 'multimod', ''], ['the', 'nongaussian', 'undergo', 'gaussif', 'degaussif', 'photonsubtract', ''], ['the', 'boson', 'nongaussian', '']]\n",
      "[['we', '', 'skewhadamard', '188', '388', ''], [''], ['the', 'goethalsseidel', '']]\n",
      "[['we', 'photon', ''], [''], ['', 'determinist', ''], ['', 'photon', ''], ['we', '', '', 'ion', '', '', '']]\n",
      "[['drellyan', 'dilepton', 'inclus', 'photon', ''], ['the', 'nonperturb', 'dglap', ''], ['we', 'success', 'dilepton', '800gev', 'pp', '', 'inclus', 'photon', 'pp', 'rhic', '', 'sqrt', '', '', '', 'gev', '', '', 'pbar', '', '', '', 'tevatron', '', 'sqrt', '', '', '', 'tev', '', '']]\n",
      "[['we', 'ultrastrong', '', 'usel', '', '', '', '', ''], ['542', '8150', '9140', 'subarusuprimecam', ''], ['keckiideimo', '', 'oiii', '', '5007', '', '', 'oii', '', '3727', '', 'strongemiss', '', '', '', '', 'ly', 'highredshift', '', '', '', '', ''], ['we', 'usel', '', '510', '', 'continuum', 'z01', '', ''], ['mani', 'usel', 'temperaturesensit', '', 'oiii', '', '4363', '', 'xmpg', '', ''], ['these', 'xmpg', ''], ['our', 'xmpg', ''], ['the', 'metal', '12log', '', '', '', '706', '', '678744', '', '', 'metal', ''], ['the', '', 'metal', 'usel', 'emitt', '', '']]\n",
      "[['jaeger', 'tutt', 'homfli', ''], [''], ['we', '', 'tutt', 'homfli', '', ''], ['we', 'homfli', 'tutt', '']]\n",
      "[['we', 'f2v', 'hd', '15115', '', 'keck', 'nearinfrar', ''], ['the', 'hd', '15115', ''], ['the', '315', '', 'wherea', '', '550', ''], ['we', 'nearinfrar', 'mic', ''], ['the', 'hd', '15115', '', 'kinemat', ''], ['12545', '', '05', '', '038', '', 'hd', '15115', '', 'heliocentr', '', '', '']]\n",
      "[['', 'erh', '', ''], ['suffici', '', '', 'muh', '', ''], ['erh', 'muh', '', '', 'irreduc', '', '', '', '', ''], ['decid', '', '', '', ''], ['', '', '']]\n",
      "[['detectionnondetect', ''], ['', 'rt', '', '', '03', '', '', '', '', '', '', ''], [''], [''], ['the', 'kklt', '', 'gravitino', ''], ['for', 'gravitino', '', '', '', '', '', '', 'tev', '', '', '', '', ''], ['', '', '', 'would', 'gravitino', 'superheavi', '', '', '', '', '', '', 'gev', ''], ['thi', 'would', 'phenomenolog', '']]\n",
      "[[''], ['multigraph', 'whose', 'synaps', ''], [''], ['coeffici', '', 'fft', '', ''], ['those', 'coeffici', 'multidimension', ''], ['avers', 'pseudometr', ''], ['the', 'neurodynam', '', 'synapt', ''], ['the', 'electrostat', '', ''], ['sinc', '', 'would', ''], [''], ['the', ''], ['the', 'electrophysiolog', '', 'hemodynam', '']]\n",
      "[['we', 'noncommut', 'jacobian', 'algebra', ''], ['thi', 'representationtheoret', 'arbitrari', ''], ['thi', 'farreach', 'bernsteingelfandponomarev', 'functor', ''], ['the', '', 'superpotenti', '', 'calabiyau', 'algebra', '', 'algebra', '']]\n",
      "[['we', 'boseeinstein', '', 'bec', '', 'fermion', ''], ['our', 'bec', 'coher', '', 'becfermion', '', ''], ['we', '', '', '', '', '', '', '', '', '', '', '', 'katom', '']]\n",
      "[['we', 'higheffici', 'ultrathin', '', 'submicron', '', ''], ['interact', 'electromagnet', 'solar', ''], ['we', 'photovolta', '']]\n",
      "[['we', 'chemodynam', 'supernova', '', '', 'starform', '', '', '', 'civ', 'ovi', '', 'intergalact', ''], ['we', '', ''], ['', '', ''], ['we', '', 'lo', '', '', 'adelberg', 'et', '', ''], ['', ''], ['the', 'without', 'civ', 'ovi', 'lo', 'kpc', '', 'civ', 'ovi', ''], ['we', 'transmiss', '', 'civ', '', 'ovi', '', '', '', '', '', 'mpc', 'starform', ''], ['the', 'transmiss', '', 'lo', 'transmiss', ''], ['', 'ovi', ''], ['we', 'ovi', '']]\n",
      "[['we', 'timedomain', '', 'st', '', 'uckelberg', 'interferomet', '', '', 'ultracold', 'feshbach', ''], ['subsequ', 'highcontrast', ''], ['thi', ''], ['we', 'interferomet', ''], ['the', 'interferometr', 'ultracold', '']]\n",
      "[['we', 'lymanalpha', 'absorb', '', 'dla', '', '', 'toward', '', 'dla', 'subdla', ''], ['we', 'lyalpha', ''], ['', 'statist', 'lyalpha', ''], ['the', 'dla', ''], ['lyalpha', 'dla', '', 'system', 'dla', ''], ['the', 'kpc', '', ''], ['qso', '', 'dla', 'kpc', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', ''], ['the', '', 'ugriz', ''], ['bandpass', 'loword', 'lightcurv', ''], ['we', '', 'g205', '005', '', 'rm', '', ''], ['the', '', '', 'lowredshift', '', '', '', '', 'although', '', 'fluxlimit', ''], ['we', '', '003', '', 'rm', '', 'lowredshift', '', '', ''], ['we', 'lightcurv', ''], ['we', 'rr', 'lyra', '', '05', '', '005', ''], ['the', 'lightcurv', 'gr', 'ug', 'colorcolor', 'bimod', '', 'algollik', '', ''], ['rr', 'lyra', '', 'kpc', ''], ['we', 'wellsampl', '', '', 'lightcurv', 'lowredshift', '', '']]\n",
      "[['we', 'variat', ''], ['optim', '', '', 'variat', '', '', '', 'deltadifferenti', '', 'lagrang', '', '']]\n",
      "[['the', 'heliospher', '', 'interstellar', ''], ['interstellar', '', 'lic', '', 'heliospher', 'radi', ''], ['we', 'interstellar', 'fuv', 'euv', 'xray', ''], ['we', 'lic', '', '', '', ''], ['we', 'lic', '', 'radi', 'transfertherm', ''], ['situ', 'heo', '', 'ion', 'anomal', 'heliospher', '', 'toward', 'epsilon', 'cma', ''], ['lic', ''], ['the', '', '', 'lic', '', '', 'h0', '', '', '019', '', '020', 'cm3', '', '', '', '', '007', '', '001', 'cm3', ''], ['', 'subsolar', '', '', 'subsolar', '', 'solar', '', 'supersolar', ''], ['the', 'interstellar', '', '', '', '', '', '', '023', '', '027', 'cm3', '', '', '6300', '', '', '', '', '02', '', '', '', '', '04', ''], ['these', 'sinc', ''], ['our', 'solar', 'lic', '']]\n",
      "[['twodimension', '', '2deg', '', 'halffil', '', 'ferromagnet', '', ''], ['the', 'deloc', 'spinexciton', 'renorm', '2deg', 'ntype', 'gaa', 'land', '', 'gfactor', '2deg', ''], ['if', '2deg', 'gfactor', '', '', 'spinflip', 'skyrmionlik', '', ''], [''], ['', '7343lp', '', '7321fg', '', '7215rn']]\n",
      "[['the', 'gammaray', '', 'lgrb', '', 'supernova', 'woosley', '', 'collapsarhypernova', '', 'grb', ''], ['the', 'lgrb', 'starform', 'lowmetal', 'collapsar', ''], ['both', 'completelymix', ''], ['grb', ''], ['we', 'tidal', 'corehelium', 'timescal', '', '', ''], ['', 'coreenvelop', 'subsequ', 'evolutionari', 'mainsequ', 'hypernovaegrb', ''], ['', 'neutronstar', 'blackhol', '', 'coreenvelop', 'posthelium', '', 'suffici', 'hypernovagrb', '']]\n",
      "[['when', 'elast', '', ''], ['these', '', 'mesoscop', '', ''], ['', 'multiscal', ''], ['to', '', 'densityfunctionaltheori', ''], ['these', 'complement', 'semiempir', '', 'poli', '', 'cg', '', 'poli', '', 'cg', '', '', '', '', ''], ['the', 'parametr', 'tightbind', '', ''], ['these', 'hamiltonian', ''], ['the', 'unstretch', '']]\n",
      "[['', 'ration', 'fibrat', 'submanifold', 'ambient', ''], ['project', 'submanifold', '', '', '', ''], ['mori', 'project', 'fibrat', '']]\n",
      "[['', '', 'semisimpl', '', 'ghat', '', ''], ['the', '', 'ghat', '', 'cohomolog', '', '', '']]\n",
      "[[''], ['', 'groupveloc', '', 'kerr', 'nonlinear', 'via', ''], ['', 'decoher', 'adiabat', '', 'tsang', '', 'phi', ''], [''], ['lett', ''], ['', '023902', '', '2006', '', '', 'numer', ''], ['the', 'appreci', '', 'gordonhau', ''], ['the', 'decoher', 'quantumenhanc', '', '']]\n",
      "[['we', 'whose', '', '', ''], ['our', 'highfrequ', '', 'p500', '', 'dax', 'wig20', '2004', '', '2006', ''], ['our', ''], ['thi', '']]\n",
      "[['we', 'defocus', '', '', '', '', '', 'hartre', '', '', 'ngeq', '', '', ''], ['we', 'wellposed', ''], ['the', '', 'displaystyl', '', 'int', '', '', 'int', '', 'xleq', '', '', '', '', '', '', 'frac', '', '', '', '', '', 'dxdt', '', 'morawetz', '', 'morawetz', 'nonlinear', '']]\n",
      "[['we', 'gaussbonnet', 'braneworld', ''], ['we', 'gaussbonnet', ''], ['we', 'superacceler', '']]\n",
      "[['the', '', '', 'tupl', 'unit', '', '', '', '', 'algebra', 'voiculescu', ''], ['', 'selfadjoint', 'selfadjoint', 'unit', '', '', '', '', 'algebra', ''], ['', 'unit', '', '', '', '', 'algebra', '', '', '', '', '', '', 'algebra', '', '', '', '', 'algebra', '', '']]\n",
      "[['ccbar', 'jpsi', ''], ['jpsi', 'auau', 'rhic', 'lhc', ''], ['the', 'ccbar', 'parton', 'pretherm', 'parton', 'ccbar', '', '', '2s1', '', 'lj', '', 'ccbar', '', '', '2s1', '', 'lj', '', '', ''], ['ccbar', 'via', '', '', '', 'ccbar', 'gluon', 'ccbar', '', '', '', 'ccbar', 'gluon', ''], ['ccbar', 'pretherm', 'rhic', 'ccbar', '', '', '2s1', '', 'lj', '', 'lhc', 'parton', 'pretherm', 'collid', 'lhc', ''], ['parton', 'deconfin', ''], ['', '', '', 'jpsi', 'jpsi', 'auau', 'nucleonnucleon', ''], ['thi', 'parton', 'deconfin', 'parton', ''], ['rhic', 'lhc', '', '', '']]\n",
      "[['we', ''], ['semigroup', '', '', '', '']]\n",
      "[['observ', '', '', '', '', '', 'rm', '', '', '', '', '', '', 'tp296', '', 'rm', 'mev', '', '', '', 'theta', '', 'rm', '', '', 'circ', '', '', ''], ['the', '', 'sigma', '', '', 'circ', '', '', '', '', 'f1', '', 'observ', '', '', 'simeq', '', 'rm', 'mev', '', '', '', '', '', '', '', ''], ['the', 'spinflip', 'unnaturalpar', 'continuum', ''], ['the', '', 'simeq', '', 'rm', '', '', '', '', '', '']]\n",
      "[['the', 'statist', 'random', '', '', 'random', '', '', 'iid', ''], ['', '', '', '', '', ''], ['', 'asymptot', '', '', ''], ['we', '', '', '', '', '', ''], ['the', '', '', '', '', ''], ['admiss', '', '', 'informationtheoret', 'distortionr', ''], ['the', 'nonparametr', 'gaussian', '']]\n",
      "[['we', 'hamiltonian', 'friedmannrobersonwalk', '', 'eo', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['thi', 'hamiltonian', 'without', '', 'friedmann', '', ''], ['', ''], ['', '', '', 'oscil', ''], ['we', ''], ['the', 'hamiltonian', '', 'wheelerdewitt', '']]\n",
      "[['suprathreshold', 'stochast', '', 'ssr', '', 'nonlinear', '', ''], ['stochast', '', 'suprathreshold', 'random', 'arbitrari', ''], ['ssr', ''], ['', 'suffici', 'optim', '', ''], ['', ''], ['jeffrey', '', '', 'via', ''], ['these', 'comput', 'neurosci', 'electron', '']]\n",
      "[['sloan', '', '', 'bgg', '', '', 'toward', 'bgg', '', 'bgg', ''], ['preferenti', ''], ['', '', '07', 'rvir', 'preferenti', 'radial', 'bgg', ''], ['the', '', '', ''], ['', '', '01', 'rvir', '', 'bgg', ''], ['we', 'lens', '']]\n",
      "[['we', '', 'neutrinodriven', 'protoneutron', '', 'pn', '', ''], ['', 'magneticallydriven', 'pn', 'nonrelativist', '', 'multidimension', ''], ['with', 'protomagnetar', '', '', 'timescal', '', 'massload', '', 'longdur', 'gammaray', '']]\n",
      "[['', 'we', 'bd43', '3654', 'ob2', ''], ['', 'we', '', 'msx', 'astrometr', ''], ['', 'our', 'bd43', '3654', 'o4if', '', '', '', '', 'solar', 'myr', ''], ['the', 'msx', 'welldefin', '', ''], ['bd43', '3654', '', 'ob2', ''], ['', 'bd43', '3654', '', 'ob2', ''], ['']]\n",
      "[['we', 'postagb', 'hd56126', '', 'iras071341005', '', ''], ['we', '', 'r25000', '60000', '', 'echel', '6m', ''], ['ion', '', 'c2', '', 'cn', '', 'ch', '', 'interstellar', '', 'dib', '', '4010', '8790', '', ''], [''], ['wellknown', 'halpha', '', 'feii', '', 'yii', '', 'baii', ''], ['we', 'hd56126', 'staralpha', 'per', ''], ['the', 'webaddress', '', '', 'wwwsaoruhqsslatlasatlashtml']]\n",
      "[['we', 'photon', '', '', '', '', '', 'n00n', '', ''], ['for', '', 'onto', '', 'photodetector', ''], ['we', '', ''], ['when', 'photon', '', 'schr', '', '', '', 'dinger', ''], ['we', '', 'subsequ', 'n00n', ''], ['our', 'exponenti', ''], ['metrolog', '']]\n",
      "[['painlev', ''], ['finit', 'manyvalu', 'global', ''], ['the', 'geometri', 'painlev', '', 'riemannhilbert', '', 'geometri', '', 'kleinian', '', 'geometri', ''], ['backlund', '']]\n",
      "[['to', '', 'snia', '', '', '', 'spacetim', 'frw', '', ''], ['', 'we', '', 'unspecifi', 'lagrangian', '', '', '', '', '', ''], ['', 'we', 'retroact', '', '', '', '', '', '', '', '', '', '', '', ''], ['', 'gr', 'frw', '', 'baryon', '', '', '', ''], ['we', '', '', '', 'gr', '']]\n",
      "[['we', 'enabl', 'spatial', 'tempor', ''], ['our', 'nearfield', 'diffus', ''], ['pixelwis', 'coeffici', '', ''], ['to', 'colloid', ''], ['we', '']]\n",
      "[['the', 'circumstellar', 'agb', ''], ['the', 'sio', 'maser', '', ''], ['our', 'sio', 'maser', ''], ['we', '', 'sio', 'maser', 'oxygenrich', ''], ['we', 'milliarcsecond', '', 'interferometri', '', '', '28sio', 'v1', '', 'j10', '29sio', 'v0', 'j10', '', '', '28sio', 'v1', 'j21', '29sio', 'v0', 'j21', '', 'mase', ''], ['we', 'oxygenrich', ''], ['', '', '28sio', 'v2', '', ''], ['', ''], ['we', '29sio', 'v0', 'j10', ''], ['the', 'alreadi', 'maser', '']]\n",
      "[['the', 'neutron', 'helimagnet', 'mnsi', '', '', 'chiral', 'ambient', '', '', '111', '', '', 'nonchir', 'ferromagnet', ''], ['thi', 'unexpect', 'spinwav', ''], ['we', 'spinwav', '', '', '111', '', '', '', '', '', '', '', '', '', '', ''], ['spinwav', 'anisotropi', ''], ['thi', '', 'ferromagnet', '']]\n",
      "[['we', 'timereparametr', ''], ['we', 'without', ''], ['we', 'numer', '', ''], ['we', 'edwardsanderson', 'spinglass', ''], ['', 'supercool', '']]\n",
      "[['chebyshev', '', 'obiu', 'subword', 'poset', '', 'a1', '', '', '', '', '', '', 'bj', '', 'orner', '', 'sagan', '', 'vatter', ''], ['', '510', '']]\n",
      "[['the', 'statist', 'relev', '', '', 'coeffici', ''], ['although', '', 'coeffici', ''], ['we', ''], ['coeffici', '', ''], ['for', '', ''], ['thi', 'statist', 'statist', '']]\n",
      "[['thi', 'finitedimension', 'twodimension', 'micropolar', ''], ['we', '', ''], ['navierstok', '']]\n",
      "[['the', 'rotorrout', 'determinist', 'random', ''], ['determinist', 'dla', ''], ['we', 'asymptot', '', ''], ['for', '', 'nomegad', 'rd', '', '', '', 'omegad', '', '', 'rd', '', '', 'inradiu', '', 'ro', '', '', '', '', 'outradiu', '', 'ro', '', 'ralpha', '', '', '', '', '11d', '', ''], ['for', '', 'divis', '', ''], ['for', 'abelian', '', '', 'npi', 'r2', '', '', 'inradiu', '', 'rsqrt', '', '', '', '', 'outradiu', '', '', 'ro', '', '', '', 'sqrt', '', '', '', ''], ['thi', 'borgn', 'rossin', ''], ['']]\n",
      "[['the', 'quasiperiod', '', 'qpo', '', 'neutron', 'lowmass', 'xray', ''], ['the', 'powerlaw', '', 'nu', '', '', '', 'nu', '', '', '', '', '', '', '', '', 'nu', '', '', 'anu', '', '', '', '', '', '', 'gx', '172', '', 'gx', '3400', '', 'gx', 'sco', 'x1', '', 'atol', '', '4u', '061409', '', '4u', '160852', '', '4u', '163653', '4u', '172834', '', ''], ['the', '', '', '', '', 'powerlaw', ''], ['', 'qpo', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', '2charg', 'd1d5', 'horizonfre', 'nonsingular', 'iib', 'supergrav', 't4', 'k3', 'fuzzbal', '', 'arbitrari', ''], ['the', 'via', 'f1p', 'heterot', 'iib', 't4', 'k3', 't4', '', ''], ['we', 'encod', '', 'vev', 'chiral', 'cohomolog', 't4', 'k3', ''], ['we', 'geometri', 'coeffici', 'supergrav', ''], ['we', 'vev', 'chiral', 'cohomolog', 'vev', 'fuzzbal', '', ''], ['we', 'whether', 'fuzzbal', 'supergrav', '']]\n",
      "[['physicist', 'sinc', '2003', ''], ['how', 'mani', 'mani', ''], ['how', 'mani', ''], ['how', '', ''], ['bilingu', '']]\n",
      "[['the', '', 'gf', '', 'twoband', 'hightc', 'superconduct', 'cuprat', '', 'plakida', 'et', '', 'phi', ''], [''], ['', '', '16599', '', '1995', '', '', 'jetp', '', '', '331', '', '2003', '', '', '', '', 'algebra', ''], ['we', '', '', 'algebra', ''], ['the', '', '', '', 'gmfa', '', '', 'gf', '', ''], ['for', 'anomal', 'gmfagf', '', 'exponenti', ''], ['gmfagf', '']]\n",
      "[['we', 'nanocontact', ''], ['', 'geometri', ''], ['we', '3pz', '', ''], ['toward', '', 'instabl', 'ferromagnet', ''], ['', 'nanocontact', ''], ['we', '']]\n",
      "[['the', 'currentvoltag', '', '', '', '', '', '', '', 'polycrystallin', '', '', '', '185', '', '', '', '', '', '015', '', '', 'cuo', '', '', '', '', '', '', '075', '', '', '', '', '', '025', '', '', '', '', '', '', '', '', '', '7delta', '', '', '', '', '', '', '', '', '', '', '', '03', '', '', '', '', '', '', '', '', '', '', '', '', '', 'yba', '', '', '', '', '', '', '', '7delta', '', '', '', ''], ['the', '', '', '', '', '', 'superconductornormalmetalsuperconductor', ''], ['the', '', '', '', '', '', '', '', '', '', '', ''], ['the', '', '', '', '', '', '', '', '', 'mmel', '', 'gunsenheim', '', 'nicolski', 'andreev', '']]\n",
      "[['photon', ''], ['', 'arbitrari', '', ''], ['the', 'circularli', 'integr', ''], ['the', 'asymptot', 'linearli', ''], ['', '']]\n",
      "[['firstprincipl', 'groupvb', '', 'megabar', ''], ['bcc', '', '', '', '', '', 'angle1105', '', '', '', '', '', '', '', 'angle1085', '', '', '', '', '', '430', '', 'bcc', 'we', 'bccv', 'vibrat', '112', ''], ['']]\n",
      "[['we', 'cp', 'froggatt', '', '', 'fn', '', ''], ['to', '', 'nonrenormaliz', 'fermion', ''], ['isosinglet', 'cp', ''], ['', 'cabibbokobayashimaskawa', '', 'ckm', '', 'cp', 'ckm', '', '', '', 'rre', '', '', '', '', '', ''], ['phii', '', 'i1', '', '', 'unitar', 'ckm', 'offdiagon', '', 'ub', '', '', '', 'cb', '', '', '', '', '', '', ''], ['although', 'cp', '', 'would', 'cp', '']]\n",
      "[['we', '', '', ''], ['the', '', 'finit', 'mani', '', '', '', '', '', 'dgeq', '', ''], ['', '', '', '', '', '', '', ''], ['neishtadt', 'anosov', ''], ['when', '', 'd1', '', '', '', '', 'mathcal', '', '', '', '', '', '', '', '', '', '', '', ''], ['the', ''], ['we', ''], ['the', 'uniformli', '', ''], ['', '', '', '', 'n1', '', ''], ['we', ''], ['', 'anosov', 'dolgopyat', '']]\n",
      "[['the', 'norbornan', '', '', '873', '973', '', '', '004', '226', '', ''], ['chromatographi', '', 'amongst', '', '13cyclopentadien', ''], ['norbornan', '', ''], ['', 'unimolecular', 'scission', 'norbornan', '', 'dirad', '', 'norbornyl', '', 'crosscoupl', '']]\n",
      "[['thi', 'unimolecular', 'cyclobutan', '', 'cyclopentan', 'cyclohexan', ''], ['birad', 'cycloalkan', '', 'birad', 'cbsqb3', ''], ['thermochem', '', 'h0f', '', 's0', '', 'c0p', '', 'isodesm', ''], ['the', ''], ['energet', 'birad', ''], ['600', '2000', ''], [''], ['rotat', 'conform', '', '', 'birad', ''], ['', 'rse', '', 'rse', 'reactant', 'upon', '']]\n",
      "[['solidst', '', 'diodepump', 'ytterbiumdop', ''], ['applic', 'solidst', ''], ['our', '', 'overview', '', 'stateoftheart', 'scientist', ''], ['ybdope', '', 'ybdope', '', ''], ['thi', 'lens', '', '', ''], ['we', '', 'thermoopt', 'coeffici', '', 'lens', 'dndt', 'relev', ''], ['stateoftheart', 'lens', ''], ['', '', 'ybdope', '', '']]\n",
      "[['conduct', 'nanowir', 'nonequilibrium', '', 'negf', '', ''], ['our', 'conduct', 'nanowir', 'onedimension', 'threedimension', ''], ['the', 'conduct', 'deby', ''], ['the', 'conduct', 'nanowir', ''], ['we', 'interfaci', 'conduct', 'nanowir', '']]\n",
      "[['we', 'nearfield', 'diffract', 'subwavelength', ''], ['the', 'diffract', 'geometri', ''], ['diffract', 'dipolar', ''], ['', 'asymptot', 'plasmon', 'polariton', '', 'spp', '', 'nearzon', ''], ['the', '', '', 'nearzon', '', ''], ['', 'diffract', 'evanesc', 'asymptot', 'spp', 'nearzon', ''], ['semianalyt', 'photon', 'whose', '']]\n",
      "[['we', 'random', 'hamiltonian', ''], ['quasiinvari', 'diffeomorph', ''], ['the', '', '', 'dirichlet', ''], ['the', 'malliavin', 'brownian', 'homeomorph', ''], ['the', 'stochast', '', 'whose', 'wasserstein', ''], ['wasserstein', '']]\n",
      "[['the', 'firstord', 'eikon', '', '', '', '', '', '', ''], ['glauber', '', '', 'typic', 'firstord', 'eikon', ''], ['we', 'eikon', '', '', '', '', '', '', 'secondord', 'eikon', ''], ['the', 'eikon', ''], ['the', 'secondord', 'eikon', '', '', '', '', 'approx', '02', '', '', 'gevc', '', '', '', ''], ['the', 'observ', '', 'leftright', '', ''], ['', '', 'secondord', 'eikon', 'andor', 'partialwav', '']]\n",
      "[['we', 'serendipit', 'infraredbright', 'supernova', '', 'snr', '', 'b0104723', 'magellan', '', 'irc', '', 'onboard', 'akari', ''], ['', 'irc', '2615', 'um', ''], ['the', '', '', 'xray', 'snr', 'radi', 'snr', ''], ['thi', 'snr', 'nearmidinfrar', 'magellan', ''], ['the', 'irc', 'h2', ''], ['we', 'b0104723', 'middleag', 'snr', 'interact', '', 'snr', '443', ''], ['our', 'akari', 'irc', 'snr', '', 'snr', '']]\n",
      "[['mani', 'polym', 'cellulos', ''], ['floryhuggin', 'polym', ''], ['', 'blocki', ''], ['blocki', '', 'coexist', 'polymerpolym', 'demix', ''], ['polym', '', '']]\n",
      "[['thi', 'emph', '', 'priori', '', '', '', '', '', ''], ['thi', '', '', 'mani', ''], ['', '', ''], ['thi', '', '', '', '', 'partialomega', '', '', 'geometri', '', '', ''], ['we', 'illpos', 'minim', '']]\n",
      "[['we', '', ''], ['hamiltonian', '', '', '', '', '', '', 'i1', '', '', 'theta', '', 'phi', '', '', '', '', 'phiomega', '', 'timedepend', '', 'theta', '', 'timeindepend', ''], ['thi', '']]\n",
      "[['crosssect', 'photoproduct', 'proton', 'proton', 'pi0', 'proton', 'cbelsa', '', 'elsa', 'bonn', ''], ['the', 'photon', '3gev', '']]\n",
      "[['we', 'twopion', 'threenucleon', '', 'tpe3np', '', 'chiral', 'q4', '', 'subset', '', 'q3', '', ''], ['coeffici', '', 'q3', '', ''], ['the', 'typic', '', 'wherea', 'either', 'nonloc', ''], ['the', 'tpe3np', 'threebodi', 'observ', '', 'perturb', '']]\n",
      "[['we', 'angleresolv', 'abovethreshold', 'diatom', 'linearli', '', 'strongfield', ''], ['the', '', 'internuclear', ''], ['we', '', '', 'rescatt', 'singlecent', ''], ['', 'rescatt', '', ''], ['', 'internuclear', '']]\n",
      "[['the', 's12', 't0', 'inequ', '', 'lieb', 'shastri', 'carlo', '']]\n",
      "[['we', '', '', '', '', '', '', '', '', 'infti', '', '', '', 'ricci', ''], ['among', '', '', '', '', '', '', '', 'symplect', '4manifold', '', 'b2', '', '', '', '', '', '', '', '', '', '', 'infti', '', '', '', '', '', '', '', 'whose', 'ricci', '', '', 'ric', '', '', '', '', '', 'leq', '', '', '', '', 'tau', '', '', '', '', '', '', 'mathbb', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'j1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'stackrel', '', '', 'gh', '', '', 'longrightarrow', '', 'coprod', '', 'j1', '', '', '', 'infti', '', '', '', '', 'infti', '', '', '', '', '', '', '', 'infti', '', '', '', '', '', '', '', '', 'infti', '', '', '', '', '', 'gromovhausdorff', '', '', '', 'longrightarrow', 'infti', '', '', '', '', '', '', '', '', 'infti', '', '', '', '', '', 'j1', '', '', '', '', '', 'orbifold', 'finit', 'mani', 'orbifold', ''], ['', '', '', 'infti', '', '', 'nonsingular', '', 'coprod1m', '', '', '', '', '', 'vol', '', '', '', '', '', '', '', '', '', 'j1', '', '', '', '', '', 'vol', '', '', '', '', 'infti', '', '', '', '', '', '', '', '', '', '', '', '', '', 'resp', ''], ['', 'tau', '', '', '', '', '', 'resp', ''], ['', '', '', '']]\n",
      "[['the', 'twodimension', 'dimer', '', ''], ['', '', 'valencebond', 'superfluid', '', 'wherea', '', 'superfluid', 'rvb', ''], ['aharonovbohm', '', 'superfluid', 'halfflux', '', 'q2e', '']]\n",
      "[['we', 'asymptot', '', ''], ['', '', '', ''], ['we', '', 'therebi', ''], ['to', '', '']]\n",
      "[['we', 'onedimension', 'bondcharg', 'halffil', ''], ['for', ''], ['for', 'spindens', 'alreadi', ''], ['', 'dimer', 'bondord', 'incommensur', 'superconductor', '']]\n",
      "[['the', 'neutrino', 'astrophys', '', 'neutrino', ''], ['', 'sinc', 'suffici', 'neutrino', 'neutrino', ''], ['critic', 'astrophys', '', '']]\n",
      "[['we', ''], [''], ['', 'sometim', '', 'socal', '', '', '', ''], ['to', '', ''], ['we', ''], ['the', 'either', ''], ['thi', 'via', '']]\n",
      "[['we', 'lohner', 'arbitrari', ''], ['pendulum', '']]\n",
      "[['rossi', 'xray', '', 'rxte', '', '', 'psd', '', 'ngc', '3783', '', 'xray', '', 'gbh', '', '', '', ''], ['the', '', '', ''], ['the', 'ngc', '3783', '', '', '', 'agn', '', '', 'psd', 'gbh', 'cyg', 'x1', '', 'agn', '', '', '', '', '', '', '', '', ''], ['if', 'ngc', '3783', '', '', 'psd', '', 'would', 'would', 'agn', 'gbh', ''], ['xray', 'psd', 'ngc', '3783', '', '', '', '', '', '', '', '', 'rxte', 'xmmnewton', ''], ['we', 'psd', '', '', '', '', '', ''], ['although', '', '', '', ''], ['ngc', '3783', ''], ['these', 'arakelian', '564', 'agn', '', 'although', '', '', '', '', '', 'psd', ''], ['the', 'ngc', '3783', 'agn', 'gbh', '', '']]\n",
      "[['the', 'gluon', 'ghostgluon', 'threegluon', 'twodimension', 'su', '', '', 'yangmil', '', '', ''], ['qualit', ''], ['the', 'faddeevpopov', 'gribovzwanzig', ''], ['', ''], ['the', '', 'stochast', 'dysonschwing', '', 'quantit', ''], ['for', '', '427', '', '']]\n",
      "[['nonequilibrium', '', 'electronphonon', 'onedimension', 'electronphonon', ''], ['thi', 'enabl', 'phonon', ''], ['we', 'electronphonon', ''], ['', 'selfconsist', '', ''], ['we', 'phonon', '']]\n",
      "[['we', 'spinorbit', 'aharonovbohm', '', '', 'magnetoresist', 'antidot', '', 'adl', '', 'twodimension', ''], ['abtyp', 'commensur', '', 'spinorbit', ''], ['spinorbit', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['when', ''], ['', 'padgett', 'et', ''], ['2006', '', ''], ['we', '', '1976', '', 'electromagnet', ''], ['we', ''], ['we', '']]\n",
      "[['we', 'stochast', ''], ['multifract', 'deterend', '', 'mfdfa', '', '', ''], ['', '', '', '1718', '', ''], ['mfdfa', 'multifract', 'longrang', ''], [''], ['we', 'multifract', 'longrang', '']]\n",
      "[['we', 'electrodynam', 'superconduct', 'fluxqubit', 'highq', 'coplanar', ''], [''], ['metrolog', '', 'photon', 'nondemolit', '']]\n",
      "[['the', 'nonequilibrium', '', 'zba', '', ''], ['outofequilibrium', ''], ['the', 'zba', 'inelast', '']]\n",
      "[['we', 'thermodynam', 'kaluzaklein', '', ''], ['these', '', 'nonrot', ''], ['we', 'spacetim', '', 'adm', ''], ['for', '', '', 'adm', ''], ['we', 'smarr', '', '', ''], ['', '', '', 'traschen', 'gibbsduhem', '', 'nonrot', '']]\n",
      "[['the', ''], [''], ['the', 'determinist', 'perinterfac', '', ''], ['though', '', '', 'other', ''], ['', ''], ['the', ''], ['to', ''], ['', 'netflow', '', '']]\n",
      "[['we', 'j2', 'skyrm', ''], ['skyrm', '', 'zerorang', ''], ['we', 'parameter', '', 'isoscalar', 'isovector', '', 'success', 'parameter', ''], ['we', 'observ', 'meanfield', '', 'spinorbit', 'split', 'singleparticl', 'doublymag', '', 'spinorbit', 'split', 'semimag', '', '', ''], ['our', 'spinorbit', 'skyrm', '']]\n",
      "[['we', 'belinskykhalatnikovlifshitzlik', '', '', 'elevendimension', 'supergrav', '', '', 'kacmoodi', 'algebra', '', '', ''], ['thi', '', '', 'supergrav', '', 'mtheori', '', 'infinitedimension', 'coset', '', '', '', '', ''], ['if', '', 'gravitycoset', 'would', '', '', '', '', '']]\n",
      "[['toroid', 'timedepend', ''], ['', 'stochast', '', 'kapitza', 'pendulum', '']]\n",
      "[['we', 'asca', '', '1994', '', '1995', '', '1996', '', '1997', '', 'xmmnewton', '', '2005', '', '', 'highsoft', ''], ['we', 'continuum', 'kerrbb', '', '', 'fcol', ''], ['if', 'kerrbb', '', 'fcol', '', '', 'fcol', '']]\n",
      "[['', 'we', '', 'sed', '', 'xraytoopt', '', 'fxfr', '', '', '', '09', '', 'kev', 'hellas2xmm', ''], ['', 'we', 'irac', '', 'ksband', 'photometri', '', 'sed', ''], ['the', 'sed', '', 'phenomenolog', 'et', ''], ['2004', '', '', 'pointlik', '', 'sed', ''], ['the', 'bolometr', 'mbhlk', 'agn', ''], ['', 'irac', '', '', ''], ['the', 'sed', 'midinfrar', ''], ['the', 'bolometr', '10451047', 'erg', 's1', '', '', 'kev', 'bolometr', '', 'et', ''], ['', '1994', '', ''], ['for', 'ellipticallik', '', '', '0862', '', 'x1011', '', '', '0225', '', 'x109', '', 'lledd', '', '01', '', 'lowaccret', '']]\n",
      "[['', '', '', '', 'adic', 'multiresolut', '', 'mra', '', '', ''], ['we', '', '', 'whose', '', 'refin', '', ''], ['thi', '', '', '', '', '', '', ''], ['the', '', 'p2', '', ''], ['our', 'mra', '2adic', 'haar', 'mra', ''], ['', 'refin', 'haar', 'mra', '', 'refin', ''], ['thi', 'mani', '2adic', 'orthonorm', '', '', '', '', 'bq2', '', '', 'haar', 'mra', ''], [''], ['sinc', '', '', 'adic', 'pseudodifferenti', 'wavelettyp', '', 'intens', '']]\n",
      "[['we', 'phenomenolog', 'success', 'hepth0502058', ''], ['', 'whether', 'dbrane', 'oplan', ''], ['noscal', 'treelevel', '', ''], ['we', 'supersymmetri', '', 'sublead', ''], ['we', 'largevolum', 'toroid', 'orientifold', 'fiber', 'calabiyau', '', '']]\n",
      "[['undergo', ''], ['our', '', 'though', 'nonequilibrium', ''], ['thi', '', '', '', 'fluctuationdissip', ''], ['thi', '']]\n",
      "[['we', 'lehmann', '']]\n",
      "[['we', '', 'mond', '', '', ''], ['we', '', 'baryon', 'mond', '', '', 'kinemat', 'twointegr', ''], ['we', 'deepmond', ''], ['', 'highsurfac', '', 'mond', '']]\n",
      "[['we', '', 'deltasigmamathrm', '', '', '', 'electronelectron', '', 'altshuleraronov', '', ''], ['the', ''], ['the', ''], ['the', '', 'deltasigmamathrm', '', '', '', 'lt', '', '', '', 'lt', '', '', 'deltasigmamathrm', '', 'wl', '', '', 'lphi', '', '', ''], ['our', '', 'deltasigmamathrm', '', '', '', '1d', '', '', 'deltasigmamathrm', '', '', '', '1d', ''], ['', 'logarithm', 'alreadi', '', 'ltsim', '', '', '', '', '', '', '']]\n",
      "[['we', ''], ['we', 'nonloc', 'drastic', 'magnetoconduct', ''], ['geometri', '', ''], ['decoher', 'electronelectron', 'geometri', '']]\n",
      "[['we', 'diatom', '', ''], ['the', 'lowtemperatur', 'rejecramsak', 'variat', 'edabi', '', 'initio', ''], ['the', '', 'singleparticl', 'renorm', 'entanglementswitch', ''], ['we', 'kondo', '']]\n",
      "[['the', '', '', '', ''], ['', ''], ['our', '', 'selfoptimis', ''], ['we', '', '', '', '', ''], ['our', 'scientist', ''], ['we', 'dynam', '', 'adapt', ''], ['the', '', ''], ['we', ''], ['these', '']]\n",
      "[['we', 'malliavinthalmaierwatanab', 'stochast', '', 'sde', '', ''], ['', 'coeffici', ''], ['the', 'libor', 'stochast', 'stochast', ''], ['sde', '', ''], ['', '', '', 'libor', '', ''], ['']]\n",
      "[['we', 'statist', 'machzehnd', 'interferomet', ''], ['the', 'gaussian', 'whose', ''], ['to', 'statist', '', ''], ['', ''], ['', 'gaussian', '']]\n",
      "[['firstord', '', '', 'bf', '', '']]\n",
      "[['we', ''], ['we', '', 'pvla', 'bfrt', ''], ['our', 'photonnois', 'homodyn', 'interferomet', '2x108', '', '', 'mw', '', '', '']]\n",
      "[['we', '', '', '', 'neutron', '', ''], ['pulsar', 'strongfield', 'andor', 'radi', '', '']]\n",
      "[['meaning', 'higherord', '', '', '', '', '', 'n34', '', '', '', 'nontrivi', '']]\n",
      "[['we', 'kobayashi', 'hyperbol', 'antipeak', '', '', '']]\n",
      "[['', 'worldsheet', ''], ['for', 'poincar', '', ''], ['', '', 'arbitrari', 'twodimension', '', ''], ['enabl', 'weyl', '']]\n",
      "[['bianchi', 'barotrop', 'lateli', 'stachel', '', ''], ['to', 'determinist', '', 'barotrop', ''], ['the', 'xaxi', ''], ['the', '']]\n",
      "[['conceptu', '', '', '', '', '', '', 'postnewtonian', 'weakfield', 'solar', '', '', '', '', '', '', 'strongfield', 'radi', 'pulsar', '', '', '', '', '', '', '']]\n",
      "[['we', 'kth', 'martix', ''], ['the', '', '', '']]\n",
      "[['braneworld', 'brane', 'higherdimension', 'spacetim', ''], ['photon', '', 'brane', 'graviton', ''], ['we', '', '', 'kaluzaklein', '', 'kk', '', 'braneworld', ''], ['we', 'massless', 'kk', 'graviton', 'brane', 'fivedimension', ''], ['we', 'graviton', 'relev', ''], ['thi', '', 'mruser', 'durrer', '', 'phi', ''], [''], ['', '104014', '', '2007', '', '', 'arxiv07040790', '']]\n",
      "[['the', ''], ['we', ''], ['inequ', '', ''], ['the', ''], ['these', '']]\n",
      "[['subsystem', '', ''], ['subsystem', ''], ['', 'conceptu', ''], ['', '', '', '', 'a1a2', 'b1b2', '', 'a1', 'b1', '', '', 'bellstat', '', '', 'bsm', '', 'a2', 'b2', 'onto', '', 'although', 'interact', '', '', ''], ['photon', 'parametr', 'downconvers', '', 'spdc', '', 'alreadi', '', '', '', '', 'cw', '', '', '', '', ''], ['the', 'suffici', 'photon', 'bsm', ''], ['narrowband', '', 'photon', 'undergo', 'bsm', '', ''], ['cw', '', '', '', '', ''], ['our', 'photon', '', 'photon', 'spdc', 'nonlinear', '', '', '', 'narrowband', ''], ['thi', '', 'timebin', 'photon', '', '', ''], ['our', 'cmlong', '']]\n",
      "[['incompress', '', '', 'fraction', '', ''], ['', '', '', '', '', '', '', 'nn', '', '', '', ''], ['we', ''], ['we', 'littlewoodpaley', ''], ['thi', 'helic', '', '', '', '', '', '', '', '', '', 'nn', '', '', '', 'helic', ''], ['', '', 'enstrophi', '']]\n",
      "[['we', '', 'longliv', 'photon', 'hadron', 'collid', ''], ['we', 'photonjetmiss', 'ppbar', 'sqrt', '', '', '196', 'tev', 'cdf', ''], ['photon', ''], ['570', 'pb1', '', '', '1307', ''], ['modelspecif', '', 'supersymmetr', 'tild', '', '', '', 'gammagravitino', 'worldbest', '', ''], ['tild', '', '', 'gevc2', 'tau', '', 'tild', '', '', '', '', '']]\n",
      "[['statist', 'routin', 'singlemolecul', 'nonequilibrium', ''], ['dwdtpartial', '', '', '', '', 'timedepend', 'hamiltonian', '', '', '', '', '', ''], ['we', 'singlemolecul', '']]\n",
      "[['the', '', '', 'selfavoid', '', '', 'interact', ''], ['we', '', 'sotero', 'whittington', '', 'phi', ''], ['', ''], ['gen', '2004', '', '', 'r279r325', '', '', 'carlo', ''], ['we', ''], ['toward', 'polym', '']]\n",
      "[['we', 'twolevel', 'electromagnet', ''], ['the', '', 'photon', '', ''], ['we', 'quasiperiod', ''], [''], ['coher', '', ''], ['the', '']]\n",
      "[['onedimension', 'ferromagnet', 'lanczo', 'renorm', ''], ['the', 'spindensitywav', 'nematiclik', 'upon', ''], ['the', 'spinflip', '', 'finites', '']]\n",
      "[['oxid', 'superconduct', 'disordertun', 'superconductorinsul', ''], ['although', '', ''], ['the', 'superconduct', 'spatial', 'inhomogen', '']]\n",
      "[['we', 'nonloc', 'brogliebohm', ''], ['', 'nonloc', '', '', 'wavefunct', '', '', '', 'inequ', '', 'without', 'ineffici', ''], ['we', 'twoparticl', 'wavefunct', 'ultrarelativist', '', '', '', 'alic', '', '', '', 'therebi', '2particl', 'brogliebohm', ''], ['we', 'sterngerlach', 'epr', '', 'nearlumin', '']]\n",
      "[['microlens', 'extrasolar', 'alreadi', 'exoplanet', ''], ['these', '', 'snowlin', '', 'neptunemass', ''], ['microlens', '', 'snowlin', '', 'lowmass', '', ''], ['', '', 'lowmass', '', 'freefloat', '', ''], ['', 'extrasolar', 'wellfund', 'microlens', ''], ['when', '', 'microlens', '', 'lowmass', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ngc', '7679', 'sy2', 'starburst', 'agn', ''], ['the', 'agn', 'powerlaw', 'continuum', 'starburst', ''], ['the', 'xray', 'xray', '', '1020', '', '', ''], ['the', 'comptonthin', 'unabsorb', 'syg', 'applic', ''], ['the', 'circumnuclear', 'ngc', '7679', 'sy1', '', '', '', '5007', 'agn', ''], ['the', '', '', '5007', 'ngc', '7679', 'isophot', '', 'deg', 'ngc', '7682', ''], ['the', 'agn', 'powerlaw', 'continuum', '', '', '5007halpha', '', ''], ['we', 'agn', ''], ['thi', 'duststarform', ''], ['unabsorb', 'comptonthin', 'sy2', '', '', '', '1041', 'erg', '', '', 'agn', '', '', '']]\n",
      "[['we', 'unpolar', 'fermion', 'temperatureth', 'interact', 'via', '', 'tunabl', '', ''], ['we', 'analyt', 'unitar', ''], ['', '', '', '', 'feshbach', '', '', '', 'mu', '', '', '', '', ''], ['', '', 'mu', '', '', '', '', '', 'twobodi', '', '', '', '', 'n3', '', '4pi', 'rs3', '', '', ''], ['the', '']]\n",
      "[[''], ['', '', 'intraclust', ''], ['these', 'nucleosynthesi', '']]\n",
      "[['we', 'onequbit', '1falpha', '', '', '', ''], ['we', 'multist', 'markovian', 'fluctuat', ''], ['with', '', 'qubit', '1falpha', 'determinist', ''], ['we', 'qubit', '', ''], ['for', '', 'qualit', 'random', ''], ['', 'nonmonoton', '', '']]\n",
      "[['we', 'twodimension', 'incompress', 'navierstok', ''], ['we', ''], ['the', 'piecewis', '', 'coloc', '', ''], ['we', '', 'fractionalstep', '', 'incompress', ''], ['we', 'navierstok', ''], ['', 'infsup', '', 'babuskabrezzi', '', ''], ['we', '']]\n",
      "[['to', '', 'crosscorrel', '', 'nse', '', ''], ['we', '', '', '', ''], ['thi', ''], ['', '', 'eg', '', '', ''], ['thi', 'explicitli', 'interact', ''], ['nse', '', 'random', '', '', 'eg', '', ''], ['we', 'intrasector', '', '', 'twofactor', ''], ['our', '']]\n",
      "[['we', 'a901902', 'superclust', 'combo17', ''], ['570', '0155', '', 'zphot', '', '0185', 'visual', 'mv18', ''], ['these', '', '', 'lens', '', ''], ['', '', 'sigma10', 'mpc2', '', '', '', 'morphologydens', ''], ['', ''], ['thi', ''], ['the', 'latetyp', 'earlytyp', ''], ['17band', 'photometri', 'combo17', '', 'superclust', 'et', ''], ['', '2005', '', ''], ['we', 'starform', 'latetyp', 'earlytyp', '', 's0', '', '', 'ellipt', 'infal', '']]\n",
      "[['', 'geq', '', ''], ['emph', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', 'potent', '', '', 'abelian', '', 'k0n', '', '', '', ''], ['if', '', '', 'algebra', '', '', 'k0n', '', '', 'cong', 'bigl', '', 'k0', '', '', 'bigr', '', '', '', 'n1', '', '', '', 'geq', '', ''], ['', 'algebra', 'cyclotom', '', ''], ['we', '', 'k0n', '', 'covari', 'functor', '', 'functori', 'emph', '', '', '', '', '']]\n",
      "[['we', 'interact', ''], ['', 'tworow', '', '', 'whose', 'nextnearest', 'fourparticl', ''], ['the', 'unpolar', '', 'antiferromagnet', 'dimer', 'fourparticl', '']]\n",
      "[['we', 'perturb', 'supergrav', 'superstr', 'compactifi', '', '', '', ''], ['for', '', '', 'finitemass', '256', 'massless', 'supergrav', ''], ['', '', 'massless', 'finitemass', ''], ['these', 'kaluza', '', '', '', 'kaluza', '', 'monopol', 'brane', 'toroid', ''], ['we', 'perturb', 'supergrav', '', ''], ['', '', 'supergrav', '']]\n",
      "[['', '', 'equivari', 'reduct', '', '', 'algebra', '', '', ''], ['', '', 'borel', '', '', ''], ['', '', '', '', 'subvarieti', '', 'diag', '', '', 'cdot', '', '', '', '', '', '', '', '', ''], ['', '', 'compactif', 'adjoint', '', '', '', 'lusztig', '', '', ''], ['we', '', '', 'frobeniu', '', '', ''], ['', '', '', '', 'project', 'toroid', '', '', '', '', '', 'frobeniu', ''], ['although', '', '', 'nonnorm', '', '', 'compactif', '', 'g2', '', ''], ['frobeniu', '', 'mathcal', '', '']]\n",
      "[['with', 'glast', '', 'xray', '', 'tev', '', 'blazar', ''], ['we', '', 'synchrotronself', ''], ['we', 'toward', 'multi', 'nonloc', '', 'synchrotronself', ''], ['', '', '', ''], ['', '', '', 'tev', 'xray', '']]\n",
      "[['radioact', '', '', '', '132', '', '', '', '', '', '', '', ''], ['subbarri', ''], ['coupledchannel', 'inelast', '', 'neutron', ''], ['when', '', '', '', '', '132', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '112124', '', '', '', '', '', '132', '', '', '', '', '', '', '', '']]\n",
      "[['we', 'comput', 'trilay', 'superlattic', 'ferroelectr', 'magnetoelectr', 'multiferro', ''], ['we', 'superlattic', 'trilay', 'conventionalferroelectr', '', 'switchabl', 'ferroelectr', ''], ['', 'epitaxi', '', '', '', 'switchabl', 'coexist', '', 'ferroelectr', 'ion', '']]\n",
      "[['', 'schwarzschild', ''], ['', '', ''], ['for', '', '', 'therebi', ''], ['these', 'firstord', ''], ['constraintpreserv', '', ''], ['', 'sommerfeld', '', 'constraintpreserv', 'kreiss', 'winicour', ''], ['', 'compactif', '', ''], ['', 'newmanpenros', 'psi0', '', '']]\n",
      "[['we', 'twodimension', 'incompress', 'navierstok', ''], ['we', ''], ['the', 'piecewis', ''], ['we', 'incompress', ''], ['we', 'navierstok', ''], ['infsup', '', 'babuskabrezzi', '', ''], ['']]\n",
      "[['we', 'instanton', 'superpotenti', 'd3brane', 'z3orientifold', ''], ['instanton', '', '', 'brane', 'affleck', '', 'seiberg', '', '', 'superpotenti', 'n1', 'bifundament', 'antisymmetr', ''], ['instanton', 'ed3bran', 'fourcycl', 't6z3', ''], ['they', 'nonrenormaliz', 'superpotenti', ''], ['superpotenti', 'n1', 'adjoint', '', '', 'antisymmetr', 'chiral', '']]\n",
      "[['diamondlik', '', 'dlc', '', 'tribolog', '', 'ultrahigh', '', 'uhv', '', '', 'either', 'coeffici', '001', '', 'coeffici', '', '', '04', '', 'drastic', ''], ['these', 'notabl', 'gaseou', '', '', '', '', 'viscoplast', '', '', ''], ['superlow', 'uhv', 'viscoplast', '', 'fluorin', '', '', '', '', ''], ['', 'nanoindent', 'nanoscratch', 'ambient', '', 'nanoindent', '', 'tribolog', '', 'viscoplast', '']]\n",
      "[['both', 'babar', 'bell', 'nonzero', '', 'd0', '', '', '', 'd0', '', ''], ['although', 'cpviolat', '', '', '', '', '', '', 'ysim', 'deltagamma', '', 'alreadi', 'cpviolat', '', '', '', '', '', 'would', '']]\n",
      "[['we', 'twodimension', 'incompress', 'navierstok', ''], ['we', ''], ['the', 'piecewis', ''], ['we', 'incompress', ''], ['', ''], ['we', '']]\n",
      "[['', '', '', '', '', '', '', '', '', ''], ['we', ''], ['we', '', '', ''], ['we', ''], ['we', 'twoalgorithm', 'whose', ''], ['for', 'twoalgorithm', '', 'maximumlikelihood', '']]\n",
      "[['we', '1200', 'spectroscopicallyselect', 'sloan', ''], ['we', ''], ['', '', 'mani', '', ''], ['the', '', '', 'would', '', 'bwd', '', '', 'intermediatepolar', ''], ['definit', ''], ['', '', 'dispar', '']]\n",
      "[['we', 'twobran', 'fivedimension', 'antid', 'spacetim', ''], ['we', 'brane', 'brane', '', '', '', '', ''], ['the', 'graviton', ''], ['we', 'massless', 'graviton', 'nucleosynthesi', ''], ['we', 'kaluzaklein', 'antidesitt', 'braneworld', ''], ['', '', 'backreact', 'kaluzaklein', 'graviton', ''], ['the', '', 'durrer', 'ruser', '', 'phi', ''], [''], ['lett', ''], ['', '071601', '', '2007', '', '', 'arxiv07040756', '', '']]\n",
      "[['we', 'energet', 'longdur', 'gammaray', '', 'grb', '', '', ''], ['', '15150', 'kev', '', 'swiftbat', '', ''], ['among', '', ''], ['we', '', 'pl', '', '', '', '', 'cpl', '', '', 'timeintegr', '', '', '', 'among', ''], ['the', 'cpl', 'nufnu', 'epk', ''], ['for', 'grb', '', 'fluenc', 'isotropicequival', '', 'eiso', '', 'among', ''], ['we', 'grb', 'restfram', 'epk', 'eiso', ''], ['we', '', '', '', '', '', '', ''], ['we', '', '', '', 'nonswift', 'grb', '']]\n",
      "[['we', 'kennicuttschmidt', '', '', '', '', ''], ['we', '', '', 'starform', ''], ['', ''], ['whose', '', 'superlinearli', ''], ['we', 'isotherm', 'quantit', '', '', '', 'hcn', '', '', '', '', ''], ['we', 'irlin', ''], ['thi', 'hco', '', '', '', '', 'hcn', '', '', '', 'intens', 'starform', ''], ['et', ''], [''], ['we', 'hcn', '', '', '', '']]\n",
      "[['with', 'masslik', 'misnersharp', '', 'thermodynam', '', 'detadsa', '', 'friedmann', '', '', 'lovelock', '', 'nonlinear', '', 'scalartensor', ''], ['thi', 'thermodynam', 'friedmann', '', '']]\n",
      "[['although', 'rocketbas', 'xray', 'calorimetri', '', 'xqc', '', 'xray', '', 'calorimet', '', '', 'lowthreshold', 'among', ''], ['we', 'carlo', 'xqc', 'spinindepend', '', 'upon', ''], ['we', 'xqc', 'nucleonscatt', '001', 'gev', ''], ['our', 'interact', '']]\n",
      "[['we', 'semilepton', 'heavylight', 'pseudoscalar', 'chiral', '', 'schpt', '', '', '', '1mq', '', '', '', 'mq', '', ''], ['we', 'pseudoscalar', 'chiral', ''], ['the', '', '', 'schpt', ''], ['our', 'continuum', 'chiral', 'becirev', '', 'prelovsek', 'zupan', '', '', 'nondegener', '', ''], ['', 'continuum', 'nondegener', ''], ['we', 'nonlead', 'chiral', '', 'among', 'coeffici', ''], ['our', '', 'btopi', '', '', 'dto', '', '']]\n",
      "[['we', '', ''], ['for', '', '', ''], ['for', 'interact', '', ''], [''], ['the', 'idempot', '', '', '', '', '', '', 'n1', '', ''], ['', 'ito', 'stochast', 'schr', '', 'oding', ''], ['', 'collision', 'brownian', 'brownian', '', 'bornmarkov', ''], ['', 'caldeira', '', 'leggett', ''], ['', 'stochast', 'schr', '', 'oding', '', '']]\n",
      "[['we', 'selfforc', 'schwarzschild', ''], ['thi', '', 'numer', 'fourthord', 'converg', 'finitediffer', ''], ['the', '', '', 'modebymod', 'via', 'modesum', 'barack', 'ori', ''], ['thi', '', '', '', 'zoomwhirl', '', '']]\n",
      "[['2002', '', 'bruner', 'tmf', 'nonimmers', 'project', ''], ['', 'completecorrect', ''], ['the', 'nonimmers', 'nonimmers', 'rpn', '', 'n1536', ''], [''], ['', '2002', ''], ['', '', '', 'x1x2', ''], ['we', ''], ['', '', 'nonimmers', ''], ['', 'tmf', '', '', '', '', 'rpinftytim', 'rpinfti', '', 'tmf', '', '', 'cpinftytim', 'cpinfti', '', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'nonlinear', 'rmode', 'xray', '', 'lmxb', '', 'parametr', ''], ['we', 'numer', ''], ['we', 'quasistationari', ''], ['', 'algebra', '', ''], ['', 'either', '', '', 'undergo', '', '', '', '', 'toward', '', '', '', 'thermogravit', 'timescal', '', '106', '', ''], ['', '', 'timescal', '', ''], ['the', '', 'hyperon', ''], ['we', 'hyperon', 'superfluid', '', 'urca', '', '', ''], ['for', 'rmode', '', 'sim', '', '', '', ''], ['the', '', 'nu', '', '', 'sim', '800', '', '', '', '', '', '', '', 'r6', '', '', '', '', '411', '', 't8', '', '211', '', '', ''], ['we', '', 'nu', '', '700', '', 'rmode', 'would', 'lmxb', 'lmxb', 'could', 'ligo', 'interferomet', '']]\n",
      "[['we', '', '', ''], [''], ['nonwin', ''], ['among', '', 'other', ''], ['the', '', 'alloc', ''], ['the', '', 'eg', '', '', 'either', 'arbitrari', '', '', '', ''], ['we', 'gametheoret', 'sealedbid', '', 'adiabat', ''], ['thi', 'comput', '']]\n",
      "[['we', 'realprincip', ''], ['via', 'meromorph', '', 'nonellipt', '']]\n",
      "[['thi', 'contentionbas', 'toward', ''], ['thi', 'enabl', ''], ['for', '', ''], [''], ['', ''], ['the', 'throughput', 'pointtopoint', '']]\n",
      "[['swave', 'superconduct', '', 'phi0', '', 'frac', '', '', '', '2e', '', '', ''], ['josephson', 'dwave', '', 'onehalf', '', '', ''], ['we', ''], ['we', 'heterojunct', 'superconductor', 'swave', 'dwave', ''], ['we', '', '', '', '', 'discontinu', '']]\n",
      "[['we', 'statist', '', 'largescal', '', 'nonlinear', ''], ['equationfre', '', 'numer', '', ''], ['although', 'statist', '', 'comput', 'typic', ''], ['the', 'nonlinear', '', 'stronglycoupl', '', 'either', 'determinist', 'stochast', '', ''], ['we', 'equationfre', 'entropybas', 'eyinklevermor', 'nonlinear', 'stochast', '']]\n",
      "[['throughput', ''], ['thi', 'hybridarq', ''], ['', '', ''], ['thi', ''], ['throughput', ''], ['the', ''], ['']]\n",
      "[['we', 'sloan', '', '', ''], ['the', '77429', '', '30000', 'sinc', ''], ['the', '', '220', '', 'h0', '', 'kmsmpc', '', 'omegam', '', '03', '', 'omegalambda', '', '07', '', 'fwhm', '', 'interestingcomplex', '', 'i150', '', ''], ['the', '5740', 'sq', ''], ['deg', ''], ['the', '008', '541', '', '148', '', '891', '', ''], ['', '', '', ''], ['for', '02', ''], ['rm', 'per', '', 'fiveband', '', 'ugriz', '', 'ccdbase', 'photometri', '003', '', ''], ['the', '', 'nearinfrar', '', 'xray', '', '', 'largearea', ''], ['the', '3800', '', '9200a', '2000', ''], ['the', 'databas', ''], ['the', '', '', ''], ['', '']]\n",
      "[['', 'chiral', '']]\n",
      "[['', '', '', ''], ['we', 'suffici', 'operatornam', '', '', 'epsilon', '', '', '', '', '', '', 'pv', ''], ['', 'int', '', 'epsilon', '', '', 'epsilon', '', 'xyv', '', '', '', 'frac', '', '', '', 'epsilon', '', '', ''], ['', 'ethinspac', 'mthinspac', '', '', '', 'lipschitz', '', '', 'epsilon', '', '', '', '', '', '', ''], ['our', 'suffici', '', '', ''], ['thi', 'suffici', '', '', '', '', '', '', '', '', '', '', ''], ['we', '', '', '', '', '', '', '', '', '', '', 'lipschitz', ''], ['the', 'suffici', '']]\n",
      "[[''], ['for', 'mani', '', '', ''], [''], ['they', '', '', '', ''], ['', '2mass', '', '', '2dfgr', '', 'ukidss', '', '', '', '', 'substellar', '', ''], ['opticalir', '', '', 'panstarr', '', '', 'lsst', ''], ['', '', 'whether', ''], ['', 'expens', 'unfruit', '', '', '', '', 'neutrino', 'astrophys', '']]\n",
      "[['the', '', 'cofe', '', 'balloonborn', 'polarim', 'ter', 'lowfrequ', 'lowl', ''], ['', 'per', '', 'mu', '', 'deg2', '', ''], ['thi', 'toward', '', '']]\n",
      "[['xray', 'earlytyp', ''], ['', 'microquasar', '', ''], ['interact', 'photon', '', '', '', '', 'interstellar', ''], ['highenergi', 'photon', 'neutrino', ''], ['the', '', '303', '', ''], ['']]\n",
      "[['we', '', 'd1', '', '589592', '', 'd2', '', '588995', '', 'latetyp', ''], ['the', 'f6', 'm55', '', 'bv', '0457', '1807', '', 'metal', '', 'feh', '', '', '082', '06', ''], ['we', 'echel', '215m', 'casleo', ''], ['the', 'sinc', '1999', ''], ['the', ''], ['pseudocontinuum', ''], ['we', 'continuum', ''], ['the', '', 'bv', '', ''], ['when', '', ''], ['', '', 'rd', '', '', '', 'bolometr', ''], ['we', '', 'photospher', '', 'chromospher', ''], ['', '', '']]\n",
      "[['we', 'boseeinstein', '', 'erdo', 'ht', 'yau', ''], ['mani', '', 'nonlinear', 'schroeding', 'grosspitaevskii', '']]\n",
      "[['the', 'electromagnet', 'paraxi', 'photon', 'spatial', ''], ['the', 'inhomogen', 'photon', ''], ['thi', 'doublelambda', 'electromagneticallyinduc', 'spatial', ''], ['photon', 'aharonovbohm', '']]\n",
      "[['interact', 'oscil', ''], ['c00', '', 'cnn', '', '', 'qubit', '', '', '', ''], ['oscil', '']]\n",
      "[['thi', '3dimension', 'kerr', 'magnetospher', 'obey', 'magnetohydrodynam', '', 'mhd', '', ''], ['', 'poynt', 'ergospher', ''], ['the', 'ergopsher', ''], ['for', '', '', '', '095', '', '', 'ergospher', 'greatli', 'poynt', ''], ['poloid', 'electromagnet', ''], ['the', 'ergospher', 'frii', '']]\n",
      "[['the', 'littlewoodrichardson', 'coeffici', '', '', 'mu', '', 'nu', '', '', 's3', '', 'via', ''], ['our', '', '', 'uniformli', '', 'littlewoodrichardson', '']]\n",
      "[['', '', 'collisionless', 'reconnect', 'twoscal', ''], ['the', '', 'ion', 'inerti', 'protonelectron', ''], ['', '', 'highveloc', 'xline', ''], ['the', 'reconnect', '', '']]\n",
      "[['we', 'maser', '', '', 'gaseou', 'keplerian', 'edgeon', ''], ['the', 'coeffici', '', 'kk0r', '', '', ''], ['we', 'positionveloc', 'maser', '', ''], ['we', '', '', 'qualit', ''], ['the', 'maser', 'either', '', '', ''], ['', '', 'positionveloc', 'qualit', 'maser', 'ngc', '4258', ''], ['', 'coeffici', '', '']]\n",
      "[['whisperinggalleri', '', 'wg', '', 'microdisk', 'photon', '', '', 'numer', ''], ['the', 'wgmode', 'qfactor', ''], ['from', '', 'microlas', '', 'coupledcav', 'microreson', '']]\n",
      "[['we', 's1', 's32', 'antiferromagnet', ''], ['schwinger', 'boson', '', '', '', 'paramagnet', 'monopol', ''], ['electromagnet', 'monopol', ''], ['for', ''], ['for', ''], ['', 'xy', '', 'xy', ''], ['dimer', 'dimer', '', '']]\n",
      "[['oeckl', 'hopf', 'algebra', ''], ['', 'nonperturb', 'among', ''], ['we', 'hopf', 'algebra', ''], ['we', 'hopf', 'algebra', '', ''], ['', 'poincar', 'noncommut', ''], ['threedimension', 'spinless', 'freidel', 'livin', '', 'noncommut', 'moyal', ''], ['we', 'kappaminkowski', 'spacetim', '']]\n",
      "[['revisit', '', 'chromospher', '', ''], ['thi', '', 'possibl', 'chromospher', '', 'chromospher', 'mani', ''], ['', 'visibleuv', 'continuum', ''], ['', 'though', 'chromospher', ''], ['the', 'chromospher', '']]\n",
      "[['3differenti', '3differenti', 'algebra', '', '', '', 'maurercartan', ''], ['we', 'coeffici', '', 'ndifferenti', 'algebra', '', 'algebroid', '']]\n",
      "[['superconduct', '', 'bilay', 'cuprat', 'superconductor', 'superconduct', ''], ['bilay', 'cuprat', 'superconductor', 'antibond', 'bilay', '', 'peakdiphump', '', '', 'pi0', '', '', 'bilay', '', 'superconduct', 'antibond', '', ''], ['the', ''], ['', 'antibond', '', '', 'pi0', '', '', '']]\n",
      "[['we', 'silic', 'lymanalpha', '', 'dla', '', '', '', '', '0524', 'toward', 'ao0235164', '', '', '', 'onboard', 'spitzer', ''], ['the', '812', 'absorb', '', 'sigma', ''], ['the', 'silic', 'olivin', 'interstellar', ''], ['to', '', 'silic', 'dla', ''], ['we', 'absorb', ''], ['although', '', 'tau', '', '', '', '008009', '', '', 'tau', '', '', '', 'bv', '', 'interstellar', ''], ['silic', 'absorb', '']]\n",
      "[['we', 'widefield', 'bvi', 'photometri', '11500', 'lowmetal', 'ngc', '5466', ''], ['we', '', 'although', '02', ''], ['the', '', '', 'yonseiyal', 'teramo', '', 'victoriaregina', ''], ['thi', 'abnorm', 'mainsequ', 'metal', ''], ['we', ''], ['we', '', ''], ['ngc', '5466', '', 'recentlydiscov', 'tidal', ''], ['the', 'central', 'rgb', ''], ['we', 'upturn', ''], ['timescal', ''], ['ngc', '5466', ''], ['', '', '']]\n",
      "[['', 'superconductor', 'kagom', ''], ['we', 'fraction', ''], ['the', 'kagom', 'commensur', 'depin', '', 'noninteg', 'interstiti', ''], ['for', '', 'bbphin2', '', '', '', ''], ['for', 'kagom', '', 'bbphin3', '', '', 'bbphin', ''], ['noninteg', 'kagom', '', 'interstiti', 'dimer', '', 'trimer', '', 'nmer', 'orient', ''], ['we', 'nmer', '', '', '', '', 'sinc', 'colloid', ''], ['we', 'ise', 'nstate', 'pott', ''], ['we', 'kagom', '']]\n",
      "[['the', '', 'twoflavor', 'grossneveu', '', '', 'gshp', '', '', '', '', '', '', 'quarkantiquark', 'pseudoscalar', 'diquark', '', 'diquark', 'quarkantiquark', '', 'coexist', ''], ['the', 'interplay', 'quarkantiquark', 'diquark', '', '4d', 'twoflavor', 'fourfermion', '']]\n",
      "[['', 'spinorbit', '', 'soc', '', 'dresselhau', '', '', '', '', 'mathemat', 'nonabelian', ''], ['', 'nonabelian', '', 'dresselhau', 'soc', ''], ['our', 'kerr', '']]\n",
      "[['we', 'practic', 'random', ''], ['we', '', 'either', 'per', '', ''], ['thi', ''], ['', 'finitelength', ''], ['our', 'random', '']]\n",
      "[['extrasolar', ''], ['the', 'joviantyp', 'cephei', 'gj', 'dynam', ''], ['the', 'scientist', ''], ['', 'earthsiz', ''], ['', '', '2008', '', '', 'terrestrialclass', '', ''], ['', '', '']]\n",
      "[['timefrequ', '', 'wellposed', 'nl', '', 'nlw', 'nlkg', 'cauchi', '', '', '', '', '', '', '', '', '', '']]\n",
      "[['increment', ''], ['for', 'increment', 'padic', ''], ['padic', 'increment', ''], ['padic', 'padic', ''], ['padic', '', ''], ['', '', 'huffman', '', 'golombric', '']]\n",
      "[['the', 'xray', 'gammaray', 'via', '3k', 'photon', ''], ['the', '', 'fornax', '', '', ''], ['for', '', '031', 'microg', '', 'gammaray', 'glast', ''], ['if', '', '', 'deg', 'deg', '', '', '', 'gammaray', ''], ['', 'gammaray', 'glast', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['zbasi', 'quasisymmetr', '', 'qsym', '', '', ''], ['nonneg', '', 'quasisymmetr', 'matroid', 'hopf', 'algebra', 'morphism', '', '', 'billera', '', 'jia', '', 'reiner', ''], ['', 'loopless', 'matroid', '', 'matroid', '', ''], ['morphism', 'inject', 'matroid', '', 'decompos', 'quasisymmetr', 'matroid', 'decompos', 'polytop', ''], ['billera', '', 'jia', '', 'reiner', '']]\n",
      "[['when', '', 'electromagnet', ''], ['bremsstrahlung', '', 'nonneglig', ''], ['nonrelativist', '', 'could', '']]\n",
      "[['we', ''], ['we', '', '', '', '', '05', '', 'nk3', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '13epsilon', '', '', '', ''], ['we', 'subclass', '', '', '', '13epsilon', '', '', '', ''], ['thi', '', 'mani', ''], ['for', '', '', '', '', '', '', '', ''], ['the', 'specif', ''], ['', ''], ['we', 'whose', '', ''], ['', 'monoton', '', 'per', '']]\n",
      "[['thi', ''], ['we', 'n3', ''], ['we', 'delignemumford', 'compactif', '', '', '']]\n",
      "[['the', 'leftright', 'higg', '', 'lrth', '', 'higg', '', 'phi', '', '', '', ''], ['', 'higg', 'boson', '', 'phi', '', '', '', '', 'via', '', 'bgto', 'tphi', '', '', '', '', '', 'cern', '', 'hadron', 'collid', '', 'lhc', '', ''], ['the', '', '', 'lrth', ''], ['we', '', '', 'higg', 'boson', '', 'phi', '', '', '', '', 'via', '', 'phi', '', '', '', '', '', '', 'lhc', '']]\n",
      "[['interplay', '', '', '', '', '', '', '', '', 'qq', '', '', '', '4d', '', '', 'massless', 'fermion', ''], ['', 'interplay', '', 'gsh', '', '4d', '', 'gshp', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'qq', '', '', 'pseudoscalar', '', '', 'qq', '', '', ''], ['', '', '', '', '', '', '', 'could', '', 'gsh', '', '', 'gshp', '', '', '2nc', '', '', 'fermion', '', '', 'qq', '', '', '', '', '', '', '', '', ''], ['', 'gsh', '', '', 'gshp', '', '', '2nc', '', '', ''], ['', '', '', '', 'coexist', '', '', '', 'qq', '', '', ''], ['the', '', 'gsh', '', '', '', 'gshp', '', '', ''], ['the', 'twoflavor', 'qcdanalog', 'njl', '']]\n",
      "[['the', 'hamiltonian', 'nboson', ''], ['the', 'pwaveparticl', 'revers', ''], ['the', 'mani', '', 'therebi', ''], ['the', 'intuit', 'via', 'twobodi', ''], ['boseclust', 'symmetr', '', '', '', '3cluster', ''], ['the', '', 'lowli', '']]\n",
      "[['', 'kadowakiwood', '', 'agamma2', '', '', '', '', '', ''], ['', '', '', '', '', 'without', ''], ['the', ''], ['', '', '', 'quasiparticl', '']]\n",
      "[['we', 'twoflavor', 'superconduct', '', ''], ['we', '']]\n",
      "[['we', 'microrefriger', 'superconduct', 'qubit', ''], ['adiabat', 'thermal', ''], ['the', 'select', 'photon', 'lc', 'lowfrequ', 'oscil', 'underdamp', ''], ['we', ''], ['thi', '']]\n",
      "[['for', 'arbitrari', '', 'kalgebra', '', '', 'x1', '', 'tau1', '', 'delta1', '', '', '', 'xn', '', 'taun', '', 'deltan', '', '', 'x1', '', 'tau1', '', '', '', 'xn', '', 'taun', '', '', 'taui', '', 'deltai', '', 'qiskew', '', '', 'qiskew', 'tauideriv', ''], ['we', 'gelfandkirillov', '', ''], ['we', 'algebra', '']]\n",
      "[['singleparticl', 'schr', '', 'oding', 'semispheroid', ''], ['', '', '', '', '', 'semispheroid', '', 'semispher', 'semispheroid', ''], ['the', 'semispher', 'superdeform', '', '', '', '', '', '', '', '', '', ''], ['the', 'superdeform', 'semispheroid', 'oscil', '', '', '', '', '', '', '112', '', '168', '']]\n",
      "[['decagon', 'quasicryst', ''], ['we', 'penros', '', 'ppt', '', '', '', ''], ['ppt', '', 'ppt', 'decagon', 'quasicrystallin', ''], ['our', 'quasicryst', '', 'nonloc', 'ppt', '']]\n",
      "[['bianchi', 'typev', '', '', ''], ['to', '', 'coeffici', ''], ['', '', '', '', '', 'supernova', ''], ['kinemat', '']]\n",
      "[['we', 'analyt', 'spin12', 'xxz', '', 'delta12', '', ''], ['we', 'massless', 'xxz', 'jimbo', 'miwa', ''], ['spinspin', '', 'fifthneighbour', ''], ['we', 'eigenvaluedistribut', ''], [''], ['we', 'asymptot', 'conform', '']]\n",
      "[[''], ['subset', '']]\n",
      "[['the', 'photon', 'boseeinstein', 'auau', '', 'sqrt', '', '', 'nn', '', '', '', 'gev', 'phenix', ''], ['twophoton', 'phenix', '']]\n",
      "[['thi', 'ricci', 'nonparabol', '', 'whose', 'asymptot', ''], ['', ''], ['']]\n",
      "[[''], ['could', ''], ['', '', 'could', ''], ['thi', ''], ['intuit', '']]\n",
      "[['the', 'intercombin', '689nm', 'success', 'photon', 'magnetoopt', '', '', ''], [''], [''], ['we', '', ''], ['detun', '', '']]\n",
      "[['we', 'radi', '', '', '', '', '', '']]\n",
      "[['', '', ''], ['', 'd5', '', '', ''], ['thi', 'lagrangian', '', 'gr', '', '', '', 'r2graviti', '', 'without', 'rterm', '', ''], ['o4symmetr', '5d', '', 'universalfunct', '', 'veryveri', '', 'bilaplac', '', 'r2', '', '', '', '1r2', '1r', '', '', '']]\n",
      "[['thi', ''], ['the', ''], ['we', 'lowinteract', '']]\n",
      "[['we', 'transfinit', '', 'chebyshev', 'choquet', '', 'fugled', 'ohtsuka', ''], ['', 'whenev', '', ''], ['for', '', 'chebyshev', 'transfinit', '', ''], ['']]\n",
      "[['thi', 'measurementbas', '4year', '373', 'sunossolari', 'workstat', ''], ['we', 'uptim', '', 'downtim', ''], ['syslogd', ''], [''], ['the', 'wtmpx', 'sunossolari', ''], ['the', 'wtmpx', 'syslogd', '']]\n",
      "[['malici', ''], [''], ['thi', 'leurr', '', '', '', '', 'com', '']]\n",
      "[['we', 'metalpoor', 'zw', 'iram', 'bure', 'interferomet', ''], ['these', 'j10', '', 'fwhm', '', 'lco', '', 's1', 'pc2', '', 'ico', '', 's1', '', '', ''], ['although', 'zw', 'starburst', '', 'lowmass', '', 'eg', ''], ['ngc', '1569', '', 'smc', '', 'ngc', '6822', '', ''], ['zw', 'bband', '', '', 'starburst', '', 'starburst', '', ''], ['unless', 'zw', '', 'cotoh2', '', 'sim', '102', ''], ['we', '3mm', 'continuum', '', 'freefre', '', 'toward', '']]\n",
      "[['the', 'farultraviolet', '', '', '1969', ''], ['heliumburn', 'without', 'hydrogenrich', '', '', ''], ['', 'subdwarf', ''], ['we', 'evolutionari', 'faruv', 'et', '', '2002', '', '2003', '', 'subdwarf', ''], ['', 'success', '', '', '', '', '1550v', '', '', '', '', '2000v', '', '', '', ''], ['we', 'colourcolour', ''], ['the', ''], ['', '', '', 'metal', '', 'univers', 'ellipt', 'ellipt', '']]\n",
      "[['the', 'gammaray', '', 'besid', 'powerlaw', ''], ['the', 'gammaray', 'bats', ''], [''], ['the', 'gammaray', 'z4', '', '', 'z20', '', ''], ['the', 'gammaray', 'bats', '']]\n",
      "[['for', '', '', '', '', 'schedul', ''], ['aadl', '', '', ''], ['', 'aadl', ''], ['thi', 'dependencydriven', 'aadl', ''], [''], ['thi', 'aadl', '', '']]\n",
      "[['', '', '', 'ahler', '', 'om', '', 'bidegre', '', '', '', '', 'nonneg', ''], ['we', '', '', 'mathcal', '', '', '', '', '', '', 'om', '', '', '', 'om', '', 'plurisubharmon', 'mongeamp', '', 'ere', ''], ['when', '', '', '', ''], ['we', 'mongeamp', '', 'ere', '', 'mongeamp', '', 'ere', '', '', 'mathcal', '', '', '', '', '', '', 'om', '', '', ''], ['thi', 'priori', 'sublevel', ''], ['our', 'ucegrel', 'skolodziej', ''], ['styau', 'priori', '', '', 'mathcal', '', '', '']]\n",
      "[[''], ['when', '', 'would', '', 'photon', ''], ['the', 'photon', 'andor', ''], ['the', '', '', ''], ['thi', 'aharonovbohm', '']]\n",
      "[['we', 'spinorbit', 'phonon', 'weaklyconfin', 'interact', ''], ['the', 'interelectron', '', 'rashba', 'dresselhau', 'spinorbit', ''], ['we', 'electronelectron', 'spinorbit', ''], ['', ''], ['we', '', '', '', ''], ['', 'tripletsinglet', 'gaa', ''], ['our', '', 'spinorbit', 'phonon', '']]\n",
      "[['we', '', 'tasep', '', ''], ['we', ''], ['our', 'algebra', 'tasep', ''], ['keyword', '', 'nonequilibrium', 'statist', '', 'asep', '', '', 'ansatz', '']]\n",
      "[['we', '', 'eoc', '', ''], ['thi', ''], ['eoc', '', '', '', 'ion', '']]\n",
      "[['timescal', 'extragalact', '', 'intraday', '', 'sourceextrins', '', ''], ['propagationinduc', 'timescal', '', ''], ['idv', 'j11285925', ''], ['we', 'idv', ''], ['we', 'timescal', 'idv', '', 'whether', 'timescal', ''], ['we', 'j11285925', '1045ghz', '100m', 'effelsberg', 'mpifr', '25m', 'urumqi', ''], ['from', '', 'timescal', ''], ['the', 'timescal', 'j11285925', 'anisotrop', ''], ['the', 'interstellar', ''], ['idv', '', ''], ['the', 'vlbi', '']]\n",
      "[['we', 'selfadjoint', 'pseudofriedrich', ''], ['we', ''], ['the', 'analyt', 'monoton', '', 'variat', '', '']]\n",
      "[['extrasolar', 'comet', ''], ['we', 'circumstellar', ''], ['the', 'heavyel', '', '', 'onto', '', ''], ['the', 'metal', 'lowmass', ''], ['', 'twothird', '', 'lowmass', 'exoplanet', '']]\n",
      "[['for', 'project', '', 'esec', 'kplane', 'among', 'enum', 'geometri', 'wellknown', 'castelnuovo', '', 'cayley', 'macdonald', ''], ['', 'enum', ''], ['the', ''], ['birat', 'geometri', 'esec', 'kplane', 'nonempti', ''], ['we', 'esec', 'kplane', ''], ['', '']]\n",
      "[['repunit', ''], [''], ['the', ''], ['repunit', '', '', 'gcd', '', '', '', '', '', 'gcd', '', '', '', '', '', '', '', '', '', '', '', 'rarb', '', '', '', 'gcd', '', '', '', '', '', '', '', 'ageq1', '', '', '', 'bgeq1', '', ''], ['repunit', '', '']]\n",
      "[['we', 'counterexampl', '720', 'villani', '', '', 'wasserstein', '', '', 'monoton', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'bimod', 'sne', ''], ['', '', 'bimod', '', '', '', 'bimod', '', 'sne', '', '', '', 'bimod', '', '108', ''], ['the', '', '', 'bimod', 'observ', 'sfr', '', '', '', 'radioloud', 'radioquiet', 'earlytyp', ''], ['we', 'bimod', ''], ['', 'sne', 'nearir', 'starburst', '']]\n",
      "[['the', 'substitut', 'cr3', 'ion', 'mgal2o4', 'spinel', 'kedg', 'xray', '', 'exaf', '', 'xray', '', 'xane', '', ''], ['firstprincipl', 'xane', '', ''], ['the', 'mgcr2o4', '', '', ''], ['these', 'vegard', 'obey', 'mgal2o4mgcr2o4', ''], ['', 'd3d', 'bsite', 'spinel', ''], ['', 'accomod', 'straininduc', '', 'mgcentr', 'tetrahedra', 'crcentr', 'octahedron', ''], ['', 'edgeshar', 'octahedra', '', '']]\n",
      "[['we', 'cachebas', ''], ['the', ''], ['', '', ''], ['the', ''], ['submodel', ''], ['the', '', 'simulationbas', 'systemlevel', '', '', '', ''], ['submodel', '', '', '', ''], ['submodel', 'lowerlevel', 'submodel', ''], ['', '', '', '', '', '', '', '', '']]\n",
      "[['stochast', 'stochast', 'revisit', ''], ['we', 'exponenti', 'lagrangian', ''], ['thi', 'thermodynam', ''], ['', '', 'concis', ''], ['', '', 'stochast', '']]\n",
      "[['our', ''], ['the', '', '', ''], ['the', ''], ['prior', '', 'omegam', '', 'dimensionless', '', '', '', 'analyt', ''], ['we', 'omegam', '']]\n",
      "[['the', '', 'supernova', ''], ['', '', 'energyth', 'dvaligabadadzeporrati', '', 'dgp', '', 'chaplygin', ''], ['both', ''], ['the', 'geometri', '', ''], ['the', '', '', '', '', '', 'pressureless', '', '', '', '', '', ''], ['the', 'dgp', 'chaplygin', 'the', 'dgp', '']]\n",
      "[['gaugehigg', '4d', 'higg', 'extradimension', ''], ['the', 'higg', 'randallsundrum', 'spacetim', 'gev', '', 'gev', ''], ['the', 'wwz', '', 'higg', ''], ['the', 'wwh', 'zzh', 'thetah', '', 'thetah', 'yangmil', ''], ['these', 'lhc', 'ilc', '']]\n",
      "[['we', 'counterexampl', 'sakai', ''], ['sakai', 'holomorphicmeromorph', '']]\n",
      "[['function', 'uniformli', 'uniformli', 'equicontinu', ''], ['if', 'countabl', ''], ['the', 'function', 'uniformli', 'equicontinu', '']]\n",
      "[['we', '', 'hamiltonian', '', 'h0', '', 'h1', ''], ['h0', 'interact', 'hamiltonian', 'g0', ''], ['the', 'h1', '', '', ''], ['for', '', 'h0', 'could', 'continuum', '', '', 'integr', 'onedimension', 'h1', ''], ['', 'relev', ''], ['', '']]\n",
      "[['nonextens', 'nonaddit', ''], ['the', 'statist', 'multistep', ''], ['thi', 'ise', 'longrang', ''], ['the', 'asymptot', ''], ['these', 'nonproport', '', '', '']]\n",
      "[['we', '', '', '', '6365', '', '', '', '', '', '', '', 'quasi2d', 'dimer', 'bacusi', '', '', '', '', '1326', 'mk', ''], ['intradim', '', '', '', 'rm', '', '', '', '', 'rm', '', '', '', '', '', '116', '', 'caxi', '', 'incommensur', '', '', ''], ['', '', '', '', '', '', '', 'rm', '', 'c1', '', '', '', '', '2335', 'boson', '', '', '', '', 'boseeinstein', 'caxi', '', '', '', '', '', 'rm', '', '', '', '', '', '', '', 'rm', '', '', '', 'simeq', '', ''], [''], ['thi', '', 'phi', '', '', '']]\n",
      "[['for', 'statist', 'bibliometr', '', ''], ['we', 'sizedepend', ''], [''], [''], ['we', 'sizedepend', 'topperform', ''], ['we', 'lowerperform', 'notcit', ''], ['', '', 'notcit', ''], ['we', ''], ['topperform', ''], ['thi', ''], ['lowerperform', 'per', ''], ['the', ''], ['topperform', ''], ['we', 'selfcit', '', '', '']]\n",
      "[['', 'we', 'whether', 'supernova', '', 'bsnr', '', 'either', 'interstellar', '', '', 'ambient', ''], ['', 'we', 'mhd', 'snr', ''], ['', '', 'ambient', 'ambient', '', '', 'ambient', ''], ['from', '', 'synchrotron', '', ''], ['', 'we', 'bsnr', 'lineofsight', 'ambient', 'ambient', ''], ['we', 'microphys', ''], ['', 'bsnr', 'ambient', '', '', 'ambient', ''], ['bsnr', '']]\n",
      "[['the', 'neutrino', 'neutrino', ''], ['among', 'antineutrino', 'could', ''], ['alreadi', '']]\n",
      "[['unsynchroniz', ''], ['', 'nonstationari', ''], ['for', 'synchroniz', '', 'onoff', ''], ['the', 'signatur', 'coexist', '', '', ''], ['the', ''], ['', '', ''], ['statist', 'nonstationari', '', ''], ['', '', '', ''], ['we', 'nonstationari', 'could', 'unsynchroniz', '']]\n",
      "[['we', '', '', 'maxim', ''], [''], ['the', 'interferometr', ''], ['both', '']]\n",
      "[['we', '', ''], ['of', '', '', '', 'dz', '', 'dq', ''], ['we', ''], ['we', 'vri', 'photometri', 'without', 'trigonometr', 'parallax', '', ''], ['for', '', 'photometri', '', ''], ['', '', 'metalrich', '', '', ''], ['nstar', '', '', '', '', ''], ['trigonometr', 'parallax', 'via', 'ctiopi', ''], [''], ['via', 'trigonometr', 'parallax', '', 'modeldepend', 'hhe', 'collisioninduc', '']]\n",
      "[['', 'explicit', 'gorenstein', ''], ['thi', ''], ['yong', '', 'mathag0603273', '', 'gorenstein', '']]\n",
      "[['we', 'relax', 'threedimension', 'random', 'anisotropi', 'nonconserv', 'ncompon', ''], ['random', 'anisotropi', 'anisotropi', 'random', ''], ['when', 'anisotropi', 'ndimension', 'hypercub', '', 'asymptot', 'randomsit', 'ise', ''], ['consider', 'nonasymptot', ''], ['we', 'fieldtheoret', 'renorm', 'twoloop', ''], ['we', 'asymptot', ''], ['the', 'asymptot', '']]\n",
      "[['we', 'holomorph', ''], ['our', 'poletski', '', 'rosay', 'holomorph', 'jointwork', 'pflug', ''], ['conform', 'siciak', 'extrem', ''], ['our', '', '', 'from', '', ''], ['', '']]\n",
      "[['the', 'arbitrari', '', '', 'higherspin', ''], ['', '', '']]\n",
      "[['sinc', '1999', '', '', '', '4600', '2500', ''], ['the', 'multimiss', '', '', ''], ['the', 'datareduct', '', 'calfus', '', ''], ['the', 'calfus', 'v32', '', ''], ['thi', 'calfus', 'v32', '', 'upon', '', '']]\n",
      "[['we', 'josephson', 'josephson', 'topolog', 'qubit', ''], ['we', 'nonmonoton', 'parametr', '', 'vpropto', '1i', '', ''], ['we', 'josephson', '']]\n",
      "[['we', 'twodimension', '', '', '', 'halfinfinit', '', '', ''], ['our', 'conform', '', 'highprecis', ''], ['for', '', '', ''], ['', '', '', '', '', '', '548', '', '', '', '', '', 'y2', '', '', '', '', '', '', '', '', 'y2', '', '', '', '', '', '', '', ''], ['we', 'numer', 'rectangl', '', '']]\n",
      "[['', 'realfrequ', 'selfenergi', '', 'momentumresolv', '', 'oneparticl', 'vo2', ''], ['quasiparticl', '', 'bandstructur', ''], ['we', 'orbitaldepend', '', 'oneparticl', 'manybodi', ''], ['', 'oneparticl', ''], ['the', 'nontrivi', 'decadeold', '', '', 'manybodi', 'peierl', '', '']]\n",
      "[['for', 'nonlinear', ''], ['we', ''], ['autocorrel', 'nonlinear', ''], ['we', '', ''], ['we', '', 'variogram', '', 'fractal', 'could', ''], ['', 'hurst', '', 'fraction', 'brownian', ''], ['the', '', 'rqa', '', ''], ['', 'psudoperiod', '', 'selfresembl', 'selfsimilar', 'determin', ''], ['', ''], ['nonlinear', '']]\n",
      "[['the', 'allski', '', 'rossi', 'xray', 'allski', '', '', '', ''], [''], ['sometim', ''], ['', '', 'semiweight', '', ''], ['we', 'glast', 'gammaray', '']]\n",
      "[['we', 'dielectron', '', 'dr', '', 'mglike', 'allik', 'via', 'n3', '', '', '', '', 'electronion', '045', ''], ['heavyion', 'heidelberg', '', ''], ['we', 'multiconfigur', 'breitpauli', '', 'mcbp', '', 'autostructur', ''], ['for', 'electronion', '', ''], ['from', ''], ['', '', ''], ['thi', '', '', '', '', '', ''], ['3s3p', '', '1p1', '', 'nl', 'dr', 'nl', ''], ['we', '', 'autostructur', '', 'maxwellianaverag', '', '', 'dr', 'coeffici', ''], ['the', 'coeffici', '', '', '', '', '', 'kbte', '', ''], ['kbte', '', '2515', '', 'photoion', '', 'experimentallyderiv', 'coeffici', ''], ['our', 'mcbp', 'coeffici', '1928', '', '']]\n",
      "[['', '', '', 'ise', 'blume', '', 'emeri', '', ''], ['', '', '', 'whose', 'exponenti', '', '', '', '', ''], ['', 'comput', ''], ['', '', 'polynomi', '1n', ''], ['', '']]\n",
      "[['we', 'nu', ''], ['the', ''], ['both', 'drainsourc', 'photon', 'hnu', '', '', '', '', 'hnue', '', ''], ['our', 'without', '']]\n",
      "[['we', '2045', '', 'wmap', ''], ['the', ''], ['allski', '', 'extragalact', 'wmap', 'physic', '', '', 'neither', 'statist', 'wmap', ''], ['if', '', '', 'nongaussian', ''], ['the', 'sachswolf', '', 'alreadi', 'statist', '', ''], ['to', 'wmap', 'mpc', '', ''], ['thi', '', '']]\n",
      "[['we', 'invari', 'l2', 'rho', ''], ['', 'novikov', '', 'shubin', 'invari', '', 'b1', '', 'asymptot', ''], ['', 'l2', 'rho', '']]\n",
      "[['nhomomorph', 'algebra', '', 'phi', '', '', '', 'phi', '', 'a1', '', '', '', 'phi', '', 'a1', '', '', 'phi', '', '', '', '', 'a1', '', '', '', '', '', 'nhomomorph', '', '', '', '', '', ''], ['hejazian', 'et', ''], ['', '', '', '', 'nhomomorph', '', 'algebra', ''], ['we', '', ''], ['we', '', 'if', '', '', '', 'phi', '', '', ''], ['if', '', '', '', '', 'phi', '', '', ''], ['', 'nontrivi', '', 'nhomomorph', '', 'algebra', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['z14', ''], ['the', '', 'tidal', '', 'tidal', '', '', 'm51type', 'tidal', '', 'earlytyp', '', 'equalmass', 'grazingcollis', '', 'jshape', ''], [''], ['', ''], ['', ''], ['among', '', ''], ['5x10', '', '', 'msun', 'could', ''], ['tidal', ''], ['tidal', 'tidal', ''], ['the', 'starform', 'tidal', '', 'although', ''], ['if', '', 'gaseou', 'interact', '', '']]\n",
      "[['we', ''], ['with', 'statemix', 'spinorbit', 'hyperfin', '', '', '1s0', '', '', '', '3p0', '', 'gfactor', 'alkalineearth', '', '', '', '', '', '', '', '', ''], [''], ['gfactor', '', '', '', '', '', ''], ['the', ''], ['spinrel', '', '', '', '', '', '']]\n",
      "[['without', '', 'superparamagnet', '', '', ''], ['victora', '', 'ebmu0', 'hsw', '', 'stonerwohlfarth', '', 'stonerwohlfarth', '', 'coher', '', 'twolay', ''], ['', 'eg', '', 'stonerwohlfarth', 'continuum', 'micromagnet', '', ''], ['mani', 'variat', '', ''], ['the', 'mz', '', '', '', 'mz', '', '', '', '', ''], ['', ''], ['we', 'anistropi', 'et', '']]\n",
      "[['', 'electromagnet', '', '', 'sigma', '', '', '', '', '', '', '', '', '', 'permitt', '', 'epsilon', '', '', '', '', 'mu', '', '', '', '', 'piecewis', '', 'mathbb', 'r3', '', 'hypersurfac', '', 'sigma', '', '', '', 'sigma', '', ''], ['', '', 'electromagnet', '', 'electromagnet', ''], ['', '', 'handlebodi', '', 'mathbb', 'r3', '', ''], ['the', 'electromagnet', 'wormhol', '']]\n",
      "[['parametr', 'socal', '', '', 'singlewal', '', 'swnt', '', 'ironaluminum', 'oxid', ''], ['millimeterthick', '', '', '05', '', 'swnt', ''], ['although', '', 'swnt', ''], ['oxid', ''], ['oxid', '', 'wellknown', 'hydrocarbon', '', '']]\n",
      "[['the', 'neutron', '', 'proton', '', 'alphaparticl', 'd59co', '3he58f', '', '', ''], ['the', 'hauserfeshbach', ''], [''], ['parameter', 'neutron', ''], ['fermiga', '60ni60co', '', '57fe', '']]\n",
      "[['the', 'highresolut', 'highaccuraci', 'sinc', '2003', ''], ['sinc', '', 'solartyp', '', '1400', '', 'lowmass', ''], ['amongst', '', 'extrasolar', 'volumelimit', 'planetform', ''], ['', 'radialveloc', 'solartyp', '', 'hd', '100777', '', 'hd', '190647', '', 'hd', '221287', ''], ['the', 'radialveloc', 'hd', '100777', 'mjup', '384', '', '', 'e036', '', ''], ['the', 'hd', '190647', 'longperiod', '', 'p1038', '', 'mjup', '', 'e018', '', ''], ['hd', '221287', 'host', 'mjup', '456', '', ''], ['the', 'nonoptim', 'abnorm', ''], ['we', '']]\n",
      "[['gaussian', 'covari', ''], ['we', 'bayesian', '', 'toward', 'recurs', ''], ['', ''], ['we', 'bayesian', 'multigrad', 'random', ''], ['thi', ''], ['', 'bayesian', 'geometri', 'toric', 'grassmannian', '', '', '']]\n",
      "[['we', ''], ['both', 'gaussian', ''], ['ensembleaverag', 'twoparticl', ''], ['diffuson', 'cooperon', 'twoparticl', ''], ['we', 'interact', 'swave', 'bardeencooperschrieff', '', 'noninteract', ''], ['we', '', 'nonmonoton', '', 'interdot', ''], ['', 'nonmonoton', '', 'either', 'diamagnet', 'paramagnet', '', 'cooperon', '']]\n",
      "[['threebodi', ''], ['hamiltonian', 'semianalyt', ''], ['the', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['the', 'threebodi', 'hyperspher', ''], ['the', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '']]\n",
      "[['yang', '', 'z0', '2gamma', '', 'poincar', '', '', '', 'photon', 'boson', 'twoparticl', 'poincar', '', '', '', '', 'coproduct', 'poincar', '', '', '', '', ''], ['thi', ''], ['noncommut', 'geometri', 'coproduct', 'drinfel', ''], ['we', '', 'z0', '2gamma', '', 'coproduct', ''], ['thi', ''], ['', '', 'z0', 'nu', '', 'nu', '', 'coproduct', 'poincar', '', '', '', 'neutrino', 'massless', '', ''], ['thi', '', '', 'massless', 'helic', '', '', '', 'coproduct', '']]\n",
      "[['we', 'gronwal', '']]\n",
      "[['we', 'oneparamet', '', '', 'mani', '', 'cramerrao', 'inequ', '']]\n",
      "[['the', 'katzsarnak', '', '', 'lfunction', '', '', 'oo', '', '', ''], ['mani', 'nlevel', '', 'random', ''], ['', 'oneparamet', '', '', ''], ['we', 'mani', '', '', ''], ['we', 'gl', '', '', 'lfunction', 'simplifi', '', 'satak', 'coeffici', 'lambdaf', '', '', ''], ['our', 'whose', 'coeffici', 'obey', '', '', 'satot', 'noncm', '', ''], ['', 'rosen', 'silverman', 'coeffici', '', '', '', ''], ['we', '', 'whether', '', '', 'nonzero', '', '', '']]\n",
      "[['we', 'antiferromagnet', 'spin1', 'boseeinstein', ''], ['the', 'nonlinear', '', '', 'anharmon', ''], [''], ['the', 'spindepend', 'coeffici', '', 'spindepend', 'swave', '', '', 'f2', '', '', 'f0', '', '', '', '247pm027', '', '']]\n",
      "[['we', 'increment', 'ito', 'stochast', ''], ['specif', '', 'stochast', 'nonlinear', 'stochast', ''], ['thi', 'noisefre', ''], ['we', 'stochast', 'nonlinear', 'stochast', '']]\n",
      "[['conrey', '', 'zirnbauer', 'lfunction', ''], ['their', 'lfunction', 'mani', '', 'nlevel', 'mollifi', ''], ['mani', 'random', '', '', ''], ['these', '', ''], ['the', 'lfunction', ''], ['we', '', '1level', 'symplect', 'dirichlet', 'discrimin', ''], ['for', '', '', '', '', '', '12epsilon', '', '', '', '', '', '', '', '', 'epsilon', '', '', 'epsilon', '', ''], ['', '1level', '']]\n",
      "[['we', 'salamsezgin', 'supergrav', '', 'supernova', '', 'nucleosynthesi', '', ''], ['the', ''], ['', '', ''], ['', '', '', ''], ['we', '', '', 'supersymmetri', '', '', '', '', '', '', '', '', '', '', '', 'robertsonwalk', '', '', '', ''], ['', '']]\n",
      "[['we', 'noncommut', '', '', '', '', 'rdc', '', '2n', '', '', '', '', '', '', '', 'infti', '', 'yangmil', 'rdc', '', 'rdc', 'ddimension', 'commut', 'spacetim', '', '2n', '', '', '', '', '2ndimension', ''], ['the', '', '', 'yangmil', 'rdc', '', 'd2n', '', '', '', 'yangmil', 'onto', 'rdc', ''], ['we', 'gaugehigg', '', 'amu', '', 'phia', '', '', '', '', 'infti', '', 'yangmil', 'rdc', 'geometri', '', 'd2n', '', 'spacetim', 'whose', ''], ['', '10dimension', 'd4', 'n3', 'geometri', '4dimension', 'n4', 'multiplet', 'adscft', ''], ['we', 'gaugehigg', '', 'amu', '', 'phia', '', 'halfbp', 'selfdual', '']]\n",
      "[['we', 'wzwtype', 'superstr', 'dbrane', ''], ['the', 'onshel', ''], ['the', 'superstr', '', 'boson', '', ''], ['', 'superstr', '', '', 'reexpress', 'boson', ''], ['thi', 'nonsingular', 'superstr', '']]\n",
      "[['we', 'isophot', 'earlytyp', 'bband', '', '', '', 'unpreced', '847', 'earlytyp', 'hao', 'et', '', '2006', '', ''], ['we', 'diski', ''], ['the', 'statist', 'isophot', ''], ['diski', '', '', '', 'xray', '', '', '', ''], ['our', 'diski', ''], ['we', 'neither', '', 'isophot', 'earlytyp', '']]\n",
      "[['semianalyt', '', 'nbodi', '', 'among', 'earlytyp', ''], ['we', '', '', '', '', '', 'rm', '', '', '01', '', ''], ['our', '', ''], ['', 'earlytyp', ''], ['thi', 'pasquali', 'et', '', '2007', '', 'earlytyp', 'isophot', ''], ['we', 'earlytyp', '', 'agn', ''], ['', '', '', '', '', '', '', '', '', 'earlytyp', ''], ['earlytyp', '', ''], ['', '', '', 'earlytyp', 'earlytyp', '', '', '', 'earlytyp', '', '', '', '', '', '', '', 'msun', '', '', '', '', 'earlytyp', 'supermass', ''], ['the', 'earlytyp', '', '']]\n",
      "[['volborthit', '', 'spin12', 'kagom', '', '', 'isoscel', '', '', '', '', '', ''], ['we', '', '', ''], ['although', 'subextens', '', '', 'exponenti', ''], ['we', ''], ['to', '', '', '', ''], ['', '', ''], ['', 'chiral', 'hamiltonian', 'nonlinear', '', 'jj', '', '', '', 'sqrt', '3time', 'sqrt', '', 'ferrimagnet', '', 'chiral', '', ''], ['thi', 'largen', '', '', '', '', ''], ['', '', '', '1n', '', '', 'nontrivi', 'wavevector', 'chiral', ''], ['the', 'via', ''], ['we', '', '']]\n",
      "[['we', 'quasiclass', 'threebodi', '', 'preexponenti', '', 'coeffici', ''], ['the', 'threebodi', 'semianalyt', 'threebodi', 'hamiltonian', '', ''], ['grigorenko', '', 'arxiv07040920v1', '', ''], ['the', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['threebodi', '']]\n",
      "[['we', 'conduct', 'selfheal', ''], ['continuum', 'effectivefield', ''], ['our', 'selfheal', '', 'the', '', 'plateaulik', 'timedepend', ''], ['we', 'lowdamag', '', 'conduct', 'transportrespons', '']]\n",
      "[['we', 'calcul', 'boson', 'superstr', 'berkovit', ''], ['we', 'superconform', '']]\n",
      "[['algebra', 'algebra', 'realcomplex', ''], ['invari', '', 'casimir', '', '', 'algebra', '', 'either', 'nonstrictli', '', 'socal', 'algebra', ''], ['', 'phi', ''], ['', ''], ['gen', '', '2006', '', 'v39', '', '5749', '', 'mathph0602046', '', '', '', 'phi', ''], ['', ''], ['theor', '', '2007', '', 'v40', '', '113', '', 'mathph0606045', '', '', 'invari', ''], ['', 'phi', ''], ['', ''], ['gen', '', '2001', '', 'v34', '', '9085', '', '', 'invari', '', '']]\n",
      "[['we', 'metast', 'ise', ''], ['the', 'nucleat', '', 'phi', '', '', '', 'langevin', ''], ['we', 'nucleat', ''], ['the', 'whose', 'nucleat', 'droplet', 'nucleat', ''], ['we', 'nucleat', 'droplet', 'metast', '']]\n",
      "[['the', 'gammaray', '', 'egret', '', 'gammaray', '', 'cgro', '', 'gammaray', 'blazar', ''], ['we', 'egret', 'blazar', 'enabl', 'powerlaw', ''], ['the', 'flatspectrum', '', 'fsrq', '', '', 'lowfrequ', 'bl', 'lac', '', 'lbl', '', 'highfrequ', 'bl', 'lac', '', 'hbl', '', ''], ['we', ''], ['blazar', 'statist', ''], ['the', ''], ['fluxhard', 'anticorrel', 'blazar', ''], ['the', 'wellobserv', 'blazar', '', '3c', '279', '', '3c', '273', '', 'pk', '0528134', '', 'pk', '1622297', 'pk', '0208512', '', 'longterm', '', ''], ['we', 'unreport', 'hysteresi', 'timescal', 'fsrq', '', '', '', ''], ['', ''], ['we', 'egret', ''], ['our', 'egret', 'skymap', '']]\n",
      "[['the', 'anisotrop', '', '', 'su', '', '', 'yangmil', ''], ['', 'lowli', 'n2', ''], ['the', '', '', 'su', '', '', 'xsu', '', '', 'chiral', 'sigma', '', ''], ['thi', 'exactlyknown', 'smatrix', 'sigma', '']]\n",
      "[['we', '', '', '', 'metal', ''], [''], ['we', 'parametr', 'galaxybygalaxi', ''], ['our', '', ''], ['sloan', '', '', ''], ['we', 'signaltonois', '', ''], ['for', '', ''], ['we', '']]\n",
      "[['c2', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['for', '', 'hyperbol', 'postcrit', 'julia', '', '', 'either', ''], ['for', '', 'jonsson', '', ''], ['ann', '', '1999', '', 'postcrit', 'julia', ''], ['', 'either', ''], ['', 'postcrit', '']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'ligo', 'geo', '600', 'gravitationalwav', '', '2005', '', ''], ['we', 'shortdur', 'gravitationalwav', 'arbitrari', '641600', 'ligo', 'interferomet', ''], ['', '', 'auxiliarychannel', ''], ['gravitationalwav', '', 'frequentist', '015', 'per', '', '', '', ''], ['the', '', 'carlo', '', ''], ['we', 'supernova', 'could', '', '']]\n",
      "[['we', 'glast', 'gammaray', 'neutralino', ''], ['we', '', 'via', 'lactea', '', '', '', 'subhalo', ''], ['we', 'allski', 'gammaray', '', ''], ['glast', 'subhalo', '']]\n",
      "[['we', ''], ['', 'gibbstyp', 'aldou', '', 'betasplit', '', '', '', '', '', '', 'rm', '', '', 'beta1', '', 'beta1', '', '', ''], ['multifurc', '', 'twoparamet', 'poisson', '', 'dirichlet', 'random', '', 'mathbb', '', '', '', '', '', '0lealphale1', '', '', '', 'thetage2alpha', '', '', '', '', '', '', 'theta', 'malpha', '', '', '', 'mathbb', '', '', '', '']]\n",
      "[['we', 'seminumer', '', '', '', ''], ['our', 'excursionset', 'firstord', 'lagrangian', ''], ['', 'nbodi', ''], ['thi', 'reioniz', '', ''], ['we', 'halofind', 'hii', 'bubblefind', 'nbodi', 'radi', ''], ['we', ''], ['we', 'volumeweight', ''], ['we', '21cm', '', ''], ['we', 'smallscal', '', 'though', 'reioniz', ''], ['we', '', '250', 'mpc', '', '', 'x108', 'msun', ''], ['we', 'reioniz', ''], ['the', 'seminumer', 'reioniz', '']]\n",
      "[['arcsecondscal', 'seyfert', 'm51', 'circumnuclear', '', ''], ['', 'interferometr', '', '', '', ''], ['to', 'put', 'circumnuclear', 'subarcsecond', 'kinemat', ''], ['we', '', '', '', '', 'm51', 'iram', 'bure', 'interferomet', '', ''], ['the', '', 'eastwest', '', '', ''], ['the', '', 'jetentrain', ''], ['the', 'eastwest', ''], ['blueshift', ''], ['thi', 'put', 'circumnuclear', ''], ['kinemat', '', 'toward', '', 'keplarianrot', '']]\n",
      "[['we', '', 'nova', '', 'porb', ''], ['the', 'and', '', '01509743', '', '', '', 'cz', 'aql', '', '02005', '', '', '', '', '01499686', '', '', '', 'gz', 'cnc', '', '00881', '', '', '', 'v632', 'cyg', '', '006377', '', '', '', 'v1006', 'cyg', '', '009903', '', '', '', 'bf', 'eri', '', '02708804', '', '', '', 'ori', '', '01915', '', '', '', 'per', '', 'porb', 'either', '01467', '', '', '01719', '', '', ''], ['bf', 'eri', '', 'k3', '', 'subclass', '', 'kpc', ''], ['', 'bf', 'eri', '', 'masyr', '', '', 'parallax', 'parallax', ''], ['bf', 'eri', '', ''], ['cz', 'aql', '', '', 'magneticallychannel', ''], ['the', 'v1006', 'cyg', '3hour', '', '', '']]\n",
      "[['the', ''], ['eulerlagrang', ''], ['optim', 'duboisreymond', 'variat', ''], ['with', '', 'noethertyp', ''], ['ergod', '']]\n",
      "[['we', 'statist', '', 'zodot', '', ''], ['the', '537', '', 'yoc', '', '', '', '', 'heliocentr', 'kpc', '2030', '1200', '', ''], ['we', 'statist', 'zodot', 'heliocentr', ''], ['we', 'zodot', '', '', 'anali', 'yoc', '', '', ''], ['zodot', 'although', 'yoc', ''], ['we', '569', '', '', '', '', '614', '', '', '', '', 'yoc', '']]\n",
      "[['strongdisord', 'renorm', '', '', 'carlo', '', 'revisit', 'random', 'antiferromagnet', 'xxz', 'spin12', 'longlength', 'groundstat', 'timeindepend', 'spinspin', '', '', 'upsilon', '', '', ''], ['wellknown', '', 'disorderindepend', '', 'powerlaw', 'eta2', '', 'prefactor', 'upsilonupsilono3', '', '', 'upsilonupsilone3', '', ''], ['although', 'upsilono', 'upsilon', 'nonunivers', '', '', '', 'upsilono', '', 'upsilon', '', '', '', ''], ['the', 'nonunivers', 'prefactor', 'renormalizationgroup', ''], ['', '', 'whose', ''], ['the', 'nonunivers', 'prefactor', ''], ['', 'whose', '', 'interestingli', '', 'prefactor', '']]\n",
      "[['the', 'decad', 'astrophys', 'spacebas', 'interferometri', '', 'sim', 'planetquest', '', '', 'bahcal', '1991', '', 'mckee', '', '2001', '', '', 'astrophys', ''], ['roadmap', 'sim', ''], ['to', '', 'sim', 'solartyp', ''], ['', 'sim', 'threedimension', '', '', '', '', 'spacebas', '', 'groundbas', 'interferometri', '', 'tpf', '']]\n",
      "[['we', '', '', '105403', 'z083', 'kband', ''], ['spectroscop', '', ''], ['we', 'similarmass', ''], ['the', 'schechter', '', '', '', '', '1149', '030029', 'lsun', '', ''], ['the', '105403', '', '', 'eg', '', '', '', 'sfr', '', ''], ['the', 'massnorm', 'sfr', '05r200', '105403', '', 'conclus', ''], ['nonneglig', '', '', '', '', 'activ', 'overdens', ''], ['passiv', '', '', 'mani', '', '']]\n",
      "[['', '', 'among', '', '', '', 'random', '', '', '', '', '', '', 'sinc', '', '', '', ''], ['the', 'signaltonois', '', 'snr', '', '', '', ''], ['these', 'snr', ''], ['the', '', '', 'among', '', '', 'consensu', '', '', ''], ['to', '', '', '', '', 'random', '', '', '', 'suffici', '', '', '', '', 'consensu', '', '', '', '', '', 'suffici', 'connect', ''], ['with', '', '', 'random', '', 'semidefinit', ''], ['we', 'consensu', 'asymptot', 'nonrandom', '']]\n",
      "[['we', 'extrem', 'geometri', ''], ['thi', 'noetherwald', 'nonextrem', ''], ['these', '', '', 'dimension', ''], ['iib', 'supergrav', 'supergrav', '', ''], ['we', 'explicitli', 'extrem', '', 'nearhorizon', 'geometri', ''], ['we', '']]\n",
      "[['we', '', '', '', '2x', '', '', '', '', 'cuo', '', '', '', '4delta', '', '', 'coexist', '', 'meanfield', '', 'antiferromagnet', 'superconduct', ''], ['', '', 'x2y2', '', '', '', 'nodeless', '', '', 'underdop', '', ''], ['', 'linearin', '', '', '', 'dwave', '', 'nodal', '']]\n",
      "[['we', 'interact', 'brownian', 'whose', ''], ['our', 'brownian', ''], ['for', 'finit', 'mani', 'brownian', 'interact', '', '', ''], ['we', 'countabl', '', 'brownian', '', 'ident', ''], ['']]\n",
      "[['the', 'blazar', 'pks0537441', '2004', '2005', ''], ['the', 'recurr', '', 'xrt', 'uvot', '', 'agn', ''], ['the', ''], ['januaryfebruari', '2005', 'pks0537441', 'xray', '', 'xray', '2004', ''], ['the', 'juli', '2005', 'xray', ''], ['the', '', 'uvot', '', '', 'vri', '2005', '', ''], ['2005', '', 'xray', '', 'januaryfebruari', '2005', '', ''], ['our', 'xray', ''], ['', '', '', 'obviou', 'xray', '', '', ''], ['the', 'xray', 'blazar', ''], ['the', 'synchrotron', 'via', '', '', '']]\n",
      "[['we', 'pentaquark', ''], ['the', ''], ['the', 'pentaquark', '', '', 'nk', '']]\n",
      "[['we', 'nanomechan', '', '', '', 'superconduct', 'cooperpair', '', 'cpb', '', 'superconduct', '', 'stlr', '', ''], ['the', 'nonlinear', 'stlr', 'cpb', ''], ['the', 'hamiltonian', 'stlr', '', 'rmddot', '', 'hlich', 'hamiltonian', ''], ['adiabat', 'cpb', '', 'parametr', 'downconvers', 'hamiltonian', ''], ['the', 'cpb', '', 'nonlinear', '', '', 'threewav', ''], ['thi', 'threewav', 'solidst', '']]\n",
      "[['', 'the', '09221333', '2002', 'polar', '', 'larp', '', 'undergo', 'polar', ''], ['', 'tovmassian', 'et', ''], ['2004', '', ''], ['the', 'dispar', ''], ['', 'we', ''], ['', 'synchrotron', ''], ['', '404', ''], ['', 'we', 'l1', '']]\n",
      "[['the', 'mathematician', 'vladimir', 'varicak', '1909', '1913', '']]\n",
      "[['lens', '', '1912', '', ''], ['lens', '1915', ''], ['relev', '', '', '1915', ''], ['', 'nova', 'geminorum', '1912', '', 'dn', '', '1912', '', '', 'relev', 'lens', 'erwin', 'freundlich', '1912', ''], ['we', 'lens', '1915', 'toward', '']]\n",
      "[['we', 'nonloc', 'hamiltonian', ''], ['hamiltonian', '', '', '', '', '', '', '', '', 'interact', '', '', '', '', ''], ['ancillaassist', 'upon', 'ancilla', ''], ['the', 'coeffici', '', 'coeffici', '', ''], ['our', '', 'timeindepend', 'unitarili', '']]\n",
      "[['', 'separ', 'multipartit', ''], ['we', 'separ', 'multipartit', 'theorem1', ''], ['the', 'theorem2', 'multipartit', ''], ['theorem3', 'corollary1', '', '', ''], ['', 'separ', 'multipartit', '']]\n",
      "[['we', 'twoparticl', 'protonproton', '410', 'gev', ''], ['the', 'phobo', 'ion', 'collid', '', 'longrang', ''], ['', 'twodimension', '', '', '', 'phi', '', ''], ['shortrang', '', 'twoparticl', 'pseudorapid', 'protonproton', 'protonantiproton', '', 'hije', '']]\n",
      "[['mimo', ''], ['mimobas', '', 'gaussian', ''], ['', '', '', '', 'dpc', '', 'gaussian', ''], ['', 'crosslay', 'mimobas', ''], ['to', '', 'dpc', 'multihopmultipath', 'mimobas', ''], ['nonconvex', ''], ['to', '', ''], ['for', '', 'lagrangian', '', '', 'cuttingplan', '', 'subgradi', ''], ['', '344', '', 'dpc', '']]\n",
      "[['to', 'lens', '', 'observ', 'lens', ''], ['', 'fraction', ''], ['from', '', ''], ['the', ''], ['we', '', 'alesssim', '', '', ''], ['the', ''], ['we', '', 'asim', '', ''], ['highmagnif', '', '', '', 'among', ''], ['', '', '', '', '', 'qlesssim', '', '', '', '', '', 'agtrsim', '', '']]\n",
      "[['', 'suffici', 'separ', ''], ['', '', '', 'ketpsi', '', '', '', '', ''], ['we', '', 'ketpsi', '', '', '', '', '', '', ''], ['separ', 'mani', '']]\n",
      "[['protoplanetari', ''], ['they', 'mhd', 'via', 'magnetocentrifug', '', 'magneticallydriven', ''], ['', 'protoplanetari', ''], ['diffus', ''], ['ion', 'mani', ''], ['', ''], ['becaus', 'ion', '', ''], ['for', '01', 'gcm2', '', 'gcm2', ''], ['', 'xray', '', '', 'gcm2', '', ''], ['']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'babar', 'bell', '', 'd0', '', '', '', '', '', '', '', 'd0to', '', '', '', 'kmp', '', 'cpconjug', ''], ['we', '', 'd0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '0to', '', '', '', 'kmp', '', '', 'd0to', '', '', '', 'kmp', '', '', '', '', '', 'timedepend', ''], ['', '', '3770', '', '', '', '', '4140', '', '', '', 'tau', '', '', '', '', '', '', '', '', '', 'timeindepend', '', '', 'd0bar', '', '', '', '', '', '', '', 'kmp', '', '', '', '', '', 'kmp', '', '', ''], ['if', 'cpviolat', '', 'd0', '', '', '', '', '', '', '', '', '', '', '', 'kmp', '', '']]\n",
      "[['', ''], ['we', '', '', '']]\n",
      "[['we', 'xray', 'psr', 'j19301852', '', 'pulsar', 'nontherm', 'supernova', 'g54103', ''], ['rossi', 'xray', 'chandra', 'xray', 'ephemeri', '136', 'pulsar', ''], ['dure', '', '', 'spindown', '', '', '75112', '', '', '', '', '', '', '', '', '', '', '', 'andor', ''], ['the', 'xray', '', '', '71pm5', '', '', '', '', '', '', 'sim', '', '', '', ''], ['the', 'photon', '', '', '12pm02', '', '', 'margin', 'unpuls', ''], ['the', '210', 'kev', 'pulsar', '', '', '', '', 'erg', '', '', '', '', '', '', '', '', '', '', ''], ['these', 'psr', 'j19301852', 'crablik', 'pulsar', '']]\n",
      "[['the', 'antiferromagnet', 'bilinearbiquadrat', 'carlo', ''], ['finitetemperatur', 'topolog', '', ''], ['the', 'relev', 'could', '', ''], ['antiferromagnet', 'niga', '', '', '', '', '']]\n",
      "[['polycrystallin', 'al25', '', 'portevinl', 'chateli', '', 'plc', '', ''], ['the', 'stresstim', '', 'rp', '', '', 'rqa', '', 'plc', ''], ['our', 'rqa', 'plc', '']]\n",
      "[['we', ''], ['the', '', '', '', ''], [''], [''], ['the', '', ''], ['we', 'exponenti', '', ''], ['we', ''], ['', '']]\n",
      "[['ramanact', '', '', '', '', '', 'singlewal', '', 'swnt', '', 'hydrostat', ''], ['with', '', 'obviou', ''], ['the', 'e1g', '', 'a1g', '', 'e2g', '', '', '', '', '', '', '', '', '', ''], ['the', 'consumedli', 'cnt', ''], ['the', 'anomal', 'd10h', 'd2h', 'c2h', '']]\n",
      "[['the', 'b0218357', '', 'lens', '', 'z068', '', '', ''], ['03', '', '', ''], ['although', '', 'whether', ''], ['to', '', 'hco', '', '', 'bure', 'interferomet', '', ''], ['selfcalibr', 'per', ''], ['our', 'hco', '', '', ''], ['we', 'fafb', '', '', '', '106', '']]\n",
      "[['', '', 'sim', '', '', '', ''], ['extragalact', '', '', 'ankletransit', '', '', '', '', '', 'protondip', '', '', ''], ['', 'whether', 'neutrino', ''], ['we', 'neutrino', '', ''], ['', 'neutrino', '', 'sim', '', '', '', 'ankletransit', 'suffici', ''], ['', 'neutrino', '', 'sim', '', '', '', 'protondip', 'extragalact', 'proton', '', '', '', '', ''], ['', 'neutrino', '', 'unless', 'neutrino', '', 'neutrino', 'agn', 'grb', ''], ['we', 'neutrino', '', 'sim', '', '', '', ''], ['that', 'neutrino', 'ultrahigh', ''], ['', 'neutrino', 'neutrino', '', 'neutrino', '']]\n",
      "[['we', 'hyperfin', 'spinorbit', 'singlettriplet', 'ina', ''], ['gaa', '', 'spinorbit', 'hyperfin', ''], ['alreadi', '', 'hyperfin', '']]\n",
      "[['we', 'dirichlet', 'selfsimilar', ''], ['we', ''], ['thi', 'toward', '']]\n",
      "[['the', 'solar', 'electr', 'planckian', '', '', 'stpetersburg', '', 'spb', '', '', ''], ['damanai', ''], ['we', 'mayjun', ''], ['the', '26kev', 'elast', 'nai', '', '', 'scintil', 'v3050', 'heliocentr', ''], ['the', 'halfyear', 'spb', 'deg', 'nearearth', ''], ['their', 'multiloop', '', 'crosslik', '', 'mani', '', 'nearearth', ''], ['1e19', 'cm2', 'solar', '']]\n",
      "[['the', 'electromagnet', ''], ['the', '']]\n",
      "[['we', ''], ['', '', 'detun', 'photon', 'photon', ''], ['we', '', 'fluoresc', ''], ['']]\n",
      "[[''], ['evolv', ''], ['thi', 'conceptu', 'evolv', 'acaus', ''], ['acaus', '', '', 'acaus', ''], ['acaus', ''], ['our', 'evol', 'acaus', ''], ['']]\n",
      "[['we', 'spacetim', ''], ['antisymmetr', '', 'whose', 'inerti', '', 'translat', '', ''], ['thi', 'gravitoelectromagnet', ''], ['we', 'schwarzschild', 'spacetim', '', 'energymomentum', '', 'teleparallel', 'relatr', '', ''], ['thi', '', '']]\n",
      "[['we', 'supersymmetr', 'orbifold', 'e8', 'e8', 'heterot', 'superstr', '', 'phenomenolog', ''], ['', 'heterot', 'superstr', '', '', '', 'x527x10', '', '', 'gev', '', 'lep', '', '2x10', '', '', 'gev', '', '', 'higgs', 'vectorlik', ''], ['our', 'fayetiliopoulo', '', '', 'higg', '', 'fermion', 'renormaliz', 'lebel', ''], ['', '', ''], ['', 'flavourchang', 'fermion', 'higg', 'doublet', ''], ['we', '', 'higg', '']]\n",
      "[['s255n', 'farinfrar', 'mani', 'nearinfrar', ''], ['we', 'midinfrar', 'evolutionari', ''], ['our', '13mm', 'continuum', 'submillimet', '', 'vla', '36cm', 'continuum', '13cm', 'maser', '', 'irac', 'spitzer', ''], ['the', 'previouslyknown', 'uchii', 'g1925840041', '', 'multiconfigur', '36cm', ''], ['the', '13mm', 'continuum', '', '', '7000au', ''], ['the', 'msun', ''], ['the', 'centroid', '', 'sma1', '', '', '', '2800', '', 'uchii', 'hc3n', '', 'cn', '', 'dcn', ''], ['sma1', 'ch3oh', '', 'sio', '', 'h2co', ''], ['we', 'kinemat', 'sma1', '', 'newlydetect', 'maser', ''], ['midinfrar', '', 'evolutionari', ''], ['the', 'midinfrar', '', 'uchii', ''], ['sma1', 'maser', 'protostar', 'sma1', ''], ['our', 's255n', 'highmass', '']]\n",
      "[['we', 'recurs', '', 'delzant', ''], ['finit', '', '', '', '', 'finit', ''], ['the', 'algorithm', 'central', ''], ['']]\n",
      "[['we', 'ultrafast', 'nanocrystallographi', 'sizeselect', 'nanoparticl', '', '220', '', ''], ['', '', 'recrystal', 'fullprofil', 'subpicosecond', ''], ['ultrafast', 'photoinduc', '', 'nanoparticl', 'nonequilibrium', '', '', 'nonequilibrium', 'electronphonon', '', 'upon', '', 'debond', '', 'nanocryst', 'nanoliquid', ''], ['the', 'displas', 'premelt', 'crystalliquid', 'coexist', 'photomelt', 'recrystal', '', 'thermal', ''], ['the', 'thermodynam', 'nanoparticl', '']]\n",
      "[['', 'onedimension', ''], ['thi', '', 'optim', 'quasivari', 'inequ', ''], ['the', 'onedimension', 'major', '']]\n",
      "[['we', 'emph', '', '', '', 'traceless', ''], ['thi', '']]\n",
      "[['we', 'latetim', 'spheric', 'yangmil', 'schwarzschild', ''], ['nonlinear', '', '', '', '', 'timelik', ''], ['', 'thirdord', 'numer', '']]\n",
      "[['subgraph', 'hypercub', '', 'subgraph', ''], ['', 'although', '', ''], ['we', '', 'mediat', '', ''], ['we', 'mediat', ''], ['we', '', 'nonnecessarili', '', 'biject', '', '', 'onto', 'mediat', '']]\n",
      "[['we', 'whether', '', '', '1lambda', '', '', 'nonloc', 'causal', '', '', 'lesssim', '', '', ''], ['we', 'modelindepend', 'bogoliubovshirkov', 'causal', ''], ['we', '', '', '', '', ''], ['we', 'causal', 'causal', ''], ['we', ''], ['we', 'causal', '']]\n",
      "[['randallsundrum', 'brane', ''], ['to', 'randallsundrum', 'brane', 'brane', ''], ['the', 'brane', 'brane', ''], ['the', 'brane', ''], ['the', 'asymptot', ''], ['we', 'brane', 'brane', '']]\n",
      "[['', '', '', '', 'algebra', '', '', '', '', '', '', 'bbb', '', '', '', '', ''], ['we', 'either', '', 'hginb', '', '', 'fq1epq2', '', '', '', '', '', 'q1', '', 'q2', '', ''], ['', '', '', 'algebra', '', '', 'ep', '', '', '', '', '', '']]\n",
      "[['qp', 'gl', '', '', '', ''], ['when', 'admiss', '', 'irreduc', '', '', 'ginvari', ''], ['when', '', '', ''], ['prasad', ''], ['', 'other', '', '']]\n",
      "[['we', 'reduct', '']]\n",
      "[['we', 'd0d0bar', 'd0', '', 'timedepend', 'dalitz', ''], ['we', 'cp', 'cp', ''], ['the', '540', 'fb', '', '', '', '', '', 'bell', 'kekb', '', '', 'collid', ''], ['cp', '', '', '', '080pm029', '', '009', '010', '', '', '', '007', '014', '', '', '', '', '', '', '033pm024', '', '008', '006', '', '', '', '012', '008', '', '', '', '', '', 'statist', '', '', 'dalitz', '', ''], ['cp', '', '', 'cpv', '', '', 'qp086', '', '030', '006', '', '', '', '029', '003', '', 'pm008', '', '', 'arg', '', 'qp', '', '', '', '', '', '', '', '', '', 'circ', '', '']]\n",
      "[['diphoton', 'tevatron', 'lhc']]\n",
      "[['sparsitycertifi']]\n",
      "[['the', 'earthmoon']]\n",
      "[['stirl', 'singlesourc']]\n",
      "[['from', 'dyadic', '', '', '', '', '', '', '', '']]\n",
      "[['boson']]\n",
      "[['polym', 'continuum']]\n",
      "[[]]\n",
      "[['the', 'spitzer', 'c2d', '', '', 'insterstellar', ''], [''], ['the', 'serpen', 'yso', 'with', 'irac']]\n",
      "[['', '', '']]\n",
      "[['hilbertsiegel', 'modular', '', '', 'sqrt', '', '', '', '', 'via', 'jacquetlangland']]\n",
      "[['coeffici', 'modular', 'modulo']]\n",
      "[['', '', 'adic', 'holomorph', 'modular']]\n",
      "[[]]\n",
      "[['fermion', 'superstr', 'spinor']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['callia']]\n",
      "[['gr', '', 'obner']]\n",
      "[['hadron', 'd0', '', '', 'nue']]\n",
      "[['alloster', 'enzym']]\n",
      "[['stochast']]\n",
      "[['alma', 'solar', 'chromospher']]\n",
      "[['quasisoliton', 'ferromagnet']]\n",
      "[['polaron', 'carlo']]\n",
      "[['', 'metafract', '', 'boxkit', '', 'infinitedimension']]\n",
      "[['fillingfactordepend', 'magnetophonon', 'graphen']]\n",
      "[['pfaffian', '', 'hafnian', 'function']]\n",
      "[['nucleon', 'flavorspin', 'chiral']]\n",
      "[['electronphonon']]\n",
      "[['lhc', 'proton']]\n",
      "[['neutrino', 'supernova', 'neutrino']]\n",
      "[[''], [''], []]\n",
      "[['', '']]\n",
      "[[''], [''], []]\n",
      "[[]]\n",
      "[['the']]\n",
      "[['the', '', 'overview']]\n",
      "[[]]\n",
      "[['multilinear', 'condit']]\n",
      "[['noncommut', 'geometri']]\n",
      "[['', 'likequantum']]\n",
      "[['nonequilibrium']]\n",
      "[['astrophys', 'gyrokinet', '', 'collision']]\n",
      "[['undular', 'shallowwat']]\n",
      "[['per']]\n",
      "[['']]\n",
      "[['lisa']]\n",
      "[['fano', 'polytop']]\n",
      "[['']]\n",
      "[['teleport']]\n",
      "[[''], [''], ['spacetim']]\n",
      "[['finsler']]\n",
      "[['the', 'hardylorentz', '', '', '', '', '', '', '']]\n",
      "[['', 'waal', 'densityfunct']]\n",
      "[['gaussiancor', 'nemat']]\n",
      "[['highspin', 'lowspin', 'multiorbit']]\n",
      "[[]]\n",
      "[['the', 'mdwarf', 'singlelin', 'hattr205013']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['viterbi', 'random']]\n",
      "[['76ge', 'neutrinoless']]\n",
      "[['nilpot', 'superfield', '', '', '', 'abelian', '1form']]\n",
      "[['littlewoodrichardson']]\n",
      "[['lagrangian', ''], [''], []]\n",
      "[['epitaxi', 'selfassembl', '']]\n",
      "[['', '', '', '']]\n",
      "[['cohomolog']]\n",
      "[[]]\n",
      "[['pairwis', 'typolog', '', '']]\n",
      "[['the', 'integr', 'nonlinear', 'pde']]\n",
      "[['kollar', 'inject']]\n",
      "[['inject', 'morita', '', 'revisit', '']]\n",
      "[[]]\n",
      "[['cp']]\n",
      "[[]]\n",
      "[['spacetim', '']]\n",
      "[['algebra']]\n",
      "[['stellardynam']]\n",
      "[[]]\n",
      "[['matterwav', 'spinor', 'boseeinstein']]\n",
      "[['someth', '', 'everyth', '', '']]\n",
      "[['freeli', 'inelast', '']]\n",
      "[['ppwave']]\n",
      "[['stochast', 'onedimension']]\n",
      "[['dirichlet']]\n",
      "[['photon']]\n",
      "[['statist', '', 'nonparametr']]\n",
      "[['', 'rop', '']]\n",
      "[['finit', 'mani', 'conjugaci', 'automorph']]\n",
      "[['chiral', 'fermion']]\n",
      "[['electronphonon', 'selfenergi', 'angleresolv', 'photoemiss']]\n",
      "[['lens', '']]\n",
      "[['geometri']]\n",
      "[['248']]\n",
      "[['conform', 'algebra']]\n",
      "[['sparselyspread', 'cdma', '', 'statist']]\n",
      "[['ando', 'inequ', 'concav']]\n",
      "[[]]\n",
      "[['the']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['', '', '']]\n",
      "[['subset', 'symplect']]\n",
      "[['parton', '', 'quarkquark']]\n",
      "[[]]\n",
      "[['2sat']]\n",
      "[['halfmetal', 'nanowir']]\n",
      "[['equivari', '']]\n",
      "[['chern', '']]\n",
      "[['', 'bitstringdriven', '', '', 'infinitedimension', 'zerodivisor']]\n",
      "[['blodgett']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fourspin', 'antiferromagnet']]\n",
      "[['kcodimens']]\n",
      "[[]]\n",
      "[['counterrot', 'ion']]\n",
      "[['singlecryst', 'al2o3', 'layerbylay', '', '']]\n",
      "[['quasiquartet', 'tetragon', 'ceag', '', '', '', '']]\n",
      "[['', 'd0d0bar', '', 'besiii']]\n",
      "[['metast', 'brane']]\n",
      "[['spinor', 'dipolar', 'boseeinstein', '']]\n",
      "[['nonlinear', 'phonon', 'solidst', 'phaser']]\n",
      "[['jholomorph']]\n",
      "[['anisotrop', 'thermoelast', '', '']]\n",
      "[['mgb2']]\n",
      "[['sub100', 'nanodot']]\n",
      "[['swiftxrt', 'grb']]\n",
      "[['aubri']]\n",
      "[['modular', 'superalgebra']]\n",
      "[[]]\n",
      "[['counterflow']]\n",
      "[['pah', 'z256', 'cloverleaf', 'qso']]\n",
      "[['causal', 'dissip', 'qgp']]\n",
      "[['ion', 'timedepend', 'oscil']]\n",
      "[['their', 'trigintaduonion']]\n",
      "[['', '']]\n",
      "[['noncircular', 'horizonskim', 'kerr', 'spacetim']]\n",
      "[['the', 'm5']]\n",
      "[['twodimension', 'antid']]\n",
      "[['toward', 'selfconsist', 'instanton']]\n",
      "[['nonperturb', 'renorm', 'phi4']]\n",
      "[['instanton']]\n",
      "[[]]\n",
      "[['']]\n",
      "[['boseeinstein', '']]\n",
      "[['povm']]\n",
      "[['decoher', 'equationofmot']]\n",
      "[[]]\n",
      "[['thermodynam', 'spin12']]\n",
      "[[]]\n",
      "[['fermion']]\n",
      "[['oscil', 'halfintegr']]\n",
      "[['hadron', '']]\n",
      "[['nonlt', 'interstellar']]\n",
      "[['nonlinear', 'forcefre']]\n",
      "[['hardspher']]\n",
      "[[]]\n",
      "[['exciton', '1ttise', '', '', '', '', '']]\n",
      "[['oxygenrich', 'droplet']]\n",
      "[['nte', '', 'cn', '', 'raman']]\n",
      "[[]]\n",
      "[['quasicryst', 'abinitio']]\n",
      "[[]]\n",
      "[['frobeniusschur', 'semisimpl', 'algebra']]\n",
      "[['supersymmetri', 'metast']]\n",
      "[[]]\n",
      "[['radi']]\n",
      "[['axion']]\n",
      "[['disquisit', 'tiox']]\n",
      "[['pointlik', 'veryhighenergi', 'gammaray', 'monocero']]\n",
      "[['qubit', 'shastrysutherland']]\n",
      "[['zno']]\n",
      "[['reparametr', '', 'controversi', '', '', '', 'btopipi', '']]\n",
      "[['solar', 'gaussbonnet']]\n",
      "[['photochrom', 'diarylethen']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['nonclass', 'singlephotonad']]\n",
      "[['neutron']]\n",
      "[['photon', 'bandgap']]\n",
      "[['magnetocrystallin', 'anisotropi', 'xray', 'dichroism', 'cofemn', 'bilay']]\n",
      "[['', '', '']]\n",
      "[['gammaray', 'agn', 'glast']]\n",
      "[['potfit', '', 'abinitio']]\n",
      "[['neutrino', 'susi', '', 'neutrino', '']]\n",
      "[['the', 'toward', '23474342']]\n",
      "[['random']]\n",
      "[['monoid', 'richard']]\n",
      "[['the', 'neutrino', 'qel', 'superkamiokand']]\n",
      "[['intric', 'protein', '']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['decoher']]\n",
      "[['grouptheoret', 'nilpot', 'modular']]\n",
      "[[]]\n",
      "[['random', 'boolean']]\n",
      "[['polariton', 'raman', 'microcav']]\n",
      "[['coxet', 'noncross']]\n",
      "[['electromagnet', 'polariz', 'nucleon']]\n",
      "[['heckeclifford', 'algebra', 'heck', 'algebra', '']]\n",
      "[['toward', 'measurementbas']]\n",
      "[['spitzer', '348']]\n",
      "[['nonequilibrium', 'josephson', 'andreev', 'interact']]\n",
      "[['xray', 'pulsar', 'psr', 'j13576429']]\n",
      "[['bistabl']]\n",
      "[['astrophys', 'neutron']]\n",
      "[['nonbraid']]\n",
      "[['chandra', 'supernova', '1987a']]\n",
      "[['superpotenti']]\n",
      "[['linked']]\n",
      "[['isocurvatur', 'twofield']]\n",
      "[['', 'nonvanish', 'littlewoodrichardson', 'coeffici']]\n",
      "[['ptsymmetr']]\n",
      "[['the', 'asymptot', 'brownian']]\n",
      "[['initio', 'graphen']]\n",
      "[['multipleantenna', 'precod']]\n",
      "[['morphic']]\n",
      "[['the', '', 'xray', '', 'g328402', '', 'pulsar', '', 'neutron', '', 'supernova']]\n",
      "[[]]\n",
      "[['the']]\n",
      "[['']]\n",
      "[['magnetohydrodynam', 'supernova']]\n",
      "[['ion', ''], ['threeparticl']]\n",
      "[['glast']]\n",
      "[['redshift', 'continuum', 'ngc', '3783']]\n",
      "[['isotop']]\n",
      "[['', '', '', '']]\n",
      "[['', 'via', 'geometri']]\n",
      "[['basalt', 'asteroid', '']]\n",
      "[[]]\n",
      "[['perturb', 'nonperturb']]\n",
      "[['manybodi', 'interband', 'bosehubbard']]\n",
      "[['', 'gammaray', 'ghirlanda', ''], ['', '', 'et', ''], ['', 'astro', '', 'ph0703676', '']]\n",
      "[['the', 'helic', '', '', '', 'boson', 'lhc']]\n",
      "[['semiriemannian']]\n",
      "[['hydrodynam', 'hmxb']]\n",
      "[['astrometr', 'extrasolar', '', 'exoplanet']]\n",
      "[[]]\n",
      "[['', '']]\n",
      "[['superconduct', 'quasi2d', '', 'nonloc']]\n",
      "[['maser']]\n",
      "[['quasiparticl', 'antiferromagnet']]\n",
      "[['exactexchang', 'currentspindens', 'spindensityfunct']]\n",
      "[['oneloop', 'mhv', 'yangmil']]\n",
      "[['fermiliquid', 'transresist', '', 'nu', '']]\n",
      "[['geometri', 'fourdimension', 'spinor']]\n",
      "[['timedomain', '', 'electromagnet', '', '']]\n",
      "[['nonperturb', 'lutting']]\n",
      "[['2dmit', 'selfdop', 'wignermott']]\n",
      "[['subspac']]\n",
      "[['', '', '', 'mu', 'mu', '']]\n",
      "[['the', 'spitzer', 'c2d', '', '', 'interstellar', ''], ['serpen']]\n",
      "[['sbottom', 'cern', 'lhc']]\n",
      "[['threepoint']]\n",
      "[['multispectr', 'lunar', '', ''], ['the', 'afgl', '5440']]\n",
      "[['orbifold', 'cohomolog', 'abelian', 'symplect', 'project']]\n",
      "[['perturb', 'renorm']]\n",
      "[['collision']]\n",
      "[['polyharmon']]\n",
      "[['selfinteract', 'crosssect', '1e', '06575']]\n",
      "[['instanton', 'orbifold']]\n",
      "[[]]\n",
      "[['gluon', 'skyrmion', 'quarkgluon']]\n",
      "[['nearir', 'multiband', 'pks2155304', '2005']]\n",
      "[['supernova', 'iin']]\n",
      "[['nearinfrar', 'xray', '', 'a062000']]\n",
      "[[]]\n",
      "[['3c', '66a', 'webt', '2003', '', '2004']]\n",
      "[['the', 'extrasolar', ''], [''], ['', 'mearth', 'gj', '674']]\n",
      "[['']]\n",
      "[['anomal', '6cm', '', '', '', '', 'l1204s140']]\n",
      "[['dimer', ''], []]\n",
      "[['taylur', '', 'arbitraryord', 'fortran']]\n",
      "[[]]\n",
      "[['for', 'the', 'loopi', '', 'the', '']]\n",
      "[['leray', 'helli']]\n",
      "[['qdeform']]\n",
      "[['ngc', '1058']]\n",
      "[['redux']]\n",
      "[['the', 'astrophys', '', 'illpos', '']]\n",
      "[['spacetim']]\n",
      "[['temperley', '', 'lieb', 'algebra', '', '']]\n",
      "[['perturb', 'quasinorm', 'schwarzschild']]\n",
      "[['epitaxi', 'graphen']]\n",
      "[['thermoacoust']]\n",
      "[['gammaray', 'milagro']]\n",
      "[['bimod']]\n",
      "[['berezinskiikosterlitzthouless', 'twodimension', 'boseeinstein']]\n",
      "[['the']]\n",
      "[[]]\n",
      "[['seedless', 'infraredsaf']]\n",
      "[['isospin']]\n",
      "[['resumm', 'showerm', 'lhc']]\n",
      "[['parametr']]\n",
      "[['twistor', 'and', '', 'with', 'with', '', 'massless']]\n",
      "[['carbonoxygen']]\n",
      "[['banach']]\n",
      "[['parametr', 'postnewtonian', 'chernsimon']]\n",
      "[['singlewal']]\n",
      "[['recurs', 'differenti']]\n",
      "[['singleindex']]\n",
      "[[]]\n",
      "[['the']]\n",
      "[['microtubul', 'tubulin']]\n",
      "[['neutron', 'inelast', 'doublebeta']]\n",
      "[['circumbinari', 'uz', 'tau']]\n",
      "[[]]\n",
      "[['the', 'hcp', 'digrap']]\n",
      "[['vlbi', 'ghzpeakedspectrum']]\n",
      "[[]]\n",
      "[['']]\n",
      "[['gapless', 'onedimension']]\n",
      "[[]]\n",
      "[['the', 'manydimension', 'rarefact']]\n",
      "[['the', '', 'the', 'supermass', 'latetyp']]\n",
      "[['ricci']]\n",
      "[[]]\n",
      "[['spinorbit', 'mesoscop']]\n",
      "[['fraction']]\n",
      "[['metal', 'ferromagnet']]\n",
      "[['farfield', 'plankton']]\n",
      "[[]]\n",
      "[['pseudospectrum']]\n",
      "[['fluctuationdissip', 'meld', '', '', '']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['electroweak', 'mssm', '', '', '', '', '']]\n",
      "[['fraction', 'reactiondiffus', 'hfunction']]\n",
      "[['random', 'nonzero', '', 'mu', '', '', '']]\n",
      "[['', '', 'aminoacyl']]\n",
      "[['the', 'largescal', 'spacetim']]\n",
      "[['holsteintj', 'meanfield']]\n",
      "[['multiphil', 'select']]\n",
      "[[]]\n",
      "[['phonon', 'dimension']]\n",
      "[[]]\n",
      "[['modtc', 'zdtp', 'friction', 'tribofilm']]\n",
      "[['incompress', 'navierstok']]\n",
      "[['phononmedi', 'surfaceinduc']]\n",
      "[['']]\n",
      "[['cofibr', 'frolich', ''], []]\n",
      "[['colloid']]\n",
      "[['the', 'blazar', 'glast']]\n",
      "[[]]\n",
      "[['xray', 'suzaku']]\n",
      "[[]]\n",
      "[['what', '']]\n",
      "[['the', 'colin', '', 'ere', 'polytop']]\n",
      "[['']]\n",
      "[['firstbas', '', 'milliarcsecondscal']]\n",
      "[['hightemperatur', 'superconductor', 'hoba2cu3o7d']]\n",
      "[['pseudospin', 'spin12', 'spin0']]\n",
      "[['asymptot']]\n",
      "[['trigonometr', 'parallax']]\n",
      "[['amr', 'tw', 'barmod', 'neutron']]\n",
      "[['evolutionari', 'minim']]\n",
      "[['susi', '', '']]\n",
      "[['mongeamper', 'cegrel']]\n",
      "[['torsion']]\n",
      "[['pseudorandom', '', 'turbo']]\n",
      "[['the', 'revisit']]\n",
      "[['', '']]\n",
      "[['', '', 'rho', '', 'vectorvector']]\n",
      "[['phononmedi', 'superconduct', 'quasi2d']]\n",
      "[['nariai', 'yangtyp', 'monopol']]\n",
      "[['instanton', 'plebanski', ''], ['initit']]\n",
      "[['metalinsul', 'lowdimension', '', 'tmtsf', '', '2fso3', 'microspectroscopi']]\n",
      "[['the', 'topcolor', 'technicolor', '', '', 'neutrino']]\n",
      "[['without']]\n",
      "[['interact', 'neutrino', '', 'phenomenolog']]\n",
      "[['levylieb', 'constrainedsearch']]\n",
      "[[]]\n",
      "[['gravityinduc']]\n",
      "[['methan', 'premix', 'hydrocarbon', '', '', 'allen', 'propyn']]\n",
      "[['holonom']]\n",
      "[['the', 'electromagnet']]\n",
      "[['toeplitz']]\n",
      "[['polym']]\n",
      "[[]]\n",
      "[['the']]\n",
      "[['kneser']]\n",
      "[['the', 'mani']]\n",
      "[['', '', '', '', '', '', '', '', '', '', '', '', '', '']]\n",
      "[['supershel', 'ultracold']]\n",
      "[['nonloc', 'boseeinstein']]\n",
      "[['solar', '', 'the', 'hd141272']]\n",
      "[['neutrino', 'cng']]\n",
      "[['inspir', '', 'quadrupol']]\n",
      "[['billiard', '', 'fagnano']]\n",
      "[['electronnuclear']]\n",
      "[['cortic']]\n",
      "[['nanoparticl']]\n",
      "[['optim', 'risksensit']]\n",
      "[['', '', '', 'jpsi', '', '', '', '', '', 'pqcd']]\n",
      "[['finitetemperatur', 'twodimension', 'boson']]\n",
      "[['pathentangl']]\n",
      "[['exponenti', '']]\n",
      "[['dilaton']]\n",
      "[['the', 'smatrix', 'adscft', 'yangian']]\n",
      "[['nearir', 'supergiantdomin']]\n",
      "[['leastenergi', 'quasilinear']]\n",
      "[['']]\n",
      "[['to', 'fsi', '', 'btopipi', '', '', 'btorhorho', '']]\n",
      "[['semimartingal', 'brownian', 'piecewis']]\n",
      "[['drude', '1d']]\n",
      "[['hadron', 'neutron', 'neutron']]\n",
      "[['photoconduct', 'singlemolecul']]\n",
      "[['overbarri']]\n",
      "[['cyclotron', 'graphen', 'monolay']]\n",
      "[['graphen', 'nanoribbon']]\n",
      "[['abelian']]\n",
      "[['hadron', 'poledomin']]\n",
      "[['lefthand', 'slab']]\n",
      "[['nanoscal']]\n",
      "[['origami', 'veech']]\n",
      "[['', 'ruell']]\n",
      "[[]]\n",
      "[['superfluid', '', '', '', '', '', 'aerogel']]\n",
      "[['the', 'hourglass', '', 'hamiltonian']]\n",
      "[['the', 'sigmad', '']]\n",
      "[['microspher']]\n",
      "[['wimpnucleon', 'csi', '', '']]\n",
      "[['uu', '520', 'mevnucleon']]\n",
      "[['obey']]\n",
      "[['', 'photodissoci']]\n",
      "[['the', 'ise', 'ferromagnet']]\n",
      "[['bok', 'globul', 'cb54']]\n",
      "[['', '', '']]\n",
      "[['toric', 'coordinat', 'delzant']]\n",
      "[['quasitoroid', 'polytrop']]\n",
      "[['huebschmann', 'stasheff', '', 'via', 'hpt']]\n",
      "[['variat', 'electrodynam']]\n",
      "[['protein', '', 'inhibitor']]\n",
      "[['spacetim']]\n",
      "[['nonlinear', 'spinor']]\n",
      "[['', '', '', 'ell', 'nu', '', 'fd', '', '']]\n",
      "[['higg', 'boson', 'righthand', 'neutrino', 'electroweak']]\n",
      "[['anyon']]\n",
      "[['ferromagnet', 'boseeinstein']]\n",
      "[[]]\n",
      "[['electromagnet', 'xwave']]\n",
      "[['neutronneutron', '', '', 'nn', 'chiral']]\n",
      "[['orbifold', '']]\n",
      "[['', 'e8']]\n",
      "[['the', 'pgq1', 'isogen']]\n",
      "[['rotat', 'twocompon']]\n",
      "[['powerlaw']]\n",
      "[['worldsheet', 'instanton', '', '']]\n",
      "[['mottanderson']]\n",
      "[['electromigr', 'nanoscal', 'surfaceenhanc', 'raman']]\n",
      "[['xray', 'x1']]\n",
      "[['antiferromagnetismsuperconduct', 'electrondop', 'cuprat']]\n",
      "[['extrasolar', 'spacebas', 'microlens']]\n",
      "[['usco16061935', '', 'lowmass', '']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['extragalact', '', 'largescal']]\n",
      "[['pointsymmetr']]\n",
      "[['the', 'kilodegre', '', '', '', 'largearea']]\n",
      "[['notcompletelyposit']]\n",
      "[['solar', '', 'egret']]\n",
      "[['twa']]\n",
      "[['dileucin', 'peptid']]\n",
      "[['nonlinear', 'fokkerplanck']]\n",
      "[['spinlattic', 'mgb2', 'superconductor']]\n",
      "[['xray', 'continuum']]\n",
      "[['inapproxim', 'bicliqu']]\n",
      "[['3net']]\n",
      "[['midinfrar', 'visir', 'vlt']]\n",
      "[['', 'statist']]\n",
      "[['nucleat', 'pott', 'metast']]\n",
      "[['transformationbas']]\n",
      "[['ewald', 'longrang']]\n",
      "[['nontherm', 'softexcess', 'sersic', '15903']]\n",
      "[['adiabat']]\n",
      "[['the']]\n",
      "[['virial', 'm82', 'starburst']]\n",
      "[['the', 'picard']]\n",
      "[['interact', 'boson']]\n",
      "[['the']]\n",
      "[['holonom']]\n",
      "[['fuldeferrelllarkinovchinnikov', 'superconductor', 'quasiclass']]\n",
      "[[]]\n",
      "[['stoke', 'via', 'minimax', 'differenti']]\n",
      "[['kinemat', 'horizontalbranch']]\n",
      "[[]]\n",
      "[['teleparallel', 'axisymmetr']]\n",
      "[['ddimens', 'spinzero', 'noncentr', 'ringshap', 'kratzer']]\n",
      "[['axionlik']]\n",
      "[[]]\n",
      "[['reesse1', 'cryptosystem']]\n",
      "[['dynam']]\n",
      "[['superconductor', 'fractal']]\n",
      "[['the', 'veldkamp', 'twoqubit']]\n",
      "[['preequilibrium', 'hartreefock']]\n",
      "[['coeffici', 'lopatinski']]\n",
      "[['neutrino', 'toward', 'theta13']]\n",
      "[['decodeandforward']]\n",
      "[['automorph']]\n",
      "[['nonlinear', 'schr', '', 'oding', '', 'umbil', '', 'tritronque', '', 'painlev', '', 'ei']]\n",
      "[['', 'project', 'functor', 'fquad']]\n",
      "[['', 'tild', 'g2', '']]\n",
      "[['neutron']]\n",
      "[['einsteinyangmil', 'higherderiv']]\n",
      "[['cecoin', '', '']]\n",
      "[['e6', 'qutrit']]\n",
      "[['function']]\n",
      "[['dissip', 'stochast', 'lipschitz', 'nonlinear']]\n",
      "[['axino', '', 'omegab', '', '', '', '']]\n",
      "[['sicpovm', 'mub']]\n",
      "[['predatorprey', '', 'meanfield']]\n",
      "[['j233325921522221', 'polar']]\n",
      "[['', 'csat']]\n",
      "[['finitelength']]\n",
      "[['shor']]\n",
      "[[]]\n",
      "[['g2996002', 'subarcsecond']]\n",
      "[['hamiltonjacobi', 'fraction']]\n",
      "[[]]\n",
      "[['fraction']]\n",
      "[['', '', '', 'cbar', '', 'kstar', '', '', 'cbar', '', 'jpsi', '', '', '', 'chic1']]\n",
      "[[]]\n",
      "[['stochast']]\n",
      "[['energymomentum']]\n",
      "[['fraction', 'wkb']]\n",
      "[['toward', 'skyrmion', '', 'einsteinskyrm']]\n",
      "[['manytoon', 'throughput', 'ieee', '80211', 'multihop']]\n",
      "[['superconduct', 'betapyrochlor', 'kos2o6']]\n",
      "[['noncommut', 'supersymmetr', 'chiral']]\n",
      "[['', '', 'ds4']]\n",
      "[['transitionmet', 'quasicryst', 'aluminid']]\n",
      "[['xray', 'multiferro', 'tbmn2o5']]\n",
      "[['selfdiffus', 'interdiffus', 'al80ni20', '']]\n",
      "[['the', '', 'multimod']]\n",
      "[['', 'microquasar', 'glast']]\n",
      "[['linearis', 'abelian', 'cremona']]\n",
      "[['pentacen', 'vacuumdeposit']]\n",
      "[['noncentr', 'multivari']]\n",
      "[[]]\n",
      "[['subset']]\n",
      "[['grassmannian']]\n",
      "[['swiftxrt', 'supergi', 'xray', 'igr', 'j112155952']]\n",
      "[[]]\n",
      "[['kenzelmann']]\n",
      "[['superconduct']]\n",
      "[['midinfrar', 'spitzer', '']]\n",
      "[['neutrino']]\n",
      "[['nonintegr']]\n",
      "[['the']]\n",
      "[['the']]\n",
      "[['the', 'photospher', '']]\n",
      "[['', 'nonabelian', 'pseudogoldston', 'boson']]\n",
      "[['inmedium', 'ion']]\n",
      "[['the', 'erdosturan']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['mregular', 'fano']]\n",
      "[['spacetim', 'noncommut', '', '', '', 'renormaliz', 'thetaexpand', 'ncsm']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hyperfin', 'highlycharg', 'ion', '']]\n",
      "[['josephson']]\n",
      "[[]]\n",
      "[['without', ''], []]\n",
      "[['noncommut']]\n",
      "[['the', 'lifshitzslyozovwagn', 'reactioncontrol']]\n",
      "[['hermitian']]\n",
      "[['asymptot', 'onefactor']]\n",
      "[['thermal']]\n",
      "[['microfluid', 'droplet']]\n",
      "[['fermion', 'conform', 'correl']]\n",
      "[['', 'bztopippimpiz', '', 'dalitz', 'babar']]\n",
      "[['thermal', 'optoelectron', '']]\n",
      "[['elativist', '', '', '', '', 'spinzero', 'noncentr', 'ringshap', 'kratzer']]\n",
      "[['']]\n",
      "[['nonperturb', 'bertrand']]\n",
      "[['neutroncaptur', 'doubleenhanc', '13050007', '', 'rprocess']]\n",
      "[['m5brane']]\n",
      "[['photospher', 'supergranular']]\n",
      "[[]]\n",
      "[['isinglik', 'ultrafin']]\n",
      "[[]]\n",
      "[['']]\n",
      "[['kktheori', 'selfabsorb', '', 'algebra']]\n",
      "[['qdeform']]\n",
      "[['magnetospectroscopi', 'epitaxi', 'fewlay', 'graphen']]\n",
      "[['supernova', 'ejecta']]\n",
      "[['coeffici', 'nucleic', 'polyion']]\n",
      "[[]]\n",
      "[['', '', '', 'csw']]\n",
      "[['hermitian']]\n",
      "[['antiferromagnet', '', '', '', '', '']]\n",
      "[['gaasalgaa']]\n",
      "[['localfield', 'radi', 'magnetodielectr', '']]\n",
      "[['bquark', 'lepii', 'sqrt', '', '', '196209', 'gev']]\n",
      "[['', 'conform']]\n",
      "[['the', 'conform']]\n",
      "[['reconnect', 'ww', 'delphi', 'lep2']]\n",
      "[['evolutionari', '', 'eng', '', '']]\n",
      "[['xray', 'dichroism', 'pseudogap', 'cuprat']]\n",
      "[[]]\n",
      "[['dbar', 'higg', 'nonunitar']]\n",
      "[['chiral']]\n",
      "[['the', '', 'solar', 'photospher']]\n",
      "[['hightc', 'cs2agf4', 'muonspin']]\n",
      "[['', '3872', '', 'nearthreshold', 'd0bar', '', '', '', '', '', '']]\n",
      "[['threedimension', '', '', '', 'atomopt', 'oneway']]\n",
      "[['plasmon', 'graphen']]\n",
      "[['homolog', 'twodimension']]\n",
      "[['the']]\n",
      "[['nonloc']]\n",
      "[['rbfnn']]\n",
      "[['the']]\n",
      "[['anomal', 'caxi']]\n",
      "[['holomorph']]\n",
      "[['via', 'concensu']]\n",
      "[['hd', '163296', '', 'kinemat']]\n",
      "[['spectropolarimetr', '8498', '8542']]\n",
      "[['irreduc']]\n",
      "[['mssm', 'higg', 'boson', '', 'higgsmass']]\n",
      "[[]]\n",
      "[['cauchi', 'integr']]\n",
      "[['sextic']]\n",
      "[['anisotrop', 'hydrogenbond']]\n",
      "[['stepedg', 'electromigr']]\n",
      "[['renormgroup', 'higgsino']]\n",
      "[['wmap']]\n",
      "[['electromagnet', 'lightfront', 'qcdinspir']]\n",
      "[[]]\n",
      "[['', 'fd', '', '', '', '', '', '', 'ell', 'nu']]\n",
      "[['the', '', 'eto', 'pipi', '', '', '', 'pi0pi0', '', '', '', 'initialst']]\n",
      "[['hydrino']]\n",
      "[[]]\n",
      "[['dwave', 'superconduct', 'electronphonon']]\n",
      "[['protein']]\n",
      "[['nucleosynthesi', '']]\n",
      "[['sumoverst', 'quasiparticl', 'exciton', '', 'femtosecond', 'multidimension']]\n",
      "[['']]\n",
      "[['jpsi', '', '', 'ppbar', '196', 'tev']]\n",
      "[['nongaussian']]\n",
      "[['skewhadamard', '188', '388']]\n",
      "[['photon']]\n",
      "[['photon', 'dilepton', 'via']]\n",
      "[[]]\n",
      "[['homfli', 'tutt']]\n",
      "[['hd', '15115']]\n",
      "[['the']]\n",
      "[[]]\n",
      "[['avers', '', 'neurodynam']]\n",
      "[['']]\n",
      "[['bosonfermion']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['', 'st', '', 'uckelberg', 'interferometri', '', 'ultracold']]\n",
      "[['lymanalpha']]\n",
      "[['sloan']]\n",
      "[['optim']]\n",
      "[['the', 'heliospher', '', 'photoion', 'interstellar', 'situ']]\n",
      "[['ferromagnet']]\n",
      "[['gammaray', '']]\n",
      "[['multiscal']]\n",
      "[['subvarieti', 'ration', 'fibrat']]\n",
      "[['cohomolog']]\n",
      "[['decoher', 'quantumenhanc']]\n",
      "[['']]\n",
      "[['wellposed', 'energycrit', '', 'defocus', 'hartre']]\n",
      "[['superacceler']]\n",
      "[['unit', '', 'algebra']]\n",
      "[['jpsi', 'parton']]\n",
      "[[]]\n",
      "[['observ', '', '', '', '', '', 'rm', '', '', '', '', '', '296', 'mev', '', '', '', 'circ', '', '']]\n",
      "[[]]\n",
      "[['hamiltonian', 'friedmann']]\n",
      "[['via', 'suprathreshold', 'stochast']]\n",
      "[[]]\n",
      "[['protoneutron', '', 'magnetar', '', 'gammaray']]\n",
      "[['ob2']]\n",
      "[['postagb', 'hd56126', '40108790']]\n",
      "[['numberpath', 'feedforward']]\n",
      "[['painlev']]\n",
      "[['', '', '', '', '']]\n",
      "[['spatial', 'colloid']]\n",
      "[['circumstellar', 'sio', 'maser']]\n",
      "[['ferromagnet', 'mnsi']]\n",
      "[[]]\n",
      "[['chebyshev', 'poset']]\n",
      "[['statist']]\n",
      "[['dimension', 'micropolar']]\n",
      "[['asymptot', 'rotorrout', 'divis']]\n",
      "[['quasiperiod', 'lowmass', 'xray']]\n",
      "[['fuzzbal']]\n",
      "[['', 'carlo']]\n",
      "[['twoband', 'superconduct']]\n",
      "[['geometri', 'atomics']]\n",
      "[['', '', '', 'superconductor']]\n",
      "[['photon']]\n",
      "[['phonon']]\n",
      "[['cp', 'multi', 'froggattnielsen']]\n",
      "[['adiabat']]\n",
      "[['norbornan', '', 'bicyclo', '', '221', '', 'heptan', '', ''], []]\n",
      "[['cycloalkan', 'cbsqb3']]\n",
      "[['', 'ytterbiumdop']]\n",
      "[['conduct', 'nanowir']]\n",
      "[['plasmon', 'polariton', 'subwavelength']]\n",
      "[['entrop', 'wasserstein']]\n",
      "[['secondord', 'eikon', '', '', '', '']]\n",
      "[['akari', 'infraredbright', 'supernova', 'b0104723', 'magellan']]\n",
      "[['floryhuggin', 'heterogeneouslymodifi', 'polym']]\n",
      "[[]]\n",
      "[['']]\n",
      "[['photoproduct', 'pi0', 'proton', '', '', '', 'gev']]\n",
      "[['twopion', 'threenucleon', '', '', 'q4', '', 'chiral']]\n",
      "[['abovethreshold', 'diatom', '', 'internuclear']]\n",
      "[['twodimension', 's12']]\n",
      "[['ricci', '4manifold']]\n",
      "[['dimer']]\n",
      "[[]]\n",
      "[['incommmensur', 'superconductor', 'bondcharg']]\n",
      "[['astrophys', 'neutrino']]\n",
      "[['']]\n",
      "[['', '', 'lohner']]\n",
      "[['seyfert', 'ngc', '3783']]\n",
      "[['threepoint', 'twodimension', 'landaugaug', 'yangmil']]\n",
      "[['phonon', 'onedimension']]\n",
      "[['spinorbit', 'magnetoresist', 'twodimension', 'antidot']]\n",
      "[[]]\n",
      "[['longrang', 'multifract']]\n",
      "[['qubit', 'coplanar']]\n",
      "[[]]\n",
      "[['the', 'kaluzaklein']]\n",
      "[['revisit', 'netflow']]\n",
      "[['the', 'skyrm', ''], []]\n",
      "[['gravitycoset']]\n",
      "[[]]\n",
      "[['gro', 'j165540', '', 'asca', 'xmmnewton']]\n",
      "[['the', 'hellas2xmm', ''], [''], ['the', 'bolometr', '', 'the', 'spitzer']]\n",
      "[['', '', 'adic', 'haar', 'multiresolut']]\n",
      "[['', 'compactif']]\n",
      "[['versu']]\n",
      "[['lehmann']]\n",
      "[['mond']]\n",
      "[['altshuleraronov']]\n",
      "[['magnetoconduct', 'decoher', 'electronelectron']]\n",
      "[['diatom']]\n",
      "[[]]\n",
      "[['stochast']]\n",
      "[['machzehnd', 'interferomet']]\n",
      "[['higherord']]\n",
      "[['axionlik', 'nonlinear', 'electrodynam']]\n",
      "[['testb']]\n",
      "[['', '']]\n",
      "[['hyperbol']]\n",
      "[['boson', 'worldsheet']]\n",
      "[['bianchi', 'barotrop']]\n",
      "[[]]\n",
      "[['kth']]\n",
      "[['the', 'casimir', 'braneworld']]\n",
      "[[]]\n",
      "[['photon']]\n",
      "[[]]\n",
      "[['', 'longliv', 'photon', 'cdf']]\n",
      "[['workhamiltonian']]\n",
      "[['selfavoid', 'interact']]\n",
      "[[]]\n",
      "[['ferromagnet', 'spin12']]\n",
      "[['spatial', 'inhomog', 'disordertun', 'superconductorinsul']]\n",
      "[['brogliebohm', 'wavefunct']]\n",
      "[['groundbas', 'microlens']]\n",
      "[['the', 'seyfert', 'ngc', '7679', '', '', '5007']]\n",
      "[['the', 'fermion', 'densityfunct', 'feshbach']]\n",
      "[[]]\n",
      "[['1f', 'onequbit']]\n",
      "[['coloc', 'incompress', 'navierstok']]\n",
      "[[]]\n",
      "[['abel', '901902', 'superclust', 'combo17']]\n",
      "[['k0theori', 'npotent', 'algebra']]\n",
      "[[]]\n",
      "[['supergrav', 'superstr']]\n",
      "[['frobeniu', 'geometri', '', '']]\n",
      "[['of', 'synchrotronself', '', 'and', 'how', 'we']]\n",
      "[['radioact', '', '', '', '132', '', '', '', '', '', '', '']]\n",
      "[['trilay', 'superlattic', '', 'magnetoelectr', 'multiferro', '']]\n",
      "[[]]\n",
      "[['incompress']]\n",
      "[['dbrane', 'instanton', 't6z3', 'orientifold']]\n",
      "[['viscoplast', 'tribolog', 'diamondlik', 'nanoindent', 'nanoscratch']]\n",
      "[['d0', 'cpviolat', 'd0bar', 'd0']]\n",
      "[['incompress']]\n",
      "[[]]\n",
      "[['sdssi', '', '']]\n",
      "[['casimir', 'graviton', 'braneworld']]\n",
      "[['grb']]\n",
      "[['the', 'kennicuttschmidt']]\n",
      "[['friedmann', 'thermodynam']]\n",
      "[['xray', 'calorimetri']]\n",
      "[['heavylight', 'semilepton', 'chiral']]\n",
      "[['']]\n",
      "[['selfforc', 'schwarzschild', 'spacetim', '', 'timedomain']]\n",
      "[['nonimmers', 'rpn', 'tmf', '', 'revisit']]\n",
      "[['neutron', '', 'nonlinear', 'rmode']]\n",
      "[[]]\n",
      "[['nonellipt']]\n",
      "[['hybridarq', 'multihop']]\n",
      "[['superconduct']]\n",
      "[['equationfre', 'statist']]\n",
      "[[]]\n",
      "[['the', 'sloan', ''], []]\n",
      "[['chiral']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['the', '', 'cofe', '', '', 'balloonborn']]\n",
      "[['xray']]\n",
      "[['the', 'latetyp']]\n",
      "[['boseeinstein']]\n",
      "[['photon', 'quasicharg']]\n",
      "[['oscil']]\n",
      "[['ergospher', 'poynt']]\n",
      "[['s3symmetr', 'littlewoodrichardson']]\n",
      "[['twoscal', 'collisionless', 'reconnect']]\n",
      "[['positionveloc', 'maser', 'keplerian']]\n",
      "[['whisperinggalleri', 'sizemismatch', 'microdisk', 'photon']]\n",
      "[['antiferromagnet']]\n",
      "[[]]\n",
      "[['chromospher']]\n",
      "[['', '', '', 'maurercartan']]\n",
      "[['superconductor', 'bilay']]\n",
      "[['silic', 'lymanalpha', 'absorb', 'z052']]\n",
      "[['photometri', 'ngc', '5466', '']]\n",
      "[['kagom']]\n",
      "[['quarkantiquark', 'diquark', 'twoflavor', 'grossneveu']]\n",
      "[['nonabelian', 'aharonovbohm']]\n",
      "[['random']]\n",
      "[['multistar']]\n",
      "[['wellposed', 'nonlinear']]\n",
      "[['padic']]\n",
      "[['xray', 'gammaray']]\n",
      "[['matroidfriendli', 'quasisymmetr']]\n",
      "[['bremsstrahlung']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['higg', 'boson', 'lhc']]\n",
      "[['difermion', '24d', 'fourfermion']]\n",
      "[['']]\n",
      "[['kadowakiwood']]\n",
      "[['superconduct']]\n",
      "[['entrop', 'superconduct', 'microcool']]\n",
      "[['qskew']]\n",
      "[['semispheroid', 'oscil']]\n",
      "[['decagon', 'quasicryst']]\n",
      "[['bianchi', 'typev', 'with', '', '']]\n",
      "[['spin12', 'xxz', '', '']]\n",
      "[[]]\n",
      "[['boseeinstein', 'photon', 'auau', '', 'sqrt', '', '', 'nn', '', '', '', '', 'gev']]\n",
      "[['ricci', 'nonparabol']]\n",
      "[['subwavelength']]\n",
      "[[]]\n",
      "[['radi']]\n",
      "[['extrasolar', '5d', '', '', 'r2graviti']]\n",
      "[['deploy', 'highinteract']]\n",
      "[['transfinit', '', 'chebyshev']]\n",
      "[['sunossolari', 'syslogd', 'wtmpx', 'logfil', '']]\n",
      "[['statist']]\n",
      "[['the', 'zw']]\n",
      "[['uvupturn', '', 'mnra', '']]\n",
      "[['gammaray']]\n",
      "[['architecturebas', 'aadl']]\n",
      "[['priori', 'mongeamp', '', 'ere']]\n",
      "[['tunabl']]\n",
      "[['electronelectron', 'phononmedi']]\n",
      "[[]]\n",
      "[[]]\n",
      "[['the', 'idv', 'j11285925', '', '']]\n",
      "[['selfadjoint']]\n",
      "[['exoplanetari']]\n",
      "[[]]\n",
      "[['the', '', 'repunit']]\n",
      "[['nonmonoton', 'wasserstein']]\n",
      "[['the', 'bimod', 'supernova']]\n",
      "[['substitut', 'cr3', 'mgal2o4']]\n",
      "[['cachebas']]\n",
      "[['stochast']]\n",
      "[[]]\n",
      "[['dgp', 'chaplygin']]\n",
      "[['gaugehigg', 'lhcilc']]\n",
      "[['sakai', 'holomorph', 'meromorph']]\n",
      "[['countabl']]\n",
      "[[]]\n",
      "[['nonextens', 'thermodynam', '1d', 'longrang']]\n",
      "[['boseeinstein', 'bacusi', '', '', '', '']]\n",
      "[['bibliometr', 'statist', '']]\n",
      "[['supernova']]\n",
      "[['neutrino']]\n",
      "[['nonstationari', 'unsynchroniz']]\n",
      "[['spinorbit']]\n",
      "[['the', 'solar', ''], [''], []]\n",
      "[['gorenstein']]\n",
      "[['random', 'anisotropi']]\n",
      "[['holomorph']]\n",
      "[['algebra']]\n",
      "[['calfus', 'v3', '', 'datareduct']]\n",
      "[['voltagecurr', 'josephson']]\n",
      "[['the']]\n",
      "[['bandstructur', 'versu', 'vo2']]\n",
      "[['', 'fractal']]\n",
      "[['the', 'allski', '', 'glast']]\n",
      "[['dielectron', '']]\n",
      "[['equienergi']]\n",
      "[['highfrequ']]\n",
      "[['extragalact', 'wmap']]\n",
      "[['l2', 'rho']]\n",
      "[['nontrivi', 'involut', 'nhomomorph', '', 'algebra']]\n",
      "[['starburst', 'tidal']]\n",
      "[[]]\n",
      "[['']]\n",
      "[['electromagnet', 'wormhol', 'via', 'handlebodi']]\n",
      "[['millimeterthick', 'singlewal', '']]\n",
      "[['hauserfeshbach']]\n",
      "[['the', 'extrasolar', ''], [''], ['exoplanet', 'hd', '100777', '', 'hd', '190647', '', 'hd', '221287']]\n",
      "[['geometri', 'gaussian', 'bayesian']]\n",
      "[['', 'superconduct', '', '', '', 'gaussian']]\n",
      "[['twoproton', 'threebodi', ''], [''], ['semianalyt']]\n",
      "[['z0', '2gamma', 'coproduct', 'poincar', '', '', '']]\n",
      "[['gronwal']]\n",
      "[['when', 'cramerrao', 'inequ']]\n",
      "[['1level', 'holomorph', 'newform']]\n",
      "[['spinor', 'antiferromagnet', 'spin1']]\n",
      "[['stochast', 'increment']]\n",
      "[['symplect', 'lfunction']]\n",
      "[[]]\n",
      "[['noncommut']]\n",
      "[['superstr']]\n",
      "[['the', 'isophot', 'earlytyp', '', 'agn']]\n",
      "[['earlytyp', '', 'the', 'agn']]\n",
      "[['spatial', 'kagom', '', 'volborthit']]\n",
      "[['twoproton', 'threebodi', ''], [''], ['quasiclass']]\n",
      "[['conduct', 'selfheal']]\n",
      "[['superstr']]\n",
      "[['invari', 'algebra']]\n",
      "[[]]\n",
      "[['blazar', 'gammaray', ''], ['egret']]\n",
      "[['gluebal', '', '', 'anisotrop', 'weaklycoupl', 'yangmil']]\n",
      "[['metal']]\n",
      "[['c2', 'postcrit']]\n",
      "[['gravitationalwav', 'ligo']]\n",
      "[['glast']]\n",
      "[[]]\n",
      "[['reioniz']]\n",
      "[['jetdisturb', 'seyfert', 'm51']]\n",
      "[[]]\n",
      "[['function']]\n",
      "[[]]\n",
      "[['random']]\n",
      "[['sim', 'planetquest', '', 'the', 'nearterm', '', '', 'threedimension']]\n",
      "[['105403', '']]\n",
      "[['random', '', 'consensu']]\n",
      "[[]]\n",
      "[['nodeless', 'dwave', 'superconduct', 'antiferromagnet', 'underdop', '', '', '', '2x', '', '', '', '', 'cuo', '', '', '', '4delta', '', '']]\n",
      "[['onedimension', 'brownian']]\n",
      "[['blazar', 'pks0537441', '2005']]\n",
      "[['pentaquark']]\n",
      "[['nanomechan']]\n",
      "[['09221333']]\n",
      "[['the', 'einsteinvaricak']]\n",
      "[['nova', 'geminorum', '1912', 'lens']]\n",
      "[['hamiltonian']]\n",
      "[['separ', 'multipartit']]\n",
      "[['twoparticl', 'pp', '', 'sqrt', '', '', '', '', '410', 'gev']]\n",
      "[['crosslay', 'mimobas', 'gaussian']]\n",
      "[['microlens']]\n",
      "[['the', 'suffici', 'separ']]\n",
      "[['protoplanetari']]\n",
      "[['d0antid0', 'cp', 'd0', 'antid0', '', '', '', '', '', '', '']]\n",
      "[['the']]\n",
      "[['xray', 'psr', 'j19301852', 'crablik', 'snr', 'g54103']]\n",
      "[['vortexinduc', 'bilinearbiquadrat', 'antiferromagnet']]\n",
      "[['portevinl', 'chateli']]\n",
      "[[]]\n",
      "[['anomal', 'singlewal']]\n",
      "[['b0218357']]\n",
      "[['neutrino', 'extragalact']]\n",
      "[['ina']]\n",
      "[['selfsimilar', ''], []]\n",
      "[['', 'their', 'celestialmechan']]\n",
      "[['isospin', 'i52']]\n",
      "[['polariton', 'qubit']]\n",
      "[['acaus', 'evolv']]\n",
      "[['spacetim', 'freeli']]\n",
      "[['phenomenolog', '']]\n",
      "[['protoclust', 's255n']]\n",
      "[[]]\n",
      "[['sizeselect', 'nanoparticl', 'ultrafast', 'nanocrystallographi']]\n",
      "[['onedimension']]\n",
      "[['']]\n",
      "[['latetim', 'yangmil', 'schwarzschild']]\n",
      "[['mediat']]\n",
      "[['causal']]\n",
      "[['brane']]\n",
      "[['algebra']]\n",
      "[['trilinear', '', 'unramifi']]\n",
      "[[]]\n",
      "[['d0d0bar', 'd0', '']]\n"
     ]
    }
   ],
   "source": [
    "num_processes = 100\n",
    "\n",
    "df['abstract_new'] = df['abstract'].apply(preprocess)\n",
    "df['title_new'] = df['title'].apply(preprocess)\n",
    "\n",
    "df = df[df['abstract_new'].apply(lambda x: len(x) > 0)]\n",
    "df = df[df['title_new'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435708d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb5cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653d7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59dec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0001',\n",
       " 'submitter': 'Pavel Nadolsky',\n",
       " 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       " 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       " 'comments': '37 pages, 15 figures; published version',\n",
       " 'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
       " 'doi': '10.1103/PhysRevD.76.013009',\n",
       " 'report-no': 'ANL-HEP-PR-07-12',\n",
       " 'categories': 'hep-ph',\n",
       " 'license': None,\n",
       " 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       " 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
       "  {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
       " 'update_date': '2008-11-26',\n",
       " 'authors_parsed': [['Balázs', 'C.', ''],\n",
       "  ['Berger', 'E. L.', ''],\n",
       "  ['Nadolsky', 'P. M.', ''],\n",
       "  ['Yuan', 'C. -P.', '']]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e348fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83961b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_phrases = [\"the paper describes\", \"in conclusion\", \"in summary\", \"our investigation\", \"the best\", \"the most important\", \"in particular\", \"according to the study\", \"significantly\", \"important\", \"hardly\", \"impossible\"]\n",
    "\n",
    "sentences = []\n",
    "def clean(preprocessed_text):\n",
    "    cleaned_sentences = \"\"\n",
    "    for i in preprocessed_text:\n",
    "        mid = \"\"\n",
    "        for j in i:\n",
    "            if j == '':\n",
    "                continue\n",
    "            else:\n",
    "                mid += j\n",
    "                mid += \" \"\n",
    "        cleaned_sentences += mid\n",
    "        cleaned_sentences += \" \"\n",
    "    sentences.append(cleaned_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba7497f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "efee34c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['addit',\n",
       "  'model',\n",
       "  'provid',\n",
       "  'an',\n",
       "  'import',\n",
       "  'famili',\n",
       "  'of',\n",
       "  'model',\n",
       "  'for',\n",
       "  'semiparametr',\n",
       "  'regress',\n",
       "  'or',\n",
       "  'classif',\n",
       "  'some',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'the',\n",
       "  'success',\n",
       "  'of',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'are',\n",
       "  'their',\n",
       "  'increas',\n",
       "  'flexibl',\n",
       "  'when',\n",
       "  'compar',\n",
       "  'to',\n",
       "  'linear',\n",
       "  'or',\n",
       "  'gener',\n",
       "  'linear',\n",
       "  'model',\n",
       "  'and',\n",
       "  'their',\n",
       "  'increas',\n",
       "  'interpret',\n",
       "  'when',\n",
       "  'compar',\n",
       "  'to',\n",
       "  'fulli',\n",
       "  'nonparametr',\n",
       "  'model'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'well',\n",
       "  'known',\n",
       "  'that',\n",
       "  'good',\n",
       "  'estim',\n",
       "  'in',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'are',\n",
       "  'in',\n",
       "  'gener',\n",
       "  'less',\n",
       "  'prone',\n",
       "  'to',\n",
       "  'the',\n",
       "  'curs',\n",
       "  'of',\n",
       "  'high',\n",
       "  'dimension',\n",
       "  'than',\n",
       "  'good',\n",
       "  'estim',\n",
       "  'in',\n",
       "  'fulli',\n",
       "  'nonparametr',\n",
       "  'model'],\n",
       " ['mani',\n",
       "  'exampl',\n",
       "  'of',\n",
       "  'such',\n",
       "  'estim',\n",
       "  'belong',\n",
       "  'to',\n",
       "  'the',\n",
       "  'larg',\n",
       "  'class',\n",
       "  'of',\n",
       "  'regular',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'method',\n",
       "  'over',\n",
       "  'a',\n",
       "  'reproduc',\n",
       "  'kernel',\n",
       "  'hilbert',\n",
       "  'space',\n",
       "  'see',\n",
       "  'e',\n",
       "  'g',\n",
       "  'in',\n",
       "  'the',\n",
       "  'last',\n",
       "  'year'],\n",
       " ['mani',\n",
       "  'interest',\n",
       "  'result',\n",
       "  'on',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'regular',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'model',\n",
       "  'for',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'have',\n",
       "  'been',\n",
       "  'publish',\n",
       "  'when',\n",
       "  'the',\n",
       "  'focu',\n",
       "  'is',\n",
       "  'on',\n",
       "  'sparsiti',\n",
       "  'and',\n",
       "  'when',\n",
       "  'the',\n",
       "  'classic',\n",
       "  'least',\n",
       "  'squar',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'is',\n",
       "  'use',\n",
       "  'see',\n",
       "  'e',\n",
       "  'g',\n",
       "  'and',\n",
       "  'the',\n",
       "  'refer',\n",
       "  'therein',\n",
       "  'of',\n",
       "  'cours',\n",
       "  'the',\n",
       "  'least',\n",
       "  'squar',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'is',\n",
       "  'differenti',\n",
       "  'and',\n",
       "  'ha',\n",
       "  'mani',\n",
       "  'nice',\n",
       "  'mathemat',\n",
       "  'properti',\n",
       "  'but',\n",
       "  'it',\n",
       "  'is',\n",
       "  'onli',\n",
       "  'local',\n",
       "  'lipschitz',\n",
       "  'continu',\n",
       "  'and',\n",
       "  'therefor',\n",
       "  'regular',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'method',\n",
       "  'base',\n",
       "  'on',\n",
       "  'thi',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'typic',\n",
       "  'suffer',\n",
       "  'on',\n",
       "  'bad',\n",
       "  'statist',\n",
       "  'robust',\n",
       "  'properti',\n",
       "  'even',\n",
       "  'if',\n",
       "  'the',\n",
       "  'kernel',\n",
       "  'is',\n",
       "  'bound'],\n",
       " ['thi',\n",
       "  'is',\n",
       "  'in',\n",
       "  'sharp',\n",
       "  'contrast',\n",
       "  'to',\n",
       "  'kernel',\n",
       "  'method',\n",
       "  'base',\n",
       "  'on',\n",
       "  'a',\n",
       "  'lipschitz',\n",
       "  'continu',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'and',\n",
       "  'on',\n",
       "  'a',\n",
       "  'bound',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'where',\n",
       "  'result',\n",
       "  'on',\n",
       "  'upper',\n",
       "  'bound',\n",
       "  'for',\n",
       "  'the',\n",
       "  'maxbia',\n",
       "  'bia',\n",
       "  'and',\n",
       "  'on',\n",
       "  'a',\n",
       "  'bound',\n",
       "  'influenc',\n",
       "  'function',\n",
       "  'are',\n",
       "  'known',\n",
       "  'see',\n",
       "  'e',\n",
       "  'g',\n",
       "  'for',\n",
       "  'the',\n",
       "  'gener',\n",
       "  'case',\n",
       "  'and',\n",
       "  'for',\n",
       "  'addit',\n",
       "  'model'],\n",
       " ['therefor',\n",
       "  'we',\n",
       "  'will',\n",
       "  'here',\n",
       "  'consid',\n",
       "  'the',\n",
       "  'case',\n",
       "  'of',\n",
       "  'regular',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'method',\n",
       "  'base',\n",
       "  'on',\n",
       "  'a',\n",
       "  'gener',\n",
       "  'convex',\n",
       "  'and',\n",
       "  'lipschitz',\n",
       "  'continu',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'on',\n",
       "  'a',\n",
       "  'gener',\n",
       "  'kernel',\n",
       "  'and',\n",
       "  'on',\n",
       "  'the',\n",
       "  'classic',\n",
       "  'regular',\n",
       "  'term',\n",
       "  'for',\n",
       "  'some',\n",
       "  'which',\n",
       "  'is',\n",
       "  'a',\n",
       "  'smooth',\n",
       "  'penalti',\n",
       "  'but',\n",
       "  'not',\n",
       "  'a',\n",
       "  'sparsiti',\n",
       "  'penalti',\n",
       "  'see',\n",
       "  'e',\n",
       "  'g'],\n",
       " ['such',\n",
       "  'regular',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'method',\n",
       "  'are',\n",
       "  'now',\n",
       "  'often',\n",
       "  'call',\n",
       "  'support',\n",
       "  'vector',\n",
       "  'machin',\n",
       "  'svm',\n",
       "  'although',\n",
       "  'the',\n",
       "  'notat',\n",
       "  'wa',\n",
       "  'histor',\n",
       "  'use',\n",
       "  'for',\n",
       "  'such',\n",
       "  'method',\n",
       "  'base',\n",
       "  'on',\n",
       "  'the',\n",
       "  'special',\n",
       "  'hing',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'and',\n",
       "  'for',\n",
       "  'special',\n",
       "  'kernel',\n",
       "  'onli',\n",
       "  'we',\n",
       "  'refer',\n",
       "  'to',\n",
       "  'in',\n",
       "  'thi',\n",
       "  'paper',\n",
       "  'we',\n",
       "  'address',\n",
       "  'the',\n",
       "  'open',\n",
       "  'question',\n",
       "  'whether',\n",
       "  'an',\n",
       "  'svm',\n",
       "  'with',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'can',\n",
       "  'provid',\n",
       "  'a',\n",
       "  'substanti',\n",
       "  'better',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'high',\n",
       "  'dimens',\n",
       "  'than',\n",
       "  'an',\n",
       "  'svm',\n",
       "  'with',\n",
       "  'a',\n",
       "  'gener',\n",
       "  'kernel',\n",
       "  'say',\n",
       "  'a',\n",
       "  'classic',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel',\n",
       "  'if',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'of',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'is',\n",
       "  'satisfi'],\n",
       " ['our',\n",
       "  'lead',\n",
       "  'exampl',\n",
       "  'cover',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'base',\n",
       "  'on',\n",
       "  'the',\n",
       "  'lipschitz',\n",
       "  'continu',\n",
       "  'but',\n",
       "  'non',\n",
       "  'differenti',\n",
       "  'pinbal',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'which',\n",
       "  'is',\n",
       "  'also',\n",
       "  'call',\n",
       "  'check',\n",
       "  'function',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'see',\n",
       "  'e',\n",
       "  'g',\n",
       "  'and',\n",
       "  'for',\n",
       "  'parametr',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'and',\n",
       "  'and',\n",
       "  'for',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'quantil',\n",
       "  'regress'],\n",
       " ['we',\n",
       "  'will',\n",
       "  'not',\n",
       "  'address',\n",
       "  'the',\n",
       "  'question',\n",
       "  'how',\n",
       "  'to',\n",
       "  'check',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'of',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'is',\n",
       "  'satisfi',\n",
       "  'becaus',\n",
       "  'thi',\n",
       "  'would',\n",
       "  'be',\n",
       "  'a',\n",
       "  'topic',\n",
       "  'of',\n",
       "  'a',\n",
       "  'paper',\n",
       "  'of',\n",
       "  'it',\n",
       "  'own'],\n",
       " ['of',\n",
       "  'cours',\n",
       "  'a',\n",
       "  'practic',\n",
       "  'approach',\n",
       "  'might',\n",
       "  'be',\n",
       "  'to',\n",
       "  'fit',\n",
       "  'both',\n",
       "  'model',\n",
       "  'and',\n",
       "  'compar',\n",
       "  'their',\n",
       "  'risk',\n",
       "  'evalu',\n",
       "  'for',\n",
       "  'test',\n",
       "  'data'],\n",
       " ['for',\n",
       "  'the',\n",
       "  'same',\n",
       "  'reason',\n",
       "  'we',\n",
       "  'will',\n",
       "  'also',\n",
       "  'not',\n",
       "  'cover',\n",
       "  'sparsiti'],\n",
       " ['consist',\n",
       "  'of',\n",
       "  'support',\n",
       "  'vector',\n",
       "  'machin',\n",
       "  'gener',\n",
       "  'by',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'for',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'wa',\n",
       "  'consid',\n",
       "  'in',\n",
       "  'in',\n",
       "  'thi',\n",
       "  'paper'],\n",
       " ['we', 'establish', 'learn', 'rate', 'for', 'these', 'algorithm'],\n",
       " ['let',\n",
       "  'us',\n",
       "  'recal',\n",
       "  'the',\n",
       "  'framework',\n",
       "  'with',\n",
       "  'a',\n",
       "  'complet',\n",
       "  'separ',\n",
       "  'metric',\n",
       "  'space',\n",
       "  'as',\n",
       "  'the',\n",
       "  'input',\n",
       "  'space',\n",
       "  'and',\n",
       "  'a',\n",
       "  'close',\n",
       "  'subset',\n",
       "  'of',\n",
       "  'as',\n",
       "  'the',\n",
       "  'output',\n",
       "  'space'],\n",
       " ['a',\n",
       "  'borel',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'on',\n",
       "  'is',\n",
       "  'use',\n",
       "  'to',\n",
       "  'model',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'problem',\n",
       "  'and',\n",
       "  'an',\n",
       "  'independ',\n",
       "  'and',\n",
       "  'ident',\n",
       "  'distribut',\n",
       "  'sampl',\n",
       "  'is',\n",
       "  'drawn',\n",
       "  'accord',\n",
       "  'to',\n",
       "  'for',\n",
       "  'learn'],\n",
       " ['a',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'is',\n",
       "  'use',\n",
       "  'to',\n",
       "  'measur',\n",
       "  'the',\n",
       "  'qualiti',\n",
       "  'of',\n",
       "  'a',\n",
       "  'predict',\n",
       "  'function',\n",
       "  'by',\n",
       "  'the',\n",
       "  'local',\n",
       "  'error'],\n",
       " ['_',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'paper',\n",
       "  'we',\n",
       "  'assum',\n",
       "  'that',\n",
       "  'is',\n",
       "  'measur',\n",
       "  'convex',\n",
       "  'with',\n",
       "  'respect',\n",
       "  'to',\n",
       "  'the',\n",
       "  'third',\n",
       "  'variabl',\n",
       "  'and',\n",
       "  'uniformli',\n",
       "  'lipschitz',\n",
       "  'continu',\n",
       "  'satisfi',\n",
       "  'with',\n",
       "  'a',\n",
       "  'finit',\n",
       "  'constant'],\n",
       " ['_',\n",
       "  'support',\n",
       "  'vector',\n",
       "  'machin',\n",
       "  'svm',\n",
       "  'consid',\n",
       "  'here',\n",
       "  'are',\n",
       "  'kernel',\n",
       "  'base',\n",
       "  'regular',\n",
       "  'scheme',\n",
       "  'in',\n",
       "  'a',\n",
       "  'reproduc',\n",
       "  'kernel',\n",
       "  'hilbert',\n",
       "  'space',\n",
       "  'rkh',\n",
       "  'gener',\n",
       "  'by',\n",
       "  'a',\n",
       "  'mercer',\n",
       "  'kernel',\n",
       "  'with',\n",
       "  'a',\n",
       "  'shift',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'introduc',\n",
       "  'for',\n",
       "  'deal'],\n",
       " ['even',\n",
       "  'with',\n",
       "  'heavi',\n",
       "  'tail',\n",
       "  'distribut',\n",
       "  'as',\n",
       "  'they',\n",
       "  'take',\n",
       "  'the',\n",
       "  'form',\n",
       "  'where',\n",
       "  'for',\n",
       "  'a',\n",
       "  'gener',\n",
       "  'borel',\n",
       "  'measur',\n",
       "  'on',\n",
       "  'the',\n",
       "  'function',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'by',\n",
       "  'where',\n",
       "  'is',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'paramet'],\n",
       " ['the',\n",
       "  'idea',\n",
       "  'to',\n",
       "  'shift',\n",
       "  'a',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'long',\n",
       "  'histori',\n",
       "  'see',\n",
       "  'e',\n",
       "  'g',\n",
       "  'in',\n",
       "  'the',\n",
       "  'context',\n",
       "  'of',\n",
       "  'm',\n",
       "  'estim'],\n",
       " ['it',\n",
       "  'wa',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'that',\n",
       "  'is',\n",
       "  'also',\n",
       "  'a',\n",
       "  'minim',\n",
       "  'of',\n",
       "  'the',\n",
       "  'follow',\n",
       "  'optim',\n",
       "  'problem',\n",
       "  'involv',\n",
       "  'the',\n",
       "  'origin',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'if',\n",
       "  'a',\n",
       "  'minim',\n",
       "  'exist',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'we',\n",
       "  'consid',\n",
       "  'consist',\n",
       "  'of',\n",
       "  'the',\n",
       "  '_',\n",
       "  'input',\n",
       "  'space',\n",
       "  'decomposit',\n",
       "  '_'],\n",
       " ['with',\n",
       "  'each',\n",
       "  'a',\n",
       "  'complet',\n",
       "  'separ',\n",
       "  'metric',\n",
       "  'space',\n",
       "  'and',\n",
       "  'a',\n",
       "  '_',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  '_'],\n",
       " ['where',\n",
       "  'is',\n",
       "  'a',\n",
       "  'set',\n",
       "  'of',\n",
       "  'function',\n",
       "  'each',\n",
       "  'of',\n",
       "  'which',\n",
       "  'is',\n",
       "  'also',\n",
       "  'identifi',\n",
       "  'as',\n",
       "  'a',\n",
       "  'map',\n",
       "  'from',\n",
       "  'to'],\n",
       " ['henc', 'the', 'function', 'from', 'take', 'the', 'addit', 'form'],\n",
       " ['we',\n",
       "  'mention',\n",
       "  'that',\n",
       "  'there',\n",
       "  'is',\n",
       "  'strictli',\n",
       "  'speak',\n",
       "  'a',\n",
       "  'notat',\n",
       "  'problem',\n",
       "  'here',\n",
       "  'becaus',\n",
       "  'in',\n",
       "  'the',\n",
       "  'previou',\n",
       "  'formula',\n",
       "  'each',\n",
       "  'quantiti',\n",
       "  'is',\n",
       "  'an',\n",
       "  'element',\n",
       "  'of',\n",
       "  'the',\n",
       "  'set',\n",
       "  'which',\n",
       "  'is',\n",
       "  'a',\n",
       "  'subset',\n",
       "  'of',\n",
       "  'the',\n",
       "  'full',\n",
       "  'input',\n",
       "  'space',\n",
       "  'wherea',\n",
       "  'in',\n",
       "  'the',\n",
       "  'definit',\n",
       "  'of',\n",
       "  'sampl',\n",
       "  'each',\n",
       "  'quantiti',\n",
       "  'is',\n",
       "  'an',\n",
       "  'element',\n",
       "  'of',\n",
       "  'the',\n",
       "  'full',\n",
       "  'input',\n",
       "  'space',\n",
       "  'where'],\n",
       " ['becaus',\n",
       "  'these',\n",
       "  'notat',\n",
       "  'will',\n",
       "  'onli',\n",
       "  'be',\n",
       "  'use',\n",
       "  'in',\n",
       "  'differ',\n",
       "  'place',\n",
       "  'and',\n",
       "  'becaus',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'expect',\n",
       "  'ani',\n",
       "  'misunderstand',\n",
       "  'we',\n",
       "  'think',\n",
       "  'thi',\n",
       "  'notat',\n",
       "  'is',\n",
       "  'easier',\n",
       "  'and',\n",
       "  'more',\n",
       "  'intuit',\n",
       "  'than',\n",
       "  'specifi',\n",
       "  'these',\n",
       "  'quantiti',\n",
       "  'with',\n",
       "  'differ',\n",
       "  'symbol'],\n",
       " ['the',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'mercer',\n",
       "  'kernel',\n",
       "  'on',\n",
       "  'as',\n",
       "  'it',\n",
       "  'gener',\n",
       "  'an',\n",
       "  'rkh',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'written',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'the',\n",
       "  'rkh',\n",
       "  'gener',\n",
       "  'by',\n",
       "  'on',\n",
       "  'correspond',\n",
       "  'to',\n",
       "  'the',\n",
       "  'form',\n",
       "  'addit',\n",
       "  'as',\n",
       "  'with',\n",
       "  'norm',\n",
       "  'given',\n",
       "  'by',\n",
       "  'the',\n",
       "  'norm',\n",
       "  'of',\n",
       "  'satisfi',\n",
       "  'to',\n",
       "  'illustr',\n",
       "  'advantag',\n",
       "  'of',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'we',\n",
       "  'provid',\n",
       "  'two',\n",
       "  'exampl',\n",
       "  'of',\n",
       "  'compar',\n",
       "  'addit',\n",
       "  'with',\n",
       "  'product',\n",
       "  'kernel'],\n",
       " ['the', 'first', 'exampl', 'deal', 'with', 'gaussian', 'rbf', 'kernel'],\n",
       " ['all', 'proof', 'will', 'be', 'given', 'in', 'section', 'proofsect'],\n",
       " ['gaussadd',\n",
       "  'let',\n",
       "  'and',\n",
       "  '2',\n",
       "  'let',\n",
       "  'and',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'is',\n",
       "  'given',\n",
       "  'by',\n",
       "  'furthermor',\n",
       "  'the',\n",
       "  'product',\n",
       "  'kernel',\n",
       "  'is',\n",
       "  'the',\n",
       "  'standard',\n",
       "  'gaussian',\n",
       "  'kernel',\n",
       "  'given',\n",
       "  'by',\n",
       "  'defin',\n",
       "  'a',\n",
       "  'gaussian',\n",
       "  'function',\n",
       "  'on',\n",
       "  '2',\n",
       "  'depend',\n",
       "  'onli',\n",
       "  'on',\n",
       "  'one',\n",
       "  'variabl',\n",
       "  'by',\n",
       "  'then',\n",
       "  'but',\n",
       "  'where',\n",
       "  'denot',\n",
       "  'the',\n",
       "  'rkh',\n",
       "  'gener',\n",
       "  'by',\n",
       "  'the',\n",
       "  'standard',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel'],\n",
       " ['the', 'second', 'exampl', 'is', 'about', 'sobolev', 'kernel'],\n",
       " ['sobolvadd',\n",
       "  'let',\n",
       "  'and',\n",
       "  'let',\n",
       "  'u',\n",
       "  'l_2',\n",
       "  '0',\n",
       "  '1',\n",
       "  'd',\n",
       "  'αu',\n",
       "  'l_2',\n",
       "  '0',\n",
       "  '1',\n",
       "  'α',\n",
       "  '1',\n",
       "  'be',\n",
       "  'the',\n",
       "  'sobolev',\n",
       "  'space',\n",
       "  'consist',\n",
       "  'of',\n",
       "  'all',\n",
       "  'squar',\n",
       "  'integr',\n",
       "  'univari',\n",
       "  'function',\n",
       "  'whose',\n",
       "  'deriv',\n",
       "  'is',\n",
       "  'also',\n",
       "  'squar',\n",
       "  'integr'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'an',\n",
       "  'rkh',\n",
       "  'with',\n",
       "  'a',\n",
       "  'mercer',\n",
       "  'kernel',\n",
       "  'defin',\n",
       "  'on',\n",
       "  '2'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'take',\n",
       "  'all',\n",
       "  'the',\n",
       "  'mercer',\n",
       "  'kernel',\n",
       "  'to',\n",
       "  'be',\n",
       "  'then',\n",
       "  'for',\n",
       "  'each'],\n",
       " ['the',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'is',\n",
       "  'also',\n",
       "  'a',\n",
       "  'mercer',\n",
       "  'kernel',\n",
       "  'and',\n",
       "  'defin',\n",
       "  'an',\n",
       "  'rkh',\n",
       "  'howev',\n",
       "  'the',\n",
       "  'multivari',\n",
       "  'sobolev',\n",
       "  'space',\n",
       "  'consist',\n",
       "  'of',\n",
       "  'all',\n",
       "  'squar',\n",
       "  'integr',\n",
       "  'function',\n",
       "  'whose',\n",
       "  'partial',\n",
       "  'deriv',\n",
       "  'are',\n",
       "  'all',\n",
       "  'squar',\n",
       "  'integr',\n",
       "  'contain',\n",
       "  'discontinu',\n",
       "  'function',\n",
       "  'and',\n",
       "  'is',\n",
       "  'not',\n",
       "  'an',\n",
       "  'rkh'],\n",
       " ['denot',\n",
       "  'the',\n",
       "  'margin',\n",
       "  'distribut',\n",
       "  'of',\n",
       "  'on',\n",
       "  'as',\n",
       "  'under',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'that',\n",
       "  'for',\n",
       "  'each',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'dens',\n",
       "  'in',\n",
       "  'in',\n",
       "  'the',\n",
       "  'it',\n",
       "  'wa',\n",
       "  'prove',\n",
       "  'in',\n",
       "  'that',\n",
       "  'in',\n",
       "  'probabl',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'satisfi',\n",
       "  'and'],\n",
       " ['the', 'rest', 'of', 'the', 'paper', 'ha', 'the', 'follow', 'structur'],\n",
       " ['section',\n",
       "  'ratessect',\n",
       "  'contain',\n",
       "  'our',\n",
       "  'main',\n",
       "  'result',\n",
       "  'on',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'svm',\n",
       "  'base',\n",
       "  'on',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress'],\n",
       " ['are', 'treat', 'as', 'import', 'special', 'case'],\n",
       " ['section',\n",
       "  'comparisonsect',\n",
       "  'contain',\n",
       "  'a',\n",
       "  'comparison',\n",
       "  'of',\n",
       "  'our',\n",
       "  'result',\n",
       "  'with',\n",
       "  'other',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'publish',\n",
       "  'recent'],\n",
       " ['section',\n",
       "  'proofsect',\n",
       "  'contain',\n",
       "  'all',\n",
       "  'the',\n",
       "  'proof',\n",
       "  'and',\n",
       "  'some',\n",
       "  'result',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'their',\n",
       "  'own'],\n",
       " ['in',\n",
       "  'thi',\n",
       "  'paper',\n",
       "  'we',\n",
       "  'provid',\n",
       "  'some',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'the',\n",
       "  'support',\n",
       "  'vector',\n",
       "  'machin',\n",
       "  'gener',\n",
       "  'by',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'for',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'which',\n",
       "  'help',\n",
       "  'improv',\n",
       "  'the',\n",
       "  'quantit',\n",
       "  'understand',\n",
       "  'present',\n",
       "  'in'],\n",
       " ['the',\n",
       "  'rate',\n",
       "  'are',\n",
       "  'about',\n",
       "  'asymptot',\n",
       "  'behavior',\n",
       "  'of',\n",
       "  'the',\n",
       "  'excess',\n",
       "  'risk',\n",
       "  'and',\n",
       "  'take',\n",
       "  'the',\n",
       "  'form',\n",
       "  'with'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'state',\n",
       "  'under',\n",
       "  'three',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'condit',\n",
       "  'involv',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'the',\n",
       "  'measur',\n",
       "  'the',\n",
       "  'loss',\n",
       "  'and',\n",
       "  'the',\n",
       "  'choic',\n",
       "  'of',\n",
       "  'the',\n",
       "  'regular',\n",
       "  'paramet'],\n",
       " ['the',\n",
       "  'first',\n",
       "  'condit',\n",
       "  'is',\n",
       "  'about',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'abil',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space'],\n",
       " ['sinc',\n",
       "  'the',\n",
       "  'output',\n",
       "  'function',\n",
       "  'is',\n",
       "  'from',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'algorithm',\n",
       "  'depend',\n",
       "  'on',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'abil',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'with',\n",
       "  'respect',\n",
       "  'to',\n",
       "  'the',\n",
       "  'optim',\n",
       "  'risk',\n",
       "  'measur',\n",
       "  'by',\n",
       "  'the',\n",
       "  'follow',\n",
       "  'approxim',\n",
       "  'error'],\n",
       " ['defapprox',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tripl',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'as',\n",
       "  'to',\n",
       "  'estim',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'we',\n",
       "  'make',\n",
       "  'an',\n",
       "  'assumpt',\n",
       "  'about',\n",
       "  'the',\n",
       "  'minim',\n",
       "  'of',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'for',\n",
       "  'each',\n",
       "  'defin',\n",
       "  'the',\n",
       "  'integr',\n",
       "  'oper',\n",
       "  'associ',\n",
       "  'with',\n",
       "  'the',\n",
       "  'kernel',\n",
       "  'by',\n",
       "  'we',\n",
       "  'mention',\n",
       "  'that',\n",
       "  'is',\n",
       "  'a',\n",
       "  'compact',\n",
       "  'and',\n",
       "  'posit',\n",
       "  'oper',\n",
       "  'on',\n",
       "  'henc',\n",
       "  'we',\n",
       "  'can',\n",
       "  'find',\n",
       "  'it',\n",
       "  'normal',\n",
       "  'eigenpair',\n",
       "  'such',\n",
       "  'that',\n",
       "  'is',\n",
       "  'an',\n",
       "  'orthonorm',\n",
       "  'basi',\n",
       "  'of',\n",
       "  'and',\n",
       "  'as',\n",
       "  'fix'],\n",
       " ['then',\n",
       "  'we',\n",
       "  'can',\n",
       "  'defin',\n",
       "  'the',\n",
       "  'power',\n",
       "  'of',\n",
       "  'by',\n",
       "  'thi',\n",
       "  'is',\n",
       "  'a',\n",
       "  'posit',\n",
       "  'and',\n",
       "  'bound',\n",
       "  'oper',\n",
       "  'and',\n",
       "  'it',\n",
       "  'rang',\n",
       "  'is',\n",
       "  'well',\n",
       "  'defin'],\n",
       " ['the', 'assumpt', 'mean', 'lie', 'in', 'thi', 'rang'],\n",
       " ['assumption1',\n",
       "  'we',\n",
       "  'assum',\n",
       "  'and',\n",
       "  'where',\n",
       "  'for',\n",
       "  'some',\n",
       "  'and',\n",
       "  'each',\n",
       "  'is',\n",
       "  'a',\n",
       "  'function',\n",
       "  'of',\n",
       "  'the',\n",
       "  'form',\n",
       "  'with',\n",
       "  'some'],\n",
       " ['the',\n",
       "  'case',\n",
       "  'of',\n",
       "  'assumpt',\n",
       "  'assumption1',\n",
       "  'mean',\n",
       "  'each',\n",
       "  'lie',\n",
       "  'in',\n",
       "  'the',\n",
       "  'rkh'],\n",
       " ['a',\n",
       "  'standard',\n",
       "  'condit',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'e',\n",
       "  'g',\n",
       "  'for',\n",
       "  'achiev',\n",
       "  'decay',\n",
       "  'of',\n",
       "  'the',\n",
       "  'form',\n",
       "  'for',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'approxerrordef',\n",
       "  'is',\n",
       "  'with',\n",
       "  'some',\n",
       "  'here'],\n",
       " ['the',\n",
       "  'oper',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'by',\n",
       "  'in',\n",
       "  'gener',\n",
       "  'thi',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'written',\n",
       "  'in',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'form'],\n",
       " ['howev',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'addit',\n",
       "  'take',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'form'],\n",
       " ['so',\n",
       "  'it',\n",
       "  'is',\n",
       "  'natur',\n",
       "  'for',\n",
       "  'us',\n",
       "  'to',\n",
       "  'impos',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'express',\n",
       "  'for',\n",
       "  'the',\n",
       "  'target',\n",
       "  'function',\n",
       "  'with',\n",
       "  'the',\n",
       "  'compon',\n",
       "  'function',\n",
       "  'satisfi',\n",
       "  'the',\n",
       "  'power',\n",
       "  'condit'],\n",
       " ['the',\n",
       "  'abov',\n",
       "  'natur',\n",
       "  'assumpt',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'a',\n",
       "  'technic',\n",
       "  'difficulti',\n",
       "  'in',\n",
       "  'estim',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'the',\n",
       "  'function',\n",
       "  'ha',\n",
       "  'no',\n",
       "  'direct',\n",
       "  'connect',\n",
       "  'to',\n",
       "  'the',\n",
       "  'margin',\n",
       "  'distribut',\n",
       "  'project',\n",
       "  'onto',\n",
       "  'henc',\n",
       "  'exist',\n",
       "  'method',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'e',\n",
       "  'g',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'appli',\n",
       "  'directli'],\n",
       " ['note',\n",
       "  'that',\n",
       "  'on',\n",
       "  'the',\n",
       "  'product',\n",
       "  'space',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'natur',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'project',\n",
       "  'from',\n",
       "  'and',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'on',\n",
       "  'is',\n",
       "  'not',\n",
       "  'defin',\n",
       "  'our',\n",
       "  'idea',\n",
       "  'to',\n",
       "  'overcom',\n",
       "  'the',\n",
       "  'difficulti',\n",
       "  'is',\n",
       "  'to',\n",
       "  'introduc',\n",
       "  'an',\n",
       "  'intermedi',\n",
       "  'function'],\n",
       " ['it',\n",
       "  'may',\n",
       "  'not',\n",
       "  'minim',\n",
       "  'a',\n",
       "  'risk',\n",
       "  'which',\n",
       "  'is',\n",
       "  'not',\n",
       "  'even',\n",
       "  'defin'],\n",
       " ['howev', 'it', 'approxim', 'the', 'compon', 'function', 'well'],\n",
       " ['when',\n",
       "  'we',\n",
       "  'add',\n",
       "  'up',\n",
       "  'such',\n",
       "  'function',\n",
       "  'we',\n",
       "  'get',\n",
       "  'a',\n",
       "  'good',\n",
       "  'approxim',\n",
       "  'of',\n",
       "  'the',\n",
       "  'target',\n",
       "  'function',\n",
       "  'and',\n",
       "  'therebi',\n",
       "  'a',\n",
       "  'good',\n",
       "  'estim',\n",
       "  'of',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error'],\n",
       " ['thi', 'is', 'the', 'first', 'novelti', 'of', 'the', 'paper'],\n",
       " ['approxerrorthm',\n",
       "  'under',\n",
       "  'assumpt',\n",
       "  'assumption1',\n",
       "  'we',\n",
       "  'have',\n",
       "  'where',\n",
       "  'is',\n",
       "  'the',\n",
       "  'constant',\n",
       "  'given',\n",
       "  'by',\n",
       "  'the',\n",
       "  'second',\n",
       "  'condit',\n",
       "  'for',\n",
       "  'our',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'is',\n",
       "  'about',\n",
       "  'the',\n",
       "  'capac',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'measur',\n",
       "  'by',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'let',\n",
       "  'be',\n",
       "  'a',\n",
       "  'set',\n",
       "  'of',\n",
       "  'function',\n",
       "  'on',\n",
       "  'and',\n",
       "  'for',\n",
       "  'everi',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'of',\n",
       "  'with',\n",
       "  'respect',\n",
       "  'to',\n",
       "  'the',\n",
       "  'empir',\n",
       "  'metric',\n",
       "  'given',\n",
       "  'by',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'as',\n",
       "  'and',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'of',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'as',\n",
       "  'assumption2',\n",
       "  'we',\n",
       "  'assum',\n",
       "  'and',\n",
       "  'that',\n",
       "  'for',\n",
       "  'some',\n",
       "  'and',\n",
       "  'everi',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'unit',\n",
       "  'ball',\n",
       "  'of',\n",
       "  'satisfi',\n",
       "  'the',\n",
       "  'second',\n",
       "  'novelti',\n",
       "  'of',\n",
       "  'thi',\n",
       "  'paper',\n",
       "  'is',\n",
       "  'to',\n",
       "  'observ',\n",
       "  'that',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'natur',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'yield',\n",
       "  'the',\n",
       "  'follow',\n",
       "  'nice',\n",
       "  'bound',\n",
       "  'with',\n",
       "  'a',\n",
       "  'dimens',\n",
       "  'independ',\n",
       "  'power',\n",
       "  'expon',\n",
       "  'for',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ball',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'to',\n",
       "  'be',\n",
       "  'prove',\n",
       "  'in',\n",
       "  'section',\n",
       "  'samplesect'],\n",
       " ['capacitythm',\n",
       "  'under',\n",
       "  'assumpt',\n",
       "  'assumption2',\n",
       "  'for',\n",
       "  'ani',\n",
       "  'and',\n",
       "  'we',\n",
       "  'have',\n",
       "  'the',\n",
       "  'bound',\n",
       "  'for',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'state',\n",
       "  'in',\n",
       "  'theorem',\n",
       "  'capacitythm',\n",
       "  'is',\n",
       "  'special',\n",
       "  'the',\n",
       "  'power',\n",
       "  'is',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'compon',\n",
       "  'in',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'model'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'well',\n",
       "  'known',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'of',\n",
       "  'function',\n",
       "  'space',\n",
       "  'that',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'of',\n",
       "  'ball',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sobolev',\n",
       "  'space',\n",
       "  'on',\n",
       "  'the',\n",
       "  'cube',\n",
       "  'of',\n",
       "  'the',\n",
       "  'euclidean',\n",
       "  'space',\n",
       "  'with',\n",
       "  'regular',\n",
       "  'index',\n",
       "  'ha',\n",
       "  'the',\n",
       "  'follow',\n",
       "  'asymptot',\n",
       "  'behavior',\n",
       "  'with',\n",
       "  'here',\n",
       "  'the',\n",
       "  'power',\n",
       "  'depend',\n",
       "  'linearli',\n",
       "  'on',\n",
       "  'the',\n",
       "  'dimens'],\n",
       " ['similar',\n",
       "  'dimens',\n",
       "  'depend',\n",
       "  'bound',\n",
       "  'for',\n",
       "  'the',\n",
       "  'cover',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'rkhss',\n",
       "  'associ',\n",
       "  'with',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel',\n",
       "  'can',\n",
       "  'be',\n",
       "  'found',\n",
       "  'in'],\n",
       " ['the',\n",
       "  'special',\n",
       "  'bound',\n",
       "  'in',\n",
       "  'theorem',\n",
       "  'capacitythm',\n",
       "  'demonstr',\n",
       "  'an',\n",
       "  'advantag',\n",
       "  'of',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'capac',\n",
       "  'of',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'hypothesi',\n",
       "  'space'],\n",
       " ['the',\n",
       "  'third',\n",
       "  'condit',\n",
       "  'for',\n",
       "  'our',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'is',\n",
       "  'about',\n",
       "  'the',\n",
       "  'nois',\n",
       "  'level',\n",
       "  'in',\n",
       "  'the',\n",
       "  'measur',\n",
       "  'with',\n",
       "  'respect',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hypothesi',\n",
       "  'space',\n",
       "  'befor',\n",
       "  'state',\n",
       "  'the',\n",
       "  'gener',\n",
       "  'condit'],\n",
       " ['we',\n",
       "  'consid',\n",
       "  'a',\n",
       "  'special',\n",
       "  'case',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'to',\n",
       "  'illustr',\n",
       "  'our',\n",
       "  'gener',\n",
       "  'result'],\n",
       " ['let', 'be', 'a', 'quantil', 'paramet'],\n",
       " ['the',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'function',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'by',\n",
       "  'it',\n",
       "  'valu',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'of',\n",
       "  'i',\n",
       "  'e',\n",
       "  'a',\n",
       "  'valu',\n",
       "  'satisfi',\n",
       "  'the',\n",
       "  'regular',\n",
       "  'scheme',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'consid',\n",
       "  'here',\n",
       "  'take',\n",
       "  'the',\n",
       "  'form',\n",
       "  'algor',\n",
       "  'with',\n",
       "  'the',\n",
       "  'loss',\n",
       "  'function',\n",
       "  'given',\n",
       "  'by',\n",
       "  'the',\n",
       "  'pinbal',\n",
       "  'loss',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nois',\n",
       "  'condit',\n",
       "  'on',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'in',\n",
       "  'as',\n",
       "  'follow',\n",
       "  'to',\n",
       "  'thi',\n",
       "  'end',\n",
       "  'let',\n",
       "  'be',\n",
       "  'a',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'on',\n",
       "  'and',\n",
       "  'then',\n",
       "  'a',\n",
       "  'real',\n",
       "  'number',\n",
       "  'is',\n",
       "  'call',\n",
       "  'of',\n",
       "  'if',\n",
       "  'and',\n",
       "  'onli',\n",
       "  'if',\n",
       "  'belong',\n",
       "  'to',\n",
       "  'the',\n",
       "  'set'],\n",
       " ['τ',\n",
       "  'q',\n",
       "  't',\n",
       "  '1',\n",
       "  'τ',\n",
       "  'it',\n",
       "  'is',\n",
       "  'well',\n",
       "  'known',\n",
       "  'that',\n",
       "  'is',\n",
       "  'a',\n",
       "  'compact',\n",
       "  'interv'],\n",
       " ['noisecond', 'let', '1'],\n",
       " ['a',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'on',\n",
       "  'is',\n",
       "  'said',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'if',\n",
       "  'there',\n",
       "  'exist',\n",
       "  'a',\n",
       "  'and',\n",
       "  'a',\n",
       "  'constant',\n",
       "  'such',\n",
       "  'that',\n",
       "  'for',\n",
       "  'all',\n",
       "  'we',\n",
       "  'have',\n",
       "  '2'],\n",
       " ['let'],\n",
       " ['we',\n",
       "  'say',\n",
       "  'that',\n",
       "  'a',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'on',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'if',\n",
       "  'the',\n",
       "  'condit',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'ha',\n",
       "  'sure',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'and',\n",
       "  'the',\n",
       "  'function',\n",
       "  'where',\n",
       "  'is',\n",
       "  'the',\n",
       "  'constant',\n",
       "  'defin',\n",
       "  'in',\n",
       "  'part',\n",
       "  '1',\n",
       "  'satisfi'],\n",
       " ['one',\n",
       "  'can',\n",
       "  'show',\n",
       "  'that',\n",
       "  'a',\n",
       "  'distribut',\n",
       "  'have',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'uniqu'],\n",
       " ['moreov',\n",
       "  'if',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'lebesgu',\n",
       "  'densiti',\n",
       "  'then',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'if',\n",
       "  'is',\n",
       "  'bound',\n",
       "  'away',\n",
       "  'from',\n",
       "  'zero',\n",
       "  'on',\n",
       "  'sinc',\n",
       "  'we',\n",
       "  'can',\n",
       "  'use',\n",
       "  'in',\n",
       "  'tauquantileoftype2formula'],\n",
       " ['thi',\n",
       "  'assumpt',\n",
       "  'is',\n",
       "  'gener',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'cover',\n",
       "  'mani',\n",
       "  'distribut',\n",
       "  'use',\n",
       "  'in',\n",
       "  'parametr',\n",
       "  'statist',\n",
       "  'such',\n",
       "  'as',\n",
       "  'gaussian',\n",
       "  'student',\n",
       "  's',\n",
       "  'and',\n",
       "  'logist',\n",
       "  'distribut',\n",
       "  'with',\n",
       "  'gamma',\n",
       "  'and',\n",
       "  'log',\n",
       "  'normal',\n",
       "  'distribut',\n",
       "  'with',\n",
       "  'and',\n",
       "  'uniform',\n",
       "  'and',\n",
       "  'beta',\n",
       "  'distribut',\n",
       "  'with'],\n",
       " ['the',\n",
       "  'follow',\n",
       "  'theorem',\n",
       "  'to',\n",
       "  'be',\n",
       "  'prove',\n",
       "  'in',\n",
       "  'section',\n",
       "  'proofsect',\n",
       "  'give',\n",
       "  'a',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'the',\n",
       "  'regular',\n",
       "  'scheme',\n",
       "  'algor',\n",
       "  'in',\n",
       "  'the',\n",
       "  'special',\n",
       "  'case',\n",
       "  'of',\n",
       "  'quantil',\n",
       "  'regress'],\n",
       " ['quantilethm',\n",
       "  'suppos',\n",
       "  'that',\n",
       "  'almost',\n",
       "  'sure',\n",
       "  'for',\n",
       "  'some',\n",
       "  'constant',\n",
       "  'and',\n",
       "  'that',\n",
       "  'each',\n",
       "  'kernel',\n",
       "  'is',\n",
       "  'with',\n",
       "  'for',\n",
       "  'some'],\n",
       " ['if',\n",
       "  'assumpt',\n",
       "  'assumption1',\n",
       "  'hold',\n",
       "  'with',\n",
       "  'and',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'for',\n",
       "  'some',\n",
       "  'then',\n",
       "  'by',\n",
       "  'take',\n",
       "  'for',\n",
       "  'ani',\n",
       "  'and',\n",
       "  'with',\n",
       "  'confid',\n",
       "  'at',\n",
       "  'least',\n",
       "  'we',\n",
       "  'have',\n",
       "  'where',\n",
       "  'is',\n",
       "  'a',\n",
       "  'constant',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'and',\n",
       "  'and',\n",
       "  'pleas',\n",
       "  'note',\n",
       "  'that',\n",
       "  'the',\n",
       "  'expon',\n",
       "  'given',\n",
       "  'by',\n",
       "  'quantilerates2',\n",
       "  'for',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'quantiler',\n",
       "  'is',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'the',\n",
       "  'quantil',\n",
       "  'level',\n",
       "  'of',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'addit',\n",
       "  'compon',\n",
       "  'in',\n",
       "  'and',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dimens',\n",
       "  'and',\n",
       "  'further',\n",
       "  'note',\n",
       "  'that',\n",
       "  'if',\n",
       "  'and',\n",
       "  'if',\n",
       "  'becaus',\n",
       "  'can',\n",
       "  'be',\n",
       "  'arbitrarili',\n",
       "  'close',\n",
       "  'to',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'which',\n",
       "  'is',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dimens',\n",
       "  'and',\n",
       "  'given',\n",
       "  'by',\n",
       "  'theorem',\n",
       "  'quantilethm',\n",
       "  'is',\n",
       "  'close',\n",
       "  'to',\n",
       "  'for',\n",
       "  'larg',\n",
       "  'valu',\n",
       "  'of',\n",
       "  'and',\n",
       "  'is',\n",
       "  'close',\n",
       "  'to',\n",
       "  'or',\n",
       "  'better',\n",
       "  'if',\n",
       "  'to',\n",
       "  'state',\n",
       "  'our',\n",
       "  'gener',\n",
       "  'learn',\n",
       "  'rate'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'an',\n",
       "  'assumpt',\n",
       "  'on',\n",
       "  'a',\n",
       "  '_',\n",
       "  'varianc',\n",
       "  'expect',\n",
       "  'bound',\n",
       "  '_',\n",
       "  'which',\n",
       "  'is',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'definit',\n",
       "  'noisecond',\n",
       "  'in',\n",
       "  'the',\n",
       "  'special',\n",
       "  'case',\n",
       "  'of',\n",
       "  'quantil',\n",
       "  'regress'],\n",
       " ['assumption3',\n",
       "  'we',\n",
       "  'assum',\n",
       "  'that',\n",
       "  'there',\n",
       "  'exist',\n",
       "  'an',\n",
       "  'expon',\n",
       "  'and',\n",
       "  'a',\n",
       "  'posit',\n",
       "  'constant',\n",
       "  'such',\n",
       "  'that',\n",
       "  'assumpt',\n",
       "  'assumption3',\n",
       "  'alway',\n",
       "  'hold',\n",
       "  'true',\n",
       "  'for',\n",
       "  'if',\n",
       "  'the',\n",
       "  'tripl',\n",
       "  'satisfi',\n",
       "  'some',\n",
       "  'condit',\n",
       "  'the',\n",
       "  'expon',\n",
       "  'can',\n",
       "  'be',\n",
       "  'larger'],\n",
       " ['for',\n",
       "  'exampl',\n",
       "  'when',\n",
       "  'is',\n",
       "  'the',\n",
       "  'pinbal',\n",
       "  'loss',\n",
       "  'pinloss',\n",
       "  'and',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'for',\n",
       "  'some',\n",
       "  'and',\n",
       "  'as',\n",
       "  'defin',\n",
       "  'in',\n",
       "  'then'],\n",
       " ['mainratesthm',\n",
       "  'suppos',\n",
       "  'that',\n",
       "  'is',\n",
       "  'bound',\n",
       "  'by',\n",
       "  'a',\n",
       "  'constant',\n",
       "  'almost',\n",
       "  'sure',\n",
       "  'under',\n",
       "  'assumpt',\n",
       "  'assumption1',\n",
       "  'to',\n",
       "  'assumption3'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'take',\n",
       "  'and',\n",
       "  'for',\n",
       "  'some',\n",
       "  'then',\n",
       "  'for',\n",
       "  'ani',\n",
       "  'with',\n",
       "  'confid',\n",
       "  'at',\n",
       "  'least',\n",
       "  'we',\n",
       "  'have',\n",
       "  'where',\n",
       "  'is',\n",
       "  'given',\n",
       "  'by',\n",
       "  'and',\n",
       "  'is',\n",
       "  'constant',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'or',\n",
       "  'to',\n",
       "  'be',\n",
       "  'given',\n",
       "  'explicitli',\n",
       "  'in',\n",
       "  'the',\n",
       "  'proof'],\n",
       " ['we',\n",
       "  'now',\n",
       "  'add',\n",
       "  'some',\n",
       "  'theoret',\n",
       "  'and',\n",
       "  'numer',\n",
       "  'comparison',\n",
       "  'on',\n",
       "  'the',\n",
       "  'good',\n",
       "  'of',\n",
       "  'our',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'with',\n",
       "  'those',\n",
       "  'from',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'as',\n",
       "  'alreadi',\n",
       "  'mention',\n",
       "  'in',\n",
       "  'the',\n",
       "  'introduct'],\n",
       " ['some',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'the',\n",
       "  'popular',\n",
       "  'of',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'are',\n",
       "  'flexibl',\n",
       "  'increas',\n",
       "  'interpret',\n",
       "  'and',\n",
       "  'often',\n",
       "  'a',\n",
       "  'reduc',\n",
       "  'prone',\n",
       "  'of',\n",
       "  'the',\n",
       "  'curs',\n",
       "  'of',\n",
       "  'high',\n",
       "  'dimens'],\n",
       " ['henc',\n",
       "  'it',\n",
       "  'is',\n",
       "  'import',\n",
       "  'to',\n",
       "  'check',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'given',\n",
       "  'in',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'under',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'of',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'favour',\n",
       "  'compar',\n",
       "  'to',\n",
       "  'essenti',\n",
       "  'optim',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'without',\n",
       "  'thi',\n",
       "  'assumpt',\n",
       "  'in',\n",
       "  'other',\n",
       "  'word'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'demonstr',\n",
       "  'that',\n",
       "  'the',\n",
       "  'main',\n",
       "  'goal',\n",
       "  'of',\n",
       "  'thi',\n",
       "  'paper',\n",
       "  'is',\n",
       "  'achiev',\n",
       "  'by',\n",
       "  'theorem',\n",
       "  'quantilethm',\n",
       "  'and',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'i',\n",
       "  'e',\n",
       "  'that',\n",
       "  'an',\n",
       "  'svm',\n",
       "  'base',\n",
       "  'on',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'can',\n",
       "  'provid',\n",
       "  'a',\n",
       "  'substanti',\n",
       "  'better',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'high',\n",
       "  'dimens',\n",
       "  'than',\n",
       "  'an',\n",
       "  'svm',\n",
       "  'with',\n",
       "  'a',\n",
       "  'gener',\n",
       "  'kernel',\n",
       "  'say',\n",
       "  'a',\n",
       "  'classic',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel',\n",
       "  'provid',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'of',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'is',\n",
       "  'satisfi'],\n",
       " ['our',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'theorem',\n",
       "  'quantilethm',\n",
       "  'is',\n",
       "  'new',\n",
       "  'and',\n",
       "  'optim',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'of',\n",
       "  'svm',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress'],\n",
       " ['most',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'of',\n",
       "  'svm',\n",
       "  'for',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'are',\n",
       "  'given',\n",
       "  'for',\n",
       "  'project',\n",
       "  'output',\n",
       "  'function',\n",
       "  'while',\n",
       "  'it',\n",
       "  'is',\n",
       "  'well',\n",
       "  'known',\n",
       "  'that',\n",
       "  'project',\n",
       "  'improv',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'here',\n",
       "  'the',\n",
       "  'project',\n",
       "  'oper',\n",
       "  'is',\n",
       "  'defin',\n",
       "  'for',\n",
       "  'ani',\n",
       "  'measur',\n",
       "  'function',\n",
       "  'by',\n",
       "  'sometim',\n",
       "  'thi',\n",
       "  'is',\n",
       "  'call',\n",
       "  'clip'],\n",
       " ['such', 'result', 'are', 'given', 'in'],\n",
       " ['for',\n",
       "  'exampl',\n",
       "  'under',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'that',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'condit',\n",
       "  'approxerrorb',\n",
       "  'is',\n",
       "  'satisfi',\n",
       "  'for',\n",
       "  'some',\n",
       "  'and',\n",
       "  'that',\n",
       "  'for',\n",
       "  'some',\n",
       "  'constant',\n",
       "  'the',\n",
       "  'sequenc',\n",
       "  'of',\n",
       "  'eigenvalu',\n",
       "  'of',\n",
       "  'the',\n",
       "  'integr',\n",
       "  'oper',\n",
       "  'satisfi',\n",
       "  'for',\n",
       "  'everi',\n",
       "  'it',\n",
       "  'wa',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'that',\n",
       "  'with',\n",
       "  'confid',\n",
       "  'at',\n",
       "  'least',\n",
       "  'where',\n",
       "  'here',\n",
       "  'the',\n",
       "  'paramet',\n",
       "  'measur',\n",
       "  'the',\n",
       "  'capac',\n",
       "  'of',\n",
       "  'the',\n",
       "  'rkh',\n",
       "  'and',\n",
       "  'it',\n",
       "  'play',\n",
       "  'a',\n",
       "  'similar',\n",
       "  'role',\n",
       "  'as',\n",
       "  'half',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paramet',\n",
       "  'in',\n",
       "  'assumpt',\n",
       "  '2',\n",
       "  'for',\n",
       "  'a',\n",
       "  'kernel',\n",
       "  'and'],\n",
       " ['one',\n",
       "  'can',\n",
       "  'choos',\n",
       "  'and',\n",
       "  'to',\n",
       "  'be',\n",
       "  'arbitrarili',\n",
       "  'small',\n",
       "  'and',\n",
       "  'the',\n",
       "  'abov',\n",
       "  'power',\n",
       "  'index',\n",
       "  'can',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'as'],\n",
       " ['the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'theorem',\n",
       "  'quantilethm',\n",
       "  'may',\n",
       "  'be',\n",
       "  'improv',\n",
       "  'by',\n",
       "  'relax',\n",
       "  'assumpt',\n",
       "  '1',\n",
       "  'to',\n",
       "  'a',\n",
       "  'sobolev',\n",
       "  'smooth',\n",
       "  'condit',\n",
       "  'for',\n",
       "  'and',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'condit',\n",
       "  'for',\n",
       "  'the',\n",
       "  'margin',\n",
       "  'distribut'],\n",
       " ['for',\n",
       "  'exampl',\n",
       "  'one',\n",
       "  'may',\n",
       "  'use',\n",
       "  'a',\n",
       "  'gaussian',\n",
       "  'kernel',\n",
       "  'depend',\n",
       "  'on',\n",
       "  'the',\n",
       "  'sampl',\n",
       "  'size',\n",
       "  'and',\n",
       "  'achiev',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'condit',\n",
       "  'approxerrorb',\n",
       "  'for',\n",
       "  'some'],\n",
       " ['thi', 'is', 'done', 'for', 'quantil', 'regress', 'in'],\n",
       " ['sinc',\n",
       "  'we',\n",
       "  'are',\n",
       "  'mainli',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'we',\n",
       "  'shall',\n",
       "  'not',\n",
       "  'discuss',\n",
       "  'such',\n",
       "  'an',\n",
       "  'extens'],\n",
       " ['gaussmor',\n",
       "  'let',\n",
       "  'and',\n",
       "  '2',\n",
       "  'let',\n",
       "  'and',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'be',\n",
       "  'given',\n",
       "  'by',\n",
       "  'gaussaddform',\n",
       "  'with',\n",
       "  'in',\n",
       "  'exampl',\n",
       "  'gaussadd',\n",
       "  'as',\n",
       "  'if',\n",
       "  'the',\n",
       "  'function',\n",
       "  'is',\n",
       "  'given',\n",
       "  'by',\n",
       "  'gaussfcn',\n",
       "  'almost',\n",
       "  'sure',\n",
       "  'for',\n",
       "  'some',\n",
       "  'constant',\n",
       "  'and',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'for',\n",
       "  'some',\n",
       "  'then',\n",
       "  'by',\n",
       "  'take',\n",
       "  'for',\n",
       "  'ani',\n",
       "  'and',\n",
       "  'quantiler',\n",
       "  'hold',\n",
       "  'with',\n",
       "  'confid',\n",
       "  'at',\n",
       "  'least',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unknown',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'abov',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'can',\n",
       "  'be',\n",
       "  'deriv',\n",
       "  'by',\n",
       "  'exist',\n",
       "  'approach',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literatur',\n",
       "  'e',\n",
       "  'g',\n",
       "  'even',\n",
       "  'after',\n",
       "  'project'],\n",
       " ['note',\n",
       "  'that',\n",
       "  'the',\n",
       "  'kernel',\n",
       "  'in',\n",
       "  'the',\n",
       "  'abov',\n",
       "  'exampl',\n",
       "  'is',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sampl',\n",
       "  'size'],\n",
       " ['it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'interest',\n",
       "  'to',\n",
       "  'see',\n",
       "  'whether',\n",
       "  'there',\n",
       "  'exist',\n",
       "  'some',\n",
       "  'such',\n",
       "  'that',\n",
       "  'the',\n",
       "  'function',\n",
       "  'defin',\n",
       "  'by',\n",
       "  'gaussfcn',\n",
       "  'lie',\n",
       "  'in',\n",
       "  'the',\n",
       "  'rang',\n",
       "  'of',\n",
       "  'the',\n",
       "  'oper'],\n",
       " ['the',\n",
       "  'exist',\n",
       "  'of',\n",
       "  'such',\n",
       "  'a',\n",
       "  'posit',\n",
       "  'index',\n",
       "  'would',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'the',\n",
       "  'approxim',\n",
       "  'error',\n",
       "  'condit',\n",
       "  'approxerrorb',\n",
       "  'see',\n",
       "  'let',\n",
       "  'us',\n",
       "  'now',\n",
       "  'add',\n",
       "  'some',\n",
       "  'numer',\n",
       "  'comparison',\n",
       "  'on',\n",
       "  'the',\n",
       "  'good',\n",
       "  'of',\n",
       "  'our',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'given',\n",
       "  'by',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'with',\n",
       "  'those',\n",
       "  'given',\n",
       "  'by'],\n",
       " ['their',\n",
       "  'corollari',\n",
       "  '4',\n",
       "  '12',\n",
       "  'give',\n",
       "  'essenti',\n",
       "  'minmax',\n",
       "  'optim',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'clip',\n",
       "  'svm',\n",
       "  'in',\n",
       "  'the',\n",
       "  'context',\n",
       "  'of',\n",
       "  'nonparametr',\n",
       "  'quantil',\n",
       "  'regress',\n",
       "  'use',\n",
       "  'one',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel',\n",
       "  'on',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'input',\n",
       "  'space',\n",
       "  'under',\n",
       "  'appropri',\n",
       "  'smooth',\n",
       "  'assumpt',\n",
       "  'of',\n",
       "  'the',\n",
       "  'target',\n",
       "  'function'],\n",
       " ['let',\n",
       "  'us',\n",
       "  'consid',\n",
       "  'the',\n",
       "  'case',\n",
       "  'that',\n",
       "  'the',\n",
       "  'distribut',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'of',\n",
       "  'type',\n",
       "  'where',\n",
       "  'and',\n",
       "  'assum',\n",
       "  'that',\n",
       "  'both',\n",
       "  'corollari',\n",
       "  '4',\n",
       "  '12',\n",
       "  'in',\n",
       "  'and',\n",
       "  'our',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'are',\n",
       "  'applic'],\n",
       " ['i',\n",
       "  'e',\n",
       "  'we',\n",
       "  'assum',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'that',\n",
       "  'is',\n",
       "  'a',\n",
       "  'probabl',\n",
       "  'measur',\n",
       "  'on',\n",
       "  'and',\n",
       "  'that',\n",
       "  'the',\n",
       "  'margin',\n",
       "  'distribut',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'lebesgu',\n",
       "  'densiti',\n",
       "  'for',\n",
       "  'some',\n",
       "  'furthermor',\n",
       "  'suppos',\n",
       "  'that',\n",
       "  'the',\n",
       "  'optim',\n",
       "  'decis',\n",
       "  'function',\n",
       "  'ha',\n",
       "  'to',\n",
       "  'make',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'applic',\n",
       "  'with',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'structur',\n",
       "  'with',\n",
       "  'each',\n",
       "  'as',\n",
       "  'state',\n",
       "  'in',\n",
       "  'assumpt',\n",
       "  'assumption1',\n",
       "  'where',\n",
       "  'and',\n",
       "  'with',\n",
       "  'minim',\n",
       "  'risk',\n",
       "  'and',\n",
       "  'addit',\n",
       "  'fulfil',\n",
       "  'to',\n",
       "  'make',\n",
       "  'corollari',\n",
       "  '4',\n",
       "  '12',\n",
       "  'in',\n",
       "  'applic',\n",
       "  'where',\n",
       "  'and',\n",
       "  'denot',\n",
       "  'a',\n",
       "  'besov',\n",
       "  'space',\n",
       "  'with',\n",
       "  'smooth',\n",
       "  'paramet'],\n",
       " ['the',\n",
       "  'intuit',\n",
       "  'mean',\n",
       "  'of',\n",
       "  'is',\n",
       "  'that',\n",
       "  'increas',\n",
       "  'valu',\n",
       "  'of',\n",
       "  'correspond',\n",
       "  'to',\n",
       "  'increas',\n",
       "  'smooth'],\n",
       " ['we',\n",
       "  'refer',\n",
       "  'to',\n",
       "  'and',\n",
       "  'p',\n",
       "  '44',\n",
       "  'for',\n",
       "  'detail',\n",
       "  'on',\n",
       "  'besov',\n",
       "  'space'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'well',\n",
       "  'known',\n",
       "  'that',\n",
       "  'the',\n",
       "  'besov',\n",
       "  'space',\n",
       "  'contain',\n",
       "  'the',\n",
       "  'sobolev',\n",
       "  'space',\n",
       "  'for',\n",
       "  'and',\n",
       "  'and',\n",
       "  'that'],\n",
       " ['we',\n",
       "  'mention',\n",
       "  'that',\n",
       "  'if',\n",
       "  'all',\n",
       "  'are',\n",
       "  'suitabl',\n",
       "  'chosen',\n",
       "  'wendland',\n",
       "  'kernel',\n",
       "  'their',\n",
       "  'reproduc',\n",
       "  'kernel',\n",
       "  'hilbert',\n",
       "  'space',\n",
       "  'are',\n",
       "  'sobolev',\n",
       "  'space',\n",
       "  'see'],\n",
       " ['thm', '10', '35', 'p', '160'],\n",
       " ['furthermor',\n",
       "  'we',\n",
       "  'use',\n",
       "  'the',\n",
       "  'same',\n",
       "  'sequenc',\n",
       "  'of',\n",
       "  'regular',\n",
       "  'paramet',\n",
       "  'as',\n",
       "  'in'],\n",
       " ['4',\n",
       "  '9',\n",
       "  'cor',\n",
       "  '4',\n",
       "  '12',\n",
       "  'i',\n",
       "  'e',\n",
       "  'where',\n",
       "  'and',\n",
       "  'is',\n",
       "  'some',\n",
       "  'user',\n",
       "  'defin',\n",
       "  'posit',\n",
       "  'constant',\n",
       "  'independ',\n",
       "  'of',\n",
       "  'for'],\n",
       " ['reason', 'of', 'simplic', 'let', 'us', 'fix'],\n",
       " ['then'],\n",
       " ['4',\n",
       "  '12',\n",
       "  'give',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'svm',\n",
       "  'for',\n",
       "  'regress',\n",
       "  'if',\n",
       "  'a',\n",
       "  'singl',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel',\n",
       "  'on',\n",
       "  'is',\n",
       "  'use',\n",
       "  'for',\n",
       "  'function',\n",
       "  'of',\n",
       "  'type',\n",
       "  'with',\n",
       "  'which',\n",
       "  'are',\n",
       "  'of',\n",
       "  'order',\n",
       "  'henc',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'theorem',\n",
       "  'quantilethm',\n",
       "  'is',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'one',\n",
       "  'in'],\n",
       " ['4',\n",
       "  '12',\n",
       "  'in',\n",
       "  'thi',\n",
       "  'situat',\n",
       "  'if',\n",
       "  'provid',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'of',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'is',\n",
       "  'valid'],\n",
       " ['tabl',\n",
       "  'table1',\n",
       "  'list',\n",
       "  'the',\n",
       "  'valu',\n",
       "  'of',\n",
       "  'from',\n",
       "  'explicitratescz2',\n",
       "  'for',\n",
       "  'some',\n",
       "  'finit',\n",
       "  'valu',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dimens',\n",
       "  'where'],\n",
       " ['all',\n",
       "  'of',\n",
       "  'these',\n",
       "  'valu',\n",
       "  'of',\n",
       "  'are',\n",
       "  'posit',\n",
       "  'with',\n",
       "  'the',\n",
       "  'except',\n",
       "  'if',\n",
       "  'or'],\n",
       " ['thi',\n",
       "  'is',\n",
       "  'in',\n",
       "  'contrast',\n",
       "  'to',\n",
       "  'the',\n",
       "  'correspond',\n",
       "  'expon',\n",
       "  'in',\n",
       "  'the',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'by'],\n",
       " ['cor',\n",
       "  '4',\n",
       "  '12',\n",
       "  'becaus',\n",
       "  'tabl',\n",
       "  'table2',\n",
       "  'and',\n",
       "  'figur',\n",
       "  'figure1',\n",
       "  'to',\n",
       "  'figure2',\n",
       "  'give',\n",
       "  'addit',\n",
       "  'inform',\n",
       "  'on',\n",
       "  'the',\n",
       "  'limit'],\n",
       " ['of',\n",
       "  'cours',\n",
       "  'higher',\n",
       "  'valu',\n",
       "  'of',\n",
       "  'the',\n",
       "  'expon',\n",
       "  'indic',\n",
       "  'faster',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'converg'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'obviou',\n",
       "  'that',\n",
       "  'an',\n",
       "  'svm',\n",
       "  'base',\n",
       "  'on',\n",
       "  'an',\n",
       "  'addit',\n",
       "  'kernel',\n",
       "  'ha',\n",
       "  'a',\n",
       "  'significantli',\n",
       "  'faster',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'converg',\n",
       "  'in',\n",
       "  'higher',\n",
       "  'dimens',\n",
       "  'compar',\n",
       "  'to',\n",
       "  'svm',\n",
       "  'base',\n",
       "  'on',\n",
       "  'a',\n",
       "  'singl',\n",
       "  'gaussian',\n",
       "  'rbf',\n",
       "  'kernel',\n",
       "  'defin',\n",
       "  'on',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'input',\n",
       "  'space',\n",
       "  'of',\n",
       "  'cours',\n",
       "  'under',\n",
       "  'the',\n",
       "  'assumpt',\n",
       "  'that',\n",
       "  'the',\n",
       "  'addit',\n",
       "  'model',\n",
       "  'is',\n",
       "  'valid'],\n",
       " ['the',\n",
       "  'figur',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'indic',\n",
       "  'that',\n",
       "  'our',\n",
       "  'learn',\n",
       "  'rate',\n",
       "  'from',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'is',\n",
       "  'probabl',\n",
       "  'not',\n",
       "  'optim',\n",
       "  'for',\n",
       "  'small',\n",
       "  'dimens',\n",
       "  'howev',\n",
       "  'the',\n",
       "  'main',\n",
       "  'focu',\n",
       "  'of',\n",
       "  'the',\n",
       "  'present',\n",
       "  'paper',\n",
       "  'is',\n",
       "  'on',\n",
       "  'high',\n",
       "  'dimens'],\n",
       " ['table1',\n",
       "  'the',\n",
       "  'tabl',\n",
       "  'list',\n",
       "  'the',\n",
       "  'limit',\n",
       "  'of',\n",
       "  'the',\n",
       "  'expon',\n",
       "  'from'],\n",
       " ['cor',\n",
       "  '4',\n",
       "  '12',\n",
       "  'and',\n",
       "  'from',\n",
       "  'theorem',\n",
       "  'mainratesthm',\n",
       "  'respect',\n",
       "  'if',\n",
       "  'the',\n",
       "  'regular',\n",
       "  'paramet',\n",
       "  'is',\n",
       "  'chosen',\n",
       "  'in',\n",
       "  'an',\n",
       "  'optim',\n",
       "  'manner',\n",
       "  'for',\n",
       "  'the',\n",
       "  'nonparametr',\n",
       "  'setup',\n",
       "  'i',\n",
       "  'e',\n",
       "  'with',\n",
       "  'for',\n",
       "  'and'],\n",
       " ['recal', 'that'],\n",
       " ['col']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "03077d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cue_phrases = [\"the paper describes\", \"in conclusion\", \"in summary\", \"our investigation\", \"the best\", \"the most important\", \"in particular\", \"according to the study\", \"significantly\", \"important\", \"hardly\", \"impossible\"]\n",
    "\n",
    "final_abstracts = []\n",
    "\n",
    "def calculate_scores(articles):\n",
    "    total_abstracts = len(articles)\n",
    "    \n",
    "    final_scores = []\n",
    "    \n",
    "    for abstracts in articles:\n",
    "        \n",
    "        abstracts = [' '.join(abstract) for abstract in abstracts]\n",
    "        print(len(abstracts))\n",
    "    \n",
    "        final_abstracts.append(abstracts)\n",
    "        \n",
    "\n",
    "#         # TF-IDF Vectorizer\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(abstracts)\n",
    "        \n",
    "        scores = []\n",
    "        for i, abstract in enumerate(abstracts):\n",
    "            sLen = len(word_tokenize(abstract))  # Sentence Length (F1)\n",
    "            sPos = i / len(abstracts)  # Sentence Position (F2)\n",
    "\n",
    "            # Calculate Noun and Verb Phrase count (F4)\n",
    "            pos_tags = nltk.pos_tag(word_tokenize(abstract))\n",
    "            nvpi = len([word for word, pos in pos_tags if pos in ['NN', 'NNS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']])\n",
    "\n",
    "            # Calculate Proper Noun count (F5)\n",
    "            PNi = len([word for word, pos in pos_tags if pos in ['NNP', 'NNPS']])\n",
    "\n",
    "            # Calculate Aggregate Cosine Similarity (F6)\n",
    "            current_tfidf = tfidf_matrix[i].toarray()\n",
    "            acs = cosine_similarity(current_tfidf, tfidf_matrix).mean()\n",
    "\n",
    "            # Count cue phrases in the abstract (F7)\n",
    "            cp_count = sum(1 for phrase in cue_phrases if phrase in abstract.lower())\n",
    "\n",
    "            # Calculate the TF-IDF score (F3)\n",
    "            tf_idf = current_tfidf.sum()\n",
    "    \n",
    "            # Store the scores for each measure\n",
    "            scores.append({\n",
    "                \"F1\": sLen,\n",
    "                \"F2\": sPos,\n",
    "                \"F3\": tf_idf,\n",
    "                \"F4\": nvpi,\n",
    "                \"F5\": PNi,\n",
    "                \"F6\": acs,\n",
    "                \"F7\": cp_count,\n",
    "            })\n",
    "\n",
    "        final_scores.append(scores)\n",
    "    return final_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "15344885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "scores = calculate_scores([sen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a8dc0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "64ec6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e3914428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for abstract in final_abstracts:\n",
    "#     df = pd.DataFrame(columns=[\"sentences\"])\n",
    "    \n",
    "#     for sentence in abstract:\n",
    "#         df = df.append({\"sentences\": sentence}, ignore_index=True)\n",
    "    \n",
    "#     # Append the DataFrame to the list of DataFrames\n",
    "#     dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "de826655",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "625de8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
      "/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_54869/3834090671.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dfs = []  # List to store DataFrames\n",
    "\n",
    "for abstract, score in zip(final_abstracts, scores):\n",
    "    df = pd.DataFrame(columns=[\"sentences\", \"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"F6\", \"F7\"])\n",
    "    \n",
    "    for sentence, s in zip(abstract, score):\n",
    "        df = df.append({\"sentences\": sentence, \"F1\": s[\"F1\"], \"F2\": s[\"F2\"], \"F3\": s[\"F3\"], \"F4\": s[\"F4\"], \"F5\": s[\"F5\"], \"F6\": s[\"F6\"], \"F7\": s[\"F7\"]}, ignore_index=True)\n",
    "    \n",
    "    # Append the DataFrame to the list of DataFrames\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "765664f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>additive models provide an important family of...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.668206</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is well known that good estimators in addit...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.298058</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many examples of such estimators belong to the...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.540474</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many interesting results on learning rates of ...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>6.784210</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is in sharp contrast to kernel methods ba...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>5.231011</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>the figures seem to indicate that our learning...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>4.917416</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>table1 the table lists the limits of the expon...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>2.730829</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>cor 4 12 and from theorem mainratesthm respect...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>4.413233</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>recall that</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.344988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>cols</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences  F1        F2  \\\n",
       "0    additive models provide an important family of...  43  0.000000   \n",
       "1    it is well known that good estimators in addit...  28  0.007812   \n",
       "2    many examples of such estimators belong to the...  28  0.015625   \n",
       "3    many interesting results on learning rates of ...  86  0.023438   \n",
       "4    this is in sharp contrast to kernel methods ba...  49  0.031250   \n",
       "..                                                 ...  ..       ...   \n",
       "123  the figures seem to indicate that our learning...  31  0.960938   \n",
       "124  table1 the table lists the limits of the expon...  10  0.968750   \n",
       "125  cor 4 12 and from theorem mainratesthm respect...  27  0.976562   \n",
       "126                                        recall that   2  0.984375   \n",
       "127                                               cols   1  0.992188   \n",
       "\n",
       "           F3  F4 F5        F6 F7  \n",
       "0    4.668206  18  0  0.065627  1  \n",
       "1    4.298058  10  0  0.075266  0  \n",
       "2    4.540474  13  0  0.073565  0  \n",
       "3    6.784210  44  0  0.113793  0  \n",
       "4    5.231011  21  0  0.115645  0  \n",
       "..        ...  .. ..       ... ..  \n",
       "123  4.917416  13  0  0.095955  0  \n",
       "124  2.730829   4  0  0.067397  0  \n",
       "125  4.413233  10  0  0.098964  0  \n",
       "126  1.344988   1  0  0.027698  0  \n",
       "127  1.000000   1  0  0.007812  0  \n",
       "\n",
       "[128 rows x 8 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "94d551bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentence_length(sLen):\n",
    "    sLenmax = max(sLen)\n",
    "    if sLenmax == 0:\n",
    "        return [0.0] * len(sLen)  # Avoid division by zero\n",
    "    return [sLeni / sLenmax for sLeni in sLen]\n",
    "\n",
    "def normalize_tfidf(tfidf_scores):\n",
    "    tfidf_max = max(tfidf_scores)\n",
    "    if tfidf_max == 0:\n",
    "        return [0.0] * len(tfidf_scores)  # Avoid division by zero\n",
    "    return [(tfidf_i / tfidf_max) for tfidf_i in tfidf_scores]\n",
    "\n",
    "def normalize_noun_verb_phrase(nvpi):\n",
    "    nvpi_max = max(nvpi)\n",
    "    if nvpi_max == 0:\n",
    "        return [0.0] * len(nvpi)  # Avoid division by zero\n",
    "    return [(nvpi_i / nvpi_max) for nvpi_i in nvpi]\n",
    "\n",
    "def normalize_proper_noun(PNi):\n",
    "    PNmax = max(PNi)\n",
    "    if PNmax == 0:\n",
    "        return [0.0] * len(PNi)  # Avoid division by zero\n",
    "    return [(PNi_i / PNmax) for PNi_i in PNi]\n",
    "\n",
    "def normalize_cosine_similarity(ACS):\n",
    "    ACSmax = max(ACS)\n",
    "    if ACSmax == 0:\n",
    "        return [0.0] * len(ACS)  # Avoid division by zero\n",
    "    return [(ACS_i / ACSmax) for ACS_i in ACS]\n",
    "\n",
    "def normalize_cue_phrases(CPi, tCP):\n",
    "    if tCP == 0:\n",
    "        return [0.0] * len(CPi)  # Avoid division by zero\n",
    "    return [(CPi_i / tCP) for CPi_i in CPi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "26b3f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentence_length(sLen):\n",
    "    sLenmax = max(sLen)\n",
    "    if sLenmax == 0:\n",
    "        return [0.0] * len(sLen)  # Avoid division by zero\n",
    "    return [sLeni / sLenmax for sLeni in sLen]\n",
    "\n",
    "def normalize_tfidf(tfidf_scores):\n",
    "    tfidf_max = max(tfidf_scores)\n",
    "    if tfidf_max == 0:\n",
    "        return [0.0] * len(tfidf_scores)  # Avoid division by zero\n",
    "    return [(tfidf_i / tfidf_max) for tfidf_i in tfidf_scores]\n",
    "\n",
    "def normalize_noun_verb_phrase(nvpi):\n",
    "    nvpi_max = max(nvpi)\n",
    "    if nvpi_max == 0:\n",
    "        return [0.0] * len(nvpi)  # Avoid division by zero\n",
    "    return [(nvpi_i / nvpi_max) for nvpi_i in nvpi]\n",
    "\n",
    "def normalize_proper_noun(PNi):\n",
    "    PNmax = max(PNi)\n",
    "    if PNmax == 0:\n",
    "        return [0.0] * len(PNi)  # Avoid division by zero\n",
    "    return [(PNi_i / PNmax) for PNi_i in PNi]\n",
    "\n",
    "def normalize_cosine_similarity(ACS):\n",
    "    ACSmax = max(ACS)\n",
    "    if ACSmax == 0:\n",
    "        return [0.0] * len(ACS)  # Avoid division by zero\n",
    "    return [(ACS_i / ACSmax) for ACS_i in ACS]\n",
    "\n",
    "def normalize_cue_phrases(CPi, tCP):\n",
    "    if tCP == 0:\n",
    "        return [0.0] * len(CPi)  # Avoid division by zero\n",
    "    return [(CPi_i / tCP) for CPi_i in CPi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "11d575b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]['F1_normalized'] = normalize_sentence_length(dfs[0]['F1'])\n",
    "\n",
    "dfs[0][\"F2_normalized\"] = dfs[0][\"F2\"]\n",
    "\n",
    "# Normalize TF-IDF (F3)\n",
    "dfs[0]['F3_normalized'] = normalize_tfidf(dfs[0]['F3'])\n",
    "\n",
    "# Normalize Noun and Verb Phrase (F4)\n",
    "dfs[0]['F4_normalized'] = normalize_noun_verb_phrase(dfs[0]['F4'])\n",
    "\n",
    "# Normalize Proper Noun (F5)\n",
    "dfs[0]['F5_normalized'] = normalize_proper_noun(dfs[0]['F5'])\n",
    "\n",
    "# Normalize Aggregate Cosine Similarity (F6)\n",
    "dfs[0]['F6_normalized'] = normalize_cosine_similarity(dfs[0]['F6'])\n",
    "\n",
    "# Normalize Cue Phrases (F7)\n",
    "tCP = len(cue_phrases)\n",
    "dfs[0]['F7_normalized'] = normalize_cue_phrases(dfs[0]['F7'], tCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3bf593b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F1_normalized</th>\n",
       "      <th>F2_normalized</th>\n",
       "      <th>F3_normalized</th>\n",
       "      <th>F4_normalized</th>\n",
       "      <th>F5_normalized</th>\n",
       "      <th>F6_normalized</th>\n",
       "      <th>F7_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>additive models provide an important family of...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.668206</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065627</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640326</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368230</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is well known that good estimators in addit...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.298058</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.589554</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422313</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many examples of such estimators belong to the...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.540474</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.622806</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412772</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many interesting results on learning rates of ...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>6.784210</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677165</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.930574</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638487</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is in sharp contrast to kernel methods ba...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>5.231011</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.717525</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648883</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>the figures seem to indicate that our learning...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>4.917416</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244094</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>table1 the table lists the limits of the expon...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>2.730829</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067397</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.374581</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378164</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>cor 4 12 and from theorem mainratesthm respect...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>4.413233</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098964</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212598</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.605352</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555284</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>recall that</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.344988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.184489</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155412</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>cols</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043836</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences  F1        F2  \\\n",
       "0    additive models provide an important family of...  43  0.000000   \n",
       "1    it is well known that good estimators in addit...  28  0.007812   \n",
       "2    many examples of such estimators belong to the...  28  0.015625   \n",
       "3    many interesting results on learning rates of ...  86  0.023438   \n",
       "4    this is in sharp contrast to kernel methods ba...  49  0.031250   \n",
       "..                                                 ...  ..       ...   \n",
       "123  the figures seem to indicate that our learning...  31  0.960938   \n",
       "124  table1 the table lists the limits of the expon...  10  0.968750   \n",
       "125  cor 4 12 and from theorem mainratesthm respect...  27  0.976562   \n",
       "126                                        recall that   2  0.984375   \n",
       "127                                               cols   1  0.992188   \n",
       "\n",
       "           F3  F4 F5        F6 F7  F1_normalized  F2_normalized  \\\n",
       "0    4.668206  18  0  0.065627  1       0.338583       0.000000   \n",
       "1    4.298058  10  0  0.075266  0       0.220472       0.007812   \n",
       "2    4.540474  13  0  0.073565  0       0.220472       0.015625   \n",
       "3    6.784210  44  0  0.113793  0       0.677165       0.023438   \n",
       "4    5.231011  21  0  0.115645  0       0.385827       0.031250   \n",
       "..        ...  .. ..       ... ..            ...            ...   \n",
       "123  4.917416  13  0  0.095955  0       0.244094       0.960938   \n",
       "124  2.730829   4  0  0.067397  0       0.078740       0.968750   \n",
       "125  4.413233  10  0  0.098964  0       0.212598       0.976562   \n",
       "126  1.344988   1  0  0.027698  0       0.015748       0.984375   \n",
       "127  1.000000   1  0  0.007812  0       0.007874       0.992188   \n",
       "\n",
       "     F3_normalized  F4_normalized  F5_normalized  F6_normalized  F7_normalized  \n",
       "0         0.640326       0.315789            0.0       0.368230       0.083333  \n",
       "1         0.589554       0.175439            0.0       0.422313       0.000000  \n",
       "2         0.622806       0.228070            0.0       0.412772       0.000000  \n",
       "3         0.930574       0.771930            0.0       0.638487       0.000000  \n",
       "4         0.717525       0.368421            0.0       0.648883       0.000000  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "123       0.674510       0.228070            0.0       0.538402       0.000000  \n",
       "124       0.374581       0.070175            0.0       0.378164       0.000000  \n",
       "125       0.605352       0.175439            0.0       0.555284       0.000000  \n",
       "126       0.184489       0.017544            0.0       0.155412       0.000000  \n",
       "127       0.137168       0.017544            0.0       0.043836       0.000000  \n",
       "\n",
       "[128 rows x 15 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1e5128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Total Score for each sentence based on the normalized features\n",
    "dfs[0]['Total Score'] = dfs[0]['F1_normalized'] + dfs[0]['F2_normalized'] + dfs[0]['F3_normalized'] + dfs[0]['F4_normalized'] + dfs[0]['F5_normalized'] + dfs[0]['F6_normalized'] + dfs[0]['F7_normalized']\n",
    "\n",
    "# Sort the DataFrame based on Total Score to rank the sentences\n",
    "dfs[0] = dfs[0].sort_values(by='Total Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Now df is sorted by Total Score, with the highest-ranked sentence at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "127a9f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F1_normalized</th>\n",
       "      <th>F2_normalized</th>\n",
       "      <th>F3_normalized</th>\n",
       "      <th>F4_normalized</th>\n",
       "      <th>F5_normalized</th>\n",
       "      <th>F6_normalized</th>\n",
       "      <th>F7_normalized</th>\n",
       "      <th>Total Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approxerrorthm under assumption assumption1 we...</td>\n",
       "      <td>127</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>6.852250</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178222</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if assumption assumption1 holds with and has a...</td>\n",
       "      <td>110</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.714675</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.921036</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.027024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaussmore let and 2 let and the additive kerne...</td>\n",
       "      <td>71</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>6.630449</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142882</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.909483</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for example under the assumptions that has a o...</td>\n",
       "      <td>72</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>6.286704</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157484</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.862332</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.530690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i e we assume in particular that is a probabil...</td>\n",
       "      <td>71</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>6.436577</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.882890</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>3.514464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>are treated as important special cases</td>\n",
       "      <td>6</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>2.391459</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.328031</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145105</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.953220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>noisecond let 1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>1.391354</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.190849</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>for the same reason we will also not cover spa...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>2.984414</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051193</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>let</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>we establish learning rates for these algorithms</td>\n",
       "      <td>7</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>2.484617</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.340809</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences   F1        F2  \\\n",
       "0    approxerrorthm under assumption assumption1 we...  127  0.476562   \n",
       "1    if assumption assumption1 holds with and has a...  110  0.625000   \n",
       "2    gaussmore let and 2 let and the additive kerne...   71  0.773438   \n",
       "3    for example under the assumptions that has a o...   72  0.726562   \n",
       "4    i e we assume in particular that is a probabil...   71  0.820312   \n",
       "..                                                 ...  ...       ...   \n",
       "123             are treated as important special cases    6  0.296875   \n",
       "124                                    noisecond let 1    3  0.554688   \n",
       "125  for the same reason we will also not cover spa...   10  0.078125   \n",
       "126                                                let    1  0.570312   \n",
       "127   we establish learning rates for these algorithms    7  0.093750   \n",
       "\n",
       "           F3  F4 F5        F6 F7  F1_normalized  F2_normalized  \\\n",
       "0    6.852250  57  0  0.178222  0       1.000000       0.476562   \n",
       "1    6.714675  37  0  0.172114  0       0.866142       0.625000   \n",
       "2    6.630449  30  0  0.142882  0       0.559055       0.773438   \n",
       "3    6.286704  28  0  0.157484  0       0.566929       0.726562   \n",
       "4    6.436577  26  0  0.127025  1       0.559055       0.820312   \n",
       "..        ...  .. ..       ... ..            ...            ...   \n",
       "123  2.391459   3  0  0.025861  1       0.047244       0.296875   \n",
       "124  1.391354   2  0  0.023904  0       0.023622       0.554688   \n",
       "125  2.984414   3  0  0.051193  0       0.078740       0.078125   \n",
       "126  1.000000   1  0  0.029403  0       0.007874       0.570312   \n",
       "127  2.484617   4  0  0.044695  0       0.055118       0.093750   \n",
       "\n",
       "     F3_normalized  F4_normalized  F5_normalized  F6_normalized  \\\n",
       "0         0.939906       1.000000            0.0       1.000000   \n",
       "1         0.921036       0.649123            0.0       0.965724   \n",
       "2         0.909483       0.526316            0.0       0.801709   \n",
       "3         0.862332       0.491228            0.0       0.883638   \n",
       "4         0.882890       0.456140            0.0       0.712733   \n",
       "..             ...            ...            ...            ...   \n",
       "123       0.328031       0.052632            0.0       0.145105   \n",
       "124       0.190849       0.035088            0.0       0.134126   \n",
       "125       0.409365       0.052632            0.0       0.287241   \n",
       "126       0.137168       0.017544            0.0       0.164980   \n",
       "127       0.340809       0.070175            0.0       0.250780   \n",
       "\n",
       "     F7_normalized  Total Score  \n",
       "0         0.000000     4.416469  \n",
       "1         0.000000     4.027024  \n",
       "2         0.000000     3.570000  \n",
       "3         0.000000     3.530690  \n",
       "4         0.083333     3.514464  \n",
       "..             ...          ...  \n",
       "123       0.083333     0.953220  \n",
       "124       0.000000     0.938372  \n",
       "125       0.000000     0.906103  \n",
       "126       0.000000     0.897878  \n",
       "127       0.000000     0.810632  \n",
       "\n",
       "[128 rows x 16 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "41ed9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define and fit a TF-IDF vectorizer on your text data\n",
    "your_tfidf_vectorizer = TfidfVectorizer()\n",
    "your_tfidf_vectorizer.fit(dfs[0][\"sentences\"])  # Replace 'your_text_data' with your actual text data\n",
    "\n",
    "Summary = []  # Initialize the summary\n",
    "Threshold = 0.15\n",
    "\n",
    "# Iterate through the sorted sentences\n",
    "for i in range(len(df)):\n",
    "    current_sentence = dfs[0]['sentences'][i]\n",
    "\n",
    "    # Calculate cosine similarity with existing summary\n",
    "    if not Summary:\n",
    "        Summary.append(current_sentence)\n",
    "    else:\n",
    "        similarity = cosine_similarity(\n",
    "            np.array(your_tfidf_vectorizer.transform([current_sentence]).todense()),\n",
    "            np.array(your_tfidf_vectorizer.transform(Summary).todense())\n",
    "        )\n",
    "        if similarity[0][0] < Threshold:  # Check if any element in the similarity array is less than the threshold\n",
    "            Summary.append(current_sentence)\n",
    "\n",
    "\n",
    "Summary_sentences = [dfs[0][dfs[0]['sentences'] == sentence]['sentences'].values[0] for sentence in Summary]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e73c3ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "89e7a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# # Load pre-trained GPT-2 model and tokenizer\n",
    "# model_name = \"gpt3\"  # You can use other variants of GPT-2 as well\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Tokenize and encode the input text\n",
    "# input_ids = tokenizer.encode(Summary_sentences, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# # Generate abstractive summary\n",
    "# summary_ids = model.generate(input_ids, max_length=150, min_length=50, num_beams=5, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "# # Decode and print the summary\n",
    "# summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c058b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0003834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f1075e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approxerrorthm under assumption assumption1 we have where is the constant given by the second condition for our learning rate is about the capacity of the hypothesis space measured by covering number let be a set of function on and for every the covering number of with respect to the empirical metric given by is defined a and the covering number of is defined a assumption2 we assume and that for some and every the covering number of the unit ball of satisfies the second novelty of this paper is to observe that the additive nature of the hypothesis space yield the following nice bound with a dimension independent power exponent for the covering number of the ball of the hypothesis space to be proved in section samplesection our leading example cover learning rate for quantile regression based on the lipschitz continuous but non differentiable pinball loss function which is also called check function in the literature see e g and for parametric quantile regression and and for kernel based quantile regression if we take all the mercer kernel to be then for each the additive kernel is also a mercer kernel and defines an rkhs however the multivariate sobolev space consisting of all square integrable function whose partial derivative are all square integrable contains discontinuous function and is not an rkhs therefore we will here consider the case of regularized kernel based method based on a general convex and lipschitz continuous loss function on a general kernel and on the classical regularizing term for some which is a smoothness penalty but not a sparsity penalty see e g we need an assumption on a _ variance expectation bound _ which is similar to definition noisecond in the special case of quantile regression cor 4 12 and from theorem mainratesthm respectively if the regularizing parameter is chosen in an optimal manner for the nonparametric setup i e with for and\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from nltk.stem import WordNetLemmatizer  # Import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Calculate sentence similarity and create a graph\n",
    "def sentence_similarity(sent1, sent2, tfidf_vectorizer):\n",
    "    tfidf_matrix = tfidf_vectorizer.transform([sent1, sent2])\n",
    "    cosine_sim = (tfidf_matrix * tfidf_matrix.T).A[0, 1]\n",
    "    return cosine_sim\n",
    "\n",
    "def build_similarity_matrix(sentences, tfidf_vectorizer):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                similarity_matrix[i][j] = sentence_similarity(sentences[i], sentences[j], tfidf_vectorizer)\n",
    "    return similarity_matrix\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([lemmatize_sentence(sent) for sent in Summary_sentences])\n",
    "\n",
    "# Create the sentence similarity graph\n",
    "sentences = [lemmatize_sentence(sent) for sent in Summary_sentences]\n",
    "sentence_similarity_matrix = build_similarity_matrix(sentences, tfidf_vectorizer)\n",
    "sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "\n",
    "# Generate summary using PageRank\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "num_sentences_in_summary = 7\n",
    "summary_sentences = [s for _, s in ranked_sentences[:num_sentences_in_summary]]\n",
    "\n",
    "# Join the summary sentences to create the final summary\n",
    "summary = ' '.join([lemmatize_sentence(sent) for sent in summary_sentences])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d3064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de954222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0b62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a960e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12ead6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a83ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c9d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca099ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5dee0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b1b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
