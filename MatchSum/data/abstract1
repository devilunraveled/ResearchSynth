additive models play an important role in semiparametric statistics . 
this paper gives learning rates for regularized kernel based methods for additive models . 
these learning rates compare favourably in particular in high dimensions to recent results on 
optimal learning rates for purely nonparametric regularized kernel based quantile regression 
using the gaussian radial basis function kernel , provided the assumption of an additive model 
is valid . additionally , a concrete example is presented to show that a gaussian function 
depending only on one variable lies in a reproducing kernel hilbert space generated by an 
additive gaussian kernel , but does not belong to the reproducing kernel hilbert space 
generated by the multivariate gaussian kernel of the same variance . * key words and phrases . 
* additive model , kernel , quantile regression , semiparametric , rate of convergence , 
support vector machine .