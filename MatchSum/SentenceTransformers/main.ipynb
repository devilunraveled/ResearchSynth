{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashmitchamoli/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('intfloat/e5-large-v2')\n",
    "model1 = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the second model to generate embeddings for the document and the summary.\n",
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "\n",
    "with open('../data/paper1', 'r') as f:\n",
    "    input_texts.append(\"passage: \" + f.read())\n",
    "with open('../data/abstract1', 'r') as f:\n",
    "    input_texts.append(\"passage: \" + f.read())    \n",
    "with open('../data/paper2', 'r') as f:\n",
    "    input_texts.append(\"passage: \" + f.read())\n",
    "with open('../data/abstract2', 'r') as f:\n",
    "    input_texts.append(\"passage: \" + f.read())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Embeddings\n",
    "We will generate the embeddings and see the semantic similarity score for abstract and the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Paper 1:\n",
      "\tAbstract 1 Score: 0.9030022621154785, Abstract 2 Score: 0.7938213348388672.\n",
      "For Paper 2:\n",
      "\tAbstract 1 Score: 0.7524808645248413, Abstract 2 Score: 0.8678621053695679.\n",
      "For Paper 1:\n",
      "\tAbstract 1 Score: 0.8340383172035217, Abstract 2 Score: 0.13522927463054657.\n",
      "For Paper 2:\n",
      "\tAbstract 1 Score: 0.048615314066410065, Abstract 2 Score: 0.7643997669219971.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = model.encode(input_texts, normalize_embeddings=True)\n",
    "embeddings = np.array(embeddings)\n",
    "print(f\"For Paper 1:\\n\\tAbstract 1 Score: {np.dot(embeddings[0], embeddings[1])}, \\\n",
    "Abstract 2 Score: {np.dot(embeddings[0], embeddings[3])}.\\n\\\n",
    "For Paper 2:\\n\\tAbstract 1 Score: {np.dot(embeddings[2], embeddings[1])}, \\\n",
    "Abstract 2 Score: {np.dot(embeddings[2], embeddings[3])}.\")\n",
    "\n",
    "embeddings1 = model1.encode(input_texts)\n",
    "embeddings1 = np.array(embeddings1)\n",
    "print(f\"For Paper 1:\\n\\tAbstract 1 Score: {np.dot(embeddings1[0], embeddings1[1]) / np.linalg.norm(embeddings1[0]) / np.linalg.norm(embeddings1[1])}, \\\n",
    "Abstract 2 Score: {np.dot(embeddings1[0], embeddings1[3]) / np.linalg.norm(embeddings1[0]) / np.linalg.norm(embeddings1[3])}.\\n\\\n",
    "For Paper 2:\\n\\tAbstract 1 Score: {np.dot(embeddings1[2], embeddings1[1]) / np.linalg.norm(embeddings1[2]) / np.linalg.norm(embeddings1[1])}, \\\n",
    "Abstract 2 Score: {np.dot(embeddings1[2], embeddings1[3]) / np.linalg.norm(embeddings1[2]) / np.linalg.norm(embeddings1[3])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, model1 provides a much more stark difference between the similarity of abstract with its own paper and the similarity of abstract with another paper, which is the property which we desire: good summaries will be more similar to the source documents.\n",
    "\n",
    "# Generating n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an array n-grams where n-grams[i] = (ith n-gram, i)\n",
    "def generate_n_grams(n, sentences):\n",
    "    return [('.'.join(sentences[i:i+n]), i) for i in range(len(sentences)-n+1)]\n",
    "\n",
    "# get the sentences\n",
    "paper1 = input_texts[0]\n",
    "sentences = paper1.split(\".\") # getting the sentences\n",
    "\n",
    "\n",
    "# generate n-grams\n",
    "n = 2\n",
    "n_grams = generate_n_grams(n, sentences)\n",
    "\n",
    "# calculate similarity of each n-gram with the paper\n",
    "sims = []\n",
    "for gram in n_grams:\n",
    "    embeddings1 = model1.encode([gram[0], paper1], normalize_embeddings=True)\n",
    "    sims.append((np.dot(embeddings1[0], embeddings1[1]), gram[1]))\n",
    "\n",
    "# select top k sentences\n",
    "k = 10\n",
    "r = int(np.ceil(k/n))\n",
    "topr_n_grams = sorted(sims, key=lambda x: x[0], reverse=True)[:r]\n",
    "topr_n_grams = sorted(topr_n_grams, key=lambda x: x[1]) # get the sentences back in order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$i^{th}$ row of the list `ngrams` (1-indexed) contains i-grams of the sentences from the source document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ngrams = []\n",
    "# k = 4\n",
    "# for i in range(1, k+1):\n",
    "#     ngrams.append(n_grams(i))\n",
    "\n",
    "# sims = []\n",
    "# for grams in ngrams:\n",
    "#     sims.append([])\n",
    "#     for gram in grams:\n",
    "#         embeddings1 = model1.encode([gram, paper1], normalize_embeddings=True)\n",
    "#         sims[-1].append(np.dot(embeddings1[0], embeddings1[1]))\n",
    "\n",
    "# for i in range(len(sims)):\n",
    "#     ind = np.argsort(sims[i])[::-1]\n",
    "#     sims[i] = np.array(sims[i])[ind]\n",
    "#     ngrams[i] = np.array(ngrams[i])[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space @xmath0 , see e.\n",
      " @xcite . in the last years many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.\n",
      " in the last years many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g.\n",
      " @xcite for the general case and @xcite for additive models . therefore , we will here consider the case of regularized kernel based methods based on a general convex and lipschitz continuous loss function , on a general kernel , and on the classical regularizing term @xmath1 for some @xmath2 which is a smoothness penalty but not a sparsity penalty , see e.\n",
      " such regularized kernel based methods are now often called support vector machines ( svms ) , although the notation was historically used for such methods based on the special hinge loss function and for special kernels only , we refer to @xcite . in this paper we address the open question , whether an svm with an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , if the assumption of an additive model is satisfied \n"
     ]
    }
   ],
   "source": [
    "# print the generated sumamry\n",
    "print(\"Summary:\")\n",
    "print(\".\\n\".join([n_grams[gram[1]][0] for gram in topr_n_grams]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
